{"meta":{"title":"On The Way","subtitle":null,"description":null,"author":"Vincent Xin","url":"https://vincentxin-scott.github.io","root":"/"},"pages":[{"title":"分类","date":"2020-09-30T07:24:22.832Z","updated":"2019-03-15T10:28:25.245Z","comments":false,"path":"categories/index.html","permalink":"https://vincentxin-scott.github.io/categories/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2020-09-30T07:24:22.796Z","updated":"2019-03-15T10:28:25.246Z","comments":false,"path":"repository/index.html","permalink":"https://vincentxin-scott.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-09-30T07:24:22.832Z","updated":"2019-03-15T10:28:25.246Z","comments":false,"path":"tags/index.html","permalink":"https://vincentxin-scott.github.io/tags/index.html","excerpt":"","text":""},{"title":"","date":"2020-09-30T07:24:22.801Z","updated":"2020-07-14T10:36:35.924Z","comments":true,"path":"uml/yunchatboard.html","permalink":"https://vincentxin-scott.github.io/uml/yunchatboard.html","excerpt":"","text":"项目目录结构说明Meeting-edu目前课桌的主要项目由以下模块组成 - edu-admin 后台管理模块 - edu-gateway 网关模块 - edu-meeting 业务功能模块 edu-admin："},{"title":"","date":"2020-09-30T07:24:22.801Z","updated":"2020-01-28T02:47:42.239Z","comments":true,"path":"uml/国电信通认证.html","permalink":"https://vincentxin-scott.github.io/uml/%E5%9B%BD%E7%94%B5%E4%BF%A1%E9%80%9A%E8%AE%A4%E8%AF%81.html","excerpt":"","text":"需求文档设计文档测试文档测试记录"},{"title":"","date":"2020-09-30T07:24:22.801Z","updated":"2019-11-12T05:04:36.881Z","comments":true,"path":"uml/年会红包产品会.html","permalink":"https://vincentxin-scott.github.io/uml/%E5%B9%B4%E4%BC%9A%E7%BA%A2%E5%8C%85%E4%BA%A7%E5%93%81%E4%BC%9A.html","excerpt":"","text":"年会红包功能项目开发来源 微信公众号作为入口到小程序 微信扫码参与登录够样账户密码（够样账户登录） 忘记密码"},{"title":"","date":"2020-09-30T07:24:22.801Z","updated":"2020-03-02T09:45:51.319Z","comments":true,"path":"uml/订单中心重构工作计划.html","permalink":"https://vincentxin-scott.github.io/uml/%E8%AE%A2%E5%8D%95%E4%B8%AD%E5%BF%83%E9%87%8D%E6%9E%84%E5%B7%A5%E4%BD%9C%E8%AE%A1%E5%88%92.html","excerpt":"","text":"辛智慧订单中心重构工作计划工作内容： 订单中心变成聚合式订单中心，所以业务订单可以通过插拔配置实现； 满足现有优惠买单订单业务需求； 增加供热订单的业务需求； 满足后期追加商城订单bbc的业务需求； 工作计划： 2月11日～2月14日：完成订单中心业务逻辑设计 2月11日：按照上级要求撰写订单中心重构工作计划，完成度100% 2月12日：调研订单中心业务逻辑，明确我们的订单中心主要存在哪些业务逻辑操作。 2月13日：初步确定重构订单中心业务逻辑及主要功能(提交初稿) 2月14日：与刘钢对接供热订单接入订单中心的逻辑、与银杰对接优惠买单接入订单中心的逻辑 2月17日～2月21日：完成订单中心表结构设计及接口设计 2月17日：完成订单路由表结构设计 2月18日：完成订单路由路由逻辑设计 2月19日：完成逻辑业务接口设计 2月20日：与刘钢、银杰对接各业务中心的接口设计和调用逻辑。 2月21日：讨论完善各个业务中心需求功能是否完善，有无需要改进。 2月24日～2月28日：完成功能开发工作 2月24日：在现有代码基础上建立订单中心重构分支，开发订单路由功能基础增删改的操作。 2月25日：完成通过路由表对各个业务中心的路由逻辑开发 2月26日：完成订单创建接口开发 2月27日：完成订单修改接口开发 2月28日：完成订单接口调试和测试"}],"posts":[{"title":"永久自动获得免费得HTTPS证书","slug":"杂记随笔/永久自动获得免费的HTTPS证书--certbot","date":"2021-01-28T08:02:16.624Z","updated":"2021-02-01T06:16:22.476Z","comments":true,"path":"2021/01/28/杂记随笔/永久自动获得免费的HTTPS证书--certbot/","link":"","permalink":"https://vincentxin-scott.github.io/2021/01/28/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/%E6%B0%B8%E4%B9%85%E8%87%AA%E5%8A%A8%E8%8E%B7%E5%BE%97%E5%85%8D%E8%B4%B9%E7%9A%84HTTPS%E8%AF%81%E4%B9%A6--certbot/","excerpt":"","text":"前提拥有域名，拥有公网IP的服务器 官方主页了解一下certbot参考学习。 功能描述 用于获取HTTPS证书并自动更新 可以对代理文件进行自动维护环境 OS： CentOS7 网站服务器： Nginx安装 官方推荐首先安装snapd,选择自己的系统进行安装。 通过命令 cat /etc/centos-release 确认自己的系统版本 以安装centos7为例 12345678# 可以使用以下命令将EPEL存储库添加到CentOS 7系统#1. sudo yum install epel-release# 将EPEL存储库添加到CentOS安装中后，只需安装snapd软件包：2. sudo yum install snapd# 安装后，需要启用用于管理主快照通信套接字的systemd单元：3. sudo systemctl enable --now snapd.socket# 要启用经典快照支持4. sudo ln -s /var/lib/snapd/snap /snap 最后系统提示 重启系统去确保snap被正确的安装。但是我没有重启也可以使用 安装certbot123456# 安装前先确保你的nsap保持的是最新的版本sudo snap install core; sudo snap refresh core# 安装certbotsudo snap install --classic certbot# 确保certbot命令可以被运行sudo ln -s /snap/bin/certbot /usr/bin/certbot 创建SSL证书并配置12sudo certbot --nginx 第一次创建的时候会提示你输入邮箱，一个开启模式，一个是是否同意协议。 之后会创建会有提示：你可以选择需要创建的域名，也可以选择全部。 创建好之后的效果红色部分是cerbot 自动写入的。 设置自动续期因为certbot生成的有效证书是三个月，为了方便，可以实现自动续期。 我们可以通过Linux自带的cron来实现自动续期 创建一个文件内容写 文件名xxxx 120 */12 * * * certbot renew --quiet --renew-hook &quot;/etc/init.d/nginx reload&quot; 系统中执行 1crontab xxxx 系统会每天检查证书是否需要更新，如果更新了之后会对nginx重载。","categories":[{"name":"杂记随笔","slug":"杂记随笔","permalink":"https://vincentxin-scott.github.io/categories/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"certbot","slug":"certbot","permalink":"https://vincentxin-scott.github.io/tags/certbot/"}]},{"title":"分布式数据库PloarDB-X","slug":"数据库/阿里分布式数据库PolarDB-X","date":"2020-09-07T02:51:54.594Z","updated":"2020-09-22T09:52:40.246Z","comments":true,"path":"2020/09/07/数据库/阿里分布式数据库PolarDB-X/","link":"","permalink":"https://vincentxin-scott.github.io/2020/09/07/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%98%BF%E9%87%8C%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93PolarDB-X/","excerpt":"","text":"产品介绍PolarDB-X是由阿里巴巴自主研发的云原生分布式数据库，融合分布式SQL引擎DRDS与分布式自研存储X-DB，基于云原生一体化架构设计，可支撑千万级并发规模及百PB级海量存储 产品特点稳定PolarDB-X将数据拆分到多个MySQL存储，使每个MySQL承担合适的并发、数据存储和计算负载，各个MySQL处于稳定状态。PolarDB-X层面处理分布式逻辑，最终得到一个具有稳定可靠、高度扩展性的分布式关系型数据库系统。 高度可扩展持续可运维","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"分布式数据库","slug":"分布式数据库","permalink":"https://vincentxin-scott.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"MySQL实践篇-MySQL是怎么保证主备一致的？","slug":"数据库/MySQL/mysql｜20MySQL是怎么保证主备一致的","date":"2020-08-27T03:58:50.328Z","updated":"2020-09-22T09:52:40.246Z","comments":true,"path":"2020/08/27/数据库/MySQL/mysql｜20MySQL是怎么保证主备一致的/","link":"","permalink":"https://vincentxin-scott.github.io/2020/08/27/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C20MySQL%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84/","excerpt":"","text":"MySQL是怎么保证主备一致的？在最开始，MySQL是以容易学习和放方便的高可用架构，被开发人员青睐的。而它的几乎所有的高可用架构，都直接依赖binlog。虽然这些高可用架构已经呈现出来越来越复杂的趋势，但都是从最基本的一主一备演化过来的。 MySQL主备的基本原理 在状态1中，客户端的读写都是直接访问节点A，而节点B是A的备库，只是将A的更新都同步过来，到本地执行。这样可以保持节点B和A的数据是相同的。 在切换的时候，就切成状态2.这时候客户端读写访问的都是节点B，而节点A是B的备库。 建议将备库设置成只读模式： 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作； 防止切换逻辑有bug； 可以用readonly状态，来判断节点角色。 readonly设置对超级权限用户是无效的，而用于同步更新的线程，就拥有超级权限。 主从复制内部流程","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"分布式数据库技术选型","slug":"数据库/分布式数据库选型方案对比","date":"2020-08-03T04:19:53.397Z","updated":"2020-08-03T10:35:23.665Z","comments":true,"path":"2020/08/03/数据库/分布式数据库选型方案对比/","link":"","permalink":"https://vincentxin-scott.github.io/2020/08/03/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E9%80%89%E5%9E%8B%E6%96%B9%E6%A1%88%E5%AF%B9%E6%AF%94/","excerpt":"","text":"分布式数据库技术选型对比OLAP(On-line Analytical Processing)事务处理：会有高并发且数据量级不大的查询，主要是用于管理事务的系统。此类系统专注于short on-line-tansactions 如INSERT, UPDATE, DELETE操作。通常存在此类系统中的数据都是以实体对象模型来存储数据，并满足3NF(数据库第三范式)。 OLTP(On-line Transaction Processing)分析处理：查询频率较OLTP系统更低，但通常会涉及到非常复杂的聚合计算。 OLAP系统以维度模型来存储历史数据，其主要存储描述性的数据并且在结构上都是同质的。 OLTP and OLAP对照 分布式数据库中间件CobarMyCATTDDLDRDSAtlasDBProxyShardingSphere–Sharding-JDBCShardingSphere–Sharding-Proxy分布式数据库产品PolarBD-XOceanBase","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"分布式数据库","slug":"分布式数据库","permalink":"https://vincentxin-scott.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Transactional事务失效自检流程","slug":"Java/Spring事务失效原因探究","date":"2020-05-29T06:12:24.360Z","updated":"2020-06-03T02:02:10.012Z","comments":true,"path":"2020/05/29/Java/Spring事务失效原因探究/","link":"","permalink":"https://vincentxin-scott.github.io/2020/05/29/Java/Spring%E4%BA%8B%E5%8A%A1%E5%A4%B1%E6%95%88%E5%8E%9F%E5%9B%A0%E6%8E%A2%E7%A9%B6/","excerpt":"","text":"Spring 的传播行为123456789 public enum Propagation &#123; REQUIRED(0), SUPPORTS(1), MANDATORY(2), REQUIRES_NEW(3), NOT_SUPPORTED(4), NEVER(5), NESTED(6); &#125; REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务。则创建一个新事务。 SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务方式继续运行。 MANDATORY:如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。 REQUIRES_NEW:创建一个新的事务，如果当前存在事务，则把当前事务挂起。 NOT_SUPPORTED ：以非事务方式运行，如果当前存在事务，则把当前事务挂起。 NEVER ：以非事务方式运行，如果当前存在事务，则抛出异常。 NESTED ：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于 REQUIRED 。 动态代理在继续探究前，先简单带过一下动态代理。代理模式主要功能是为了增强一个类中的方法诞生的一种设计模式。而代理模式分为动态代理和静态代理，动态代理的代理类是在运行时生成的，而静态代理是在编译时生成的。动态代理可以分为基于接口的JDK动态代理和基于类的Cglib动态代理。下面讲解一下基于JDK的动态代理：在java的java.lang.reflect包下提供了一个Proxy类和一个InvocationHandler接口，通过这个类和这个接口可以生成JDK动态代理类和动态代理对象。 1234567891011121314151617181920212223242526272829303132333435363738public interface Person &#123; void work();&#125;public class Student implements Person &#123; @Override public void work() &#123; System.out.println(&quot;读书&quot;); &#125;&#125;public class MyInvocationHandler implements InvocationHandler &#123; //增强的目标类 private Person person; public MyInvocationHandler(Person person) &#123; this.person = person; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;先吃饭-----再看书&quot;); method.invoke(person, args); return null; &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; Person person = new Student(); MyInvocationHandler myInvocationHandler = new MyInvocationHandler(person); System.out.println(Arrays.toString(Student.class.getInterfaces())); Person proPerson = (Person) Proxy.newProxyInstance(Student.class.getClassLoader(), Student.class.getInterfaces(), myInvocationHandler); proPerson.work(); &#125;&#125;//结果为： 先吃饭-----再看书 读书 动态代理的坑Spring事务是基于动态代理实现的。那么，Spring事务失效的真正原因和动态代理有什么关联呢？","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"事务","slug":"事务","permalink":"https://vincentxin-scott.github.io/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"shell构建项目部署脚本","slug":"Shell/项目部署脚本","date":"2020-05-18T03:36:36.574Z","updated":"2020-05-18T03:47:13.833Z","comments":true,"path":"2020/05/18/Shell/项目部署脚本/","link":"","permalink":"https://vincentxin-scott.github.io/2020/05/18/Shell/%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E8%84%9A%E6%9C%AC/","excerpt":"","text":"centos部署jar包脚本在～目录建立一个start.sh文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106#!/bin/bash# 启动的方法参数（[start|stop|restart|status]）PARAMETER=$1#jar包路径，加不加引号都行。 注意：等号两边 不能 有空格，否则会提示command找不到JAR_NAME=$2# 日志路径，加不加引号都行。 注意：等号两边 不能 有空格，否则会提示command找不到LOG_PATh=$3 # 如果输入格式不对，给出提示！tips() &#123; echo &quot;&quot; echo &quot;WARNING!!!......Tips, please use command: sh srart.sh [start|stop|restart|status]. For example: sh srart.sh start &quot; echo &quot;&quot; exit 1&#125; # 启动方法start() &#123; # 重新获取一下pid，因为其它操作如stop会导致pid的状态更新 pid=`ps -ef |grep java | grep $JAR_NAME | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27;` # -z 表示如果$pid为空时执行 if [ -z $pid ]; then nohup java -jar $JAR_NAME &gt; /dev/null 2&gt;&amp;1 &amp; pid=`ps -ef | grep $JAR_NAME | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27;` echo &quot;&quot; echo &quot;Service $&#123;JAR_NAME&#125; is starting！pid=$&#123;pid&#125;&quot; echo &quot;........................Here is the log..............................&quot; echo &quot;.....................................................................&quot; tail -f $LOG_PATh echo &quot;........................Start successfully！.........................&quot; else echo &quot;&quot; echo &quot;Service $&#123;JAR_NAME&#125; is already running,it&#x27;s pid = $&#123;pid&#125;. If necessary, please use command: sh srart.sh restart.&quot; echo &quot;&quot; fi&#125; # 停止方法stop() &#123; # 重新获取一下pid，因为其它操作如start会导致pid的状态更新 pid=`ps -ef | grep java | grep $JAR_NAME | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27;` # -z 表示如果$pid为空时执行。 注意：每个命令和变量之间一定要前后加空格，否则会提示command找不到 if [ -z $pid ];then echo &quot;&quot; echo &quot;Service $&#123;JAR_NAME&#125; is not running! It&#x27;s not necessary to stop it!&quot; echo &quot;&quot; else kill -9 $pid echo &quot;&quot; echo &quot;Service stop successfully！pid:$&#123;pid&#125; which has been killed forcibly!&quot; echo &quot;&quot; fi&#125; # 输出运行状态方法status() &#123; # 重新获取一下pid，因为其它操作如stop、restart、start等会导致pid的状态更新 pid=`ps -ef | grep java | grep $JAR_NAME | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27;` # -z 表示如果$pid为空时执行。注意：每个命令和变量之间一定要前后加空格，否则会提示command找不到 if [ -z $pid ];then echo &quot;&quot; echo &quot;Service $&#123;JAR_NAME&#125; is not running!&quot; echo &quot;&quot; else echo &quot;&quot; echo &quot;Service $&#123;JAR_NAME&#125; is running. It&#x27;s pid=$&#123;pid&#125;&quot; echo &quot;&quot; fi&#125; # 重启方法restart() &#123; echo &quot;&quot; echo &quot;.............................Restarting..............................&quot; echo &quot;.....................................................................&quot; # 重新获取一下pid，因为其它操作如start会导致pid的状态更新 pid=`ps -ef | grep java | grep $JAR_NAME | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27;` # -z 表示如果$pid为空时执行。 注意：每个命令和变量之间一定要前后加空格，否则会提示command找不到 if [ ! -z $pid ]; then kill -9 $pid fi start echo &quot;....................Restart successfully！...........................&quot;&#125; # 根据输入参数执行对应方法，不输入则执行tips提示方法case &quot;$&#123;PARAMETER&#125;&quot; in &quot;start&quot;) start ;; &quot;stop&quot;) stop ;; &quot;status&quot;) status ;; &quot;restart&quot;) restart ;; *) tips ;;esac 执行方式在脚本目录执行 1sh start.sh start（启动参数[start|stop|restart|status]） &#x2F;use&#x2F;local&#x2F;demo&#x2F;xxxx.jar(jar包的位置名称) &#x2F;user&#x2F;var&#x2F;demo&#x2F;XXXX.log（这个是项目配置的日志地址）","categories":[{"name":"脚本语言","slug":"脚本语言","permalink":"https://vincentxin-scott.github.io/categories/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://vincentxin-scott.github.io/tags/shell/"}]},{"title":"微信小程序获取公众号授权","slug":"uni-app/微信小程序获取公众号授权","date":"2020-05-18T03:36:05.632Z","updated":"2020-05-18T09:03:24.538Z","comments":true,"path":"2020/05/18/uni-app/微信小程序获取公众号授权/","link":"","permalink":"https://vincentxin-scott.github.io/2020/05/18/uni-app/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E8%8E%B7%E5%8F%96%E5%85%AC%E4%BC%97%E5%8F%B7%E6%8E%88%E6%9D%83/","excerpt":"","text":"需求分析微信小程序需要给用户（单个或多个）推送业务消息。 没有支付业务（不能用服务通知） 不能有数量限制（根据业务需求消息数量不少） 微信公众号有消息模版可以给用户推送消息需要公众号关联小程序(互相跳转) 如何解决小程序用户于公众号用户匹配通过UnionID来实现小程序和公众号openId关联。 用户关注公众号，直接持久化用户unionId和openId。 通过微信开发的api同步公众号关注用户信息。 在小程序中只需要获取unionId就可以找到对应的公众号openId，进行消息发送。 通过在小程序中获取微信公众号的code 后台解析微信公众号的code，获取openId，和小程序的openId及账号信息进行关联。 主要讨论在小程序中如何获取公众号code 使用小程序的 web-view组件，打开H5公众号授权页面。123456789101112131415161718&lt;template&gt; &lt;view&gt; &lt;web-view :src=&#x27;src_url&#x27;&gt;&lt;/web-view&gt; &lt;/view&gt;&lt;/template&gt;&lt;script&gt; export default &#123; data() &#123; return &#123; src_url: &#x27;https://XXXXXXXXXXXXXXXX&#x27;, &#125; &#125; &#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; H5页面部署在服务器上，小程序跳转当前页面后，直接访问微信公众号进行授权，微信授权完成后返回当前页面，页面解析授权是否完成，授权成功后跳转回小程序的登录页面。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;微信授权中&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt;&lt;/div&gt;&lt;!-- 微信jssdk --&gt;&lt;script src=&quot;https://res.wx.qq.com/open/js/jweixin-1.3.2.js&quot;&gt;&lt;/script&gt;&lt;script&gt; function getQueryVariable(variable) &#123; var query = window.location.search.substring(1); var vars = query.split(&quot;&amp;&quot;); for (var i = 0; i &lt; vars.length; i++) &#123; var pair = vars[i].split(&quot;=&quot;); if (pair[0] == variable) &#123; return pair[1]; &#125; &#125; return (false); &#125; var wxcode = getQueryVariable(&quot;code&quot;); let httpUrl = &#x27;https://XXXXXXXXXXXXXXXXXXXXXX&#x27;; if (wxcode) &#123; //console.log(wxcode); try &#123; wx.miniProgram.redirectTo(&#123; url: &#x27;/pages/rn-login/rn-wxlogin?code=&#x27; + wxcode, &#125;) &#125; catch (e) &#123; wx.miniProgram.redirectTo(&#123; url: &#x27;/pages/rn-login/rn-wxlogin?code=&#x27; + wxcode, &#125;) &#125; &#125; else &#123; try &#123; var url = &#x27;https://open.weixin.qq.com/connect/oauth2/authorize?appid=&#x27; + &quot;XXXXXXXXXXX&quot; + &#x27;&amp;redirect_uri=&#x27; + httpUrl + &#x27;&amp;response_type=code&#x27; + &#x27;&amp;scope=snsapi_base&#x27; + &#x27;&amp;state=STATE#wechat_redirect&#x27;; window.location.href = url; &#125; catch (e) &#123; var url = &#x27;https://open.weixin.qq.com/connect/oauth2/authorize?appid=&#x27; + &quot;XXXXXXXXXXXXXXXX&quot; + &#x27;&amp;redirect_uri=&#x27; + httpUrl + &#x27;&amp;response_type=code&#x27; + &#x27;&amp;scope=snsapi_base&#x27; + &#x27;&amp;state=STATE#wechat_redirect&#x27;; window.location.href = url; &#125; &#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 小程序登录页面通过onload来监听授权参数信息并获得123456789101112131415161718192021222324onLoad: function(option) &#123; try &#123; if (option &amp;&amp; option.code) &#123; getApp().globalData.isFristGetCode = true; uni.reLaunch(&#123; url: &#x27;./rn-login?code=&#x27; + option.code &#125;); &#125; //启动一个计数器,检测5秒后时候获取到code setTimeout(function() &#123; //检测获取到code没有 if (!getApp().globalData.isFristGetCode) &#123; uni.reLaunch(&#123; url: &#x27;./rn-login&#x27; &#125;); &#125; &#125;, 5000); &#125; catch (e) &#123; //TODO handle the exception uni.reLaunch(&#123; url: &#x27;./rn-login&#x27; &#125;); &#125;&#125;","categories":[{"name":"小程序","slug":"小程序","permalink":"https://vincentxin-scott.github.io/categories/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"}],"tags":[{"name":"微信公众号，微信小程序","slug":"微信公众号，微信小程序","permalink":"https://vincentxin-scott.github.io/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%EF%BC%8C%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/"}]},{"title":"05｜Docker-Compose","slug":"Docker/docker | 05Docker-compose","date":"2020-04-25T02:49:46.943Z","updated":"2020-04-28T07:40:50.198Z","comments":true,"path":"2020/04/25/Docker/docker | 05Docker-compose/","link":"","permalink":"https://vincentxin-scott.github.io/2020/04/25/Docker/docker%20|%2005Docker-compose/","excerpt":"","text":"安装docker-compose前提先安装docker 参考前面的文档。 从github上下载docker-compose二进制文件安装1234# github 下载sudo curl -L https://github.com/docker/compose/releases/download/1.16.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose# daocloud 下载（速度快）sudo curl -L https://get.daocloud.io/docker/compose/releases/download/1.25.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose 添加权限1sudo chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-compose pip安装1sudo pip install docker-compose 验证测试结果123$ docker-compose --version docker-compose version 1.25.5, build 8a1c60f6 删除docker-compose1sudo rm /usr/local/bin/docker-compose 创建Docker-compose.yml文件","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://vincentxin-scott.github.io/categories/DevOps/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://vincentxin-scott.github.io/tags/Docker/"}]},{"title":"01｜ORACLE基础篇-建表并主键自增","slug":"数据库/ORACLE/oracle｜01建表并主键自增","date":"2020-04-20T08:17:10.397Z","updated":"2020-04-26T09:46:46.265Z","comments":true,"path":"2020/04/20/数据库/ORACLE/oracle｜01建表并主键自增/","link":"","permalink":"https://vincentxin-scott.github.io/2020/04/20/%E6%95%B0%E6%8D%AE%E5%BA%93/ORACLE/oracle%EF%BD%9C01%E5%BB%BA%E8%A1%A8%E5%B9%B6%E4%B8%BB%E9%94%AE%E8%87%AA%E5%A2%9E/","excerpt":"","text":"建表1234567CREATE TABLE &quot;TSMIS&quot;.&quot;TB_USER_WECHAT_BINDING&quot; ( &quot;USER_ID&quot; NUMBER(16,0) NOT NULL ENABLE, &quot;WX_OPENID&quot; VARCHAR2(64), &quot;CREATE_TIME&quot; DATE DEFAULT sysdate, &quot;BINDING_TIME&quot; DATE DEFAULT sysdate, &quot;STATE&quot; NUMBER(1,0) DEFAULT 0, CONSTRAINT &quot;PK_TB_USER_WECHAT_BINDING&quot; PRIMARY KEY (&quot;USER_ID&quot;)); 建立自增 SEQUENCE123456CREATE SEQUENCE SEQ_TB_USER_WECHAT_BINDING INCREMENT BY 1 -- 每次加几个 START WITH 1 -- 从1开始计数 NOMAXVALUE -- 不设置最大值 NOCYCLE -- 一直累加，不循环 NOCACHE; -- 不建缓冲区 查看已经建立的sequence1select * from user_sequences; 删除已经建立的sequence1DROP SEQUENCE SEQ_TB_USER_WECHAT_BINDING; id设置默认值（触发方式的一种）1alter table TB_USER_WECHAT_BINDING modify USER_ID default &quot;TSMIS&quot;.&quot;SEQ_TB_USER_WECHAT_BINDING&quot;.&quot;NEXTVAL&quot;; 触发器(触发方式的另一种)","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"ORACLE","slug":"ORACLE","permalink":"https://vincentxin-scott.github.io/tags/ORACLE/"}]},{"title":"01｜SpringBoot整合Activiti Modeler","slug":"工作流/01｜先运行起来在说","date":"2020-04-17T07:56:10.841Z","updated":"2020-04-17T09:50:59.157Z","comments":true,"path":"2020/04/17/工作流/01｜先运行起来在说/","link":"","permalink":"https://vincentxin-scott.github.io/2020/04/17/%E5%B7%A5%E4%BD%9C%E6%B5%81/01%EF%BD%9C%E5%85%88%E8%BF%90%E8%A1%8C%E8%B5%B7%E6%9D%A5%E5%9C%A8%E8%AF%B4/","excerpt":"","text":"版本说明： Spring boot: 2.1.4.RELEASE activiti: 6.0.0 Mybatis-plus: 3.3.0","categories":[{"name":"工作流","slug":"工作流","permalink":"https://vincentxin-scott.github.io/categories/%E5%B7%A5%E4%BD%9C%E6%B5%81/"}],"tags":[{"name":"Activiti","slug":"Activiti","permalink":"https://vincentxin-scott.github.io/tags/Activiti/"}]},{"title":"SpringSecurity介绍","slug":"SpringSecurity/01｜SpringSecurity介绍","date":"2020-03-20T14:58:00.476Z","updated":"2020-03-21T03:07:14.557Z","comments":true,"path":"2020/03/20/SpringSecurity/01｜SpringSecurity介绍/","link":"","permalink":"https://vincentxin-scott.github.io/2020/03/20/SpringSecurity/01%EF%BD%9CSpringSecurity%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"Spring Security jar包介绍spring-security-core.jar核心包，任何Spring Security 安全功能都包含此包。 spring-security-web.jarweb功能必备，包含过滤器和相关的Web安全基础结构代码。 spring-security-config.jar用于解析xml配置文件，用到Spring Security的xml配置文件的就要用到此包。 spring-security-taglibs.jarSpring Security 提供的动态标签库，jsp页面可以用。 注意：后面两个包包含了 前面所有的包。 Spring Security 过滤器介绍","categories":[{"name":"Spring","slug":"Spring","permalink":"https://vincentxin-scott.github.io/categories/Spring/"}],"tags":[{"name":"SpringSecurity","slug":"SpringSecurity","permalink":"https://vincentxin-scott.github.io/tags/SpringSecurity/"}]},{"title":"在Linux中查看JDK安装路径","slug":"Linux/Linux中查看JDK安装路径","date":"2020-03-18T06:04:55.415Z","updated":"2020-03-18T06:50:17.680Z","comments":true,"path":"2020/03/18/Linux/Linux中查看JDK安装路径/","link":"","permalink":"https://vincentxin-scott.github.io/2020/03/18/Linux/Linux%E4%B8%AD%E6%9F%A5%E7%9C%8BJDK%E5%AE%89%E8%A3%85%E8%B7%AF%E5%BE%84/","excerpt":"","text":"which java/usr/bin/java ls -lrt /usr/bin/javalrwxrwxrwx. 1 root root 22 3月 31 20:07 /usr/bin/java -&gt; /etc/alternatives/java ls -lrt /etc/alternatives/javalrwxrwxrwx. 1 root root 71 3月 31 20:07 /etc/alternatives/java -&gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-7.b13.el7.x86_64/jre/bin/java cd /usr/lib/jvm/OK","categories":[{"name":"Linux","slug":"Linux","permalink":"https://vincentxin-scott.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://vincentxin-scott.github.io/tags/Linux/"}]},{"title":"在Linux中配置ssh密钥","slug":"杂记随笔/Linux中配置ssh密钥","date":"2020-03-18T05:23:48.803Z","updated":"2020-03-18T06:04:30.599Z","comments":true,"path":"2020/03/18/杂记随笔/Linux中配置ssh密钥/","link":"","permalink":"https://vincentxin-scott.github.io/2020/03/18/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/Linux%E4%B8%AD%E9%85%8D%E7%BD%AEssh%E5%AF%86%E9%92%A5/","excerpt":"","text":"ssh密钥作用在Linux中配置ssh密钥,在Git中使用SSH协议访问Github，使用 SSH 协议, 您可以连接并验证远程服务器和服务。在每次访问时连接到服务而不提供用户名或密码。 第一步：检查是否存在SSH密钥1ls -al ~/.ssh 如果不存在就会显示无法访问 第二步：生成SSH key输入指令：1$ ssh-keygen -t rsa -C &quot;your_email@example.com&quot; 字母C一定要大写 Enter file in which to save the key (~/.ssh/id_rsa): 提示文件存放位置，一般情况下就是存储在当前用户下.ssh文件夹下面。【直接回车】。 Enter passphrase (empty for no passphrase)：提示输入密码 Enter same passphrase again: 输入确认密码 此时可以在/～/.ssh中看到 id_rsa(私钥) 和id_rsa_pub（公钥） 第三步：连接gitlab、github、gitee 粘贴id_rsa_pub公钥中的内容，cat、vim或者其他工具直接粘贴出来。 github网站上，右上角头像，点击settings==》SSH and GPC keys ==》new SSH key。粘贴公钥，确定完成。 测试 ssh -T &#103;&#105;&#x74;&#x40;&#103;&#105;&#x74;&#104;&#x75;&#98;&#46;&#x63;&#x6f;&#x6d; 其他类似。 实现远程服务器免密登录连接第一步：修改远程服务器sshd服务的配置文件vim /etc/ssh/sshd_config修改： 123RSAAuthentication yes # RSA认证PubkeyAuthentication yes # 公钥认证AuthorizedKeysFile .ssh/authorized_keys # 公钥认证文件路径 之后重启sshd systemctl restart sshd 第二部 将之前我们生成的公钥加入到服务器.ssh/authorized_keys文件中依旧是复制粘贴，vim保存退出，搞定。 配置本地config文件。12345Host vps # 一个便于你区别这是哪台机器的名字 HostName xx.xx.xx.xx # 目的机器的ip User username # ssh登陆时候的用户名 Port 22 # ssh所使用的端口，默认是22 IdentityFile /~/.ssh/id_rsa # 对应服务器公钥的本地私钥文件路径 注意：～是指当前用户下地址，绝对路径自己pwd就可以看到了。","categories":[{"name":"杂记随笔","slug":"杂记随笔","permalink":"https://vincentxin-scott.github.io/categories/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"解决问题","slug":"解决问题","permalink":"https://vincentxin-scott.github.io/tags/%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/"}]},{"title":"Navicat 导入数据报错 --- 1153 - Got a packet bigger than 'max_allowed_packet' bytes","slug":"数据库/MySQL/mysql报错｜1153-max_allowed_packet问题处理","date":"2020-03-16T15:31:24.999Z","updated":"2020-04-23T01:23:36.776Z","comments":true,"path":"2020/03/16/数据库/MySQL/mysql报错｜1153-max_allowed_packet问题处理/","link":"","permalink":"https://vincentxin-scott.github.io/2020/03/16/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%E6%8A%A5%E9%94%99%EF%BD%9C1153-max_allowed_packet%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86/","excerpt":"","text":"以MariaDB为例在linux或mac中在/etc/my.cnf 或者 /etc/my.cnf.d/server.cnf中修改一下内容 123[mysqld]max_allowed_packet = 10M 之后重启mysql 1systemctl restart mariadb","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL(MariaDB)报错处理","slug":"MySQL-MariaDB-报错处理","permalink":"https://vincentxin-scott.github.io/tags/MySQL-MariaDB-%E6%8A%A5%E9%94%99%E5%A4%84%E7%90%86/"}]},{"title":"MySQL实践篇-MySQL是怎么保证数据不丢的？","slug":"数据库/MySQL/mysql｜19MySQL是怎么保证数据不丢的","date":"2020-03-12T15:07:14.138Z","updated":"2020-04-23T01:23:36.862Z","comments":true,"path":"2020/03/12/数据库/MySQL/mysql｜19MySQL是怎么保证数据不丢的/","link":"","permalink":"https://vincentxin-scott.github.io/2020/03/12/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C19MySQL%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E7%9A%84/","excerpt":"","text":"MySQL是怎么保证数据不丢的？之前介绍了WAL机制 write ahead log 得到结论是：只要redo log和binlog保证持久化到磁盘，就能确保MySQL异常重启后，数据可以恢复。 redo log的写入流程是怎样的，如何确保redo log 真实地写入了磁盘。 binlog的写入机制其实，binlog的写入逻辑比较简单：事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。 一个事务的binlog是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就设计到了binlog cache的保存问题。 系统给binlog cache分配到了一片内存，每个线程一个，参数binlog_cache_size用于控制单个线程内binlog cache 所占用内存的大小。如果超过这个参数规定的大小，就要暂存到磁盘。 事务提交的时候，执行器把binlog cache里的完整事务写入到binlog中，并清空binlog cache。 可以看到，每个线程有自己binlog cache，但是共同一份binlog文件。 图中write，指的就是把日志写入到文件系统的page cache，并没有把数据持久化到磁盘，所以速度比较快。 图中的fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为fsync才占磁盘的IOPS。 write和fsync的时机，是由参数sync_binlog控制的： sync_binlog=0的时候，表示每次提交事务都只write，不fsync； sync_binlog = 1的时候，表示每次提交事务都会执行fsync； sync_binlog=N(N&gt;1)的时候，表示每次提交事务都write，但积累N个事务后才fsync。 因此，在出现IO瓶颈的场景里，将sync_binlog设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成0，比较常见的是将其设置为100～1000中的某个数值。 但是，将sync_binlog设置为N，对饮的风险是：如果主机发生异常重启，会丢失最近N个事务的binlog日志。 redo log的写入机制事务在执行过程中，生成的redo log是要先写到redo log buffer的。 如果事务执行期间MySQL发生异常重启，那这部分日志就丢了。由于事务没有提交，所以这时日志也不会有损失。 那么另外一个问题，事务没有提交的时候，redo log buffer中的部分日志有没有可能被持久化到磁盘呢？ 这个问题，要从redo log可能存在的三种状态说起。这三种状态，对应的就是图2中的三个颜色快。 这三种状态分别是： 存在redo log buffer中，物理上是在MySQL进程内存中，就是图中的红色部分； 写到磁盘（write），但是没有持久化(sync)，物理上是在文件系统的page cache里面，也就是黄色的部分； 持久化到磁盘，对应的hard disk，也就是图中的绿色部分。 日志写到redo log buffer是很快的，write到page cache也差不多，但是持久化到磁盘的速度就慢多了。 为了控制redo log的写入策略，InnoDB提供了innodb_flush_log_at_trx_commit参数，他有三种可能的取值。 设置为0的时候，表示每次事务提交都只是把redo log留在redo log buffer中; 设置为1的时候，表示每次事务提交时都将redo log直接持久化到磁盘； 设置为2的时候，表示每次事务提交时都只是把redo log写到page cache。 InnoDB有一个后台线程,每隔一秒，就会把redo log buffer中的日志，调用wirte写到文件系统的page cache，然后调用fsync持久化到磁盘。 注意，事务执行中间过程的redo log也是直接写在redo log buffer中的，这些redo log也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的redo log，也是可能已经持久化到磁盘的。 时间上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的redo log写入到磁盘中。 一种是，redo log buffer占用的空间即将达到innodb_log_buffer_size一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是write，而没有调用fsync，也就是只留在了文件系统的page cache。 另一种，并行的事务提交的时候，顺带将这个事务的redo log buffer持久化到磁盘。 假设一个事务A执行到一半，已经写了一些redo log到buffer中，这时候有另外一个线程的事务B提交，如果innodb_flush_log_at_trx_commit设置的是1，那么按照这个参数的逻辑，事务B要把redo log buffer里的日志全部持久化到磁盘。这时候，就会带上事务A在redo log buffer里的日志一起持久化到磁盘。 这里需要说明的是，介绍的两阶段提交的时候说过，时序上redo log先prepare，再写binlog，最后再把redo log commit。 如果把innodb_flush_log_at_trx_commit设置成1，那么redo log在prepare阶段就要持久化一次，因为有一点奔溃恢复逻辑是要依赖于prepare的redo log，再加上binlog来恢复。 每秒一次后台轮询刷盘，再加上奔溃恢复这个逻辑，InnoDB就认为redo log在commit的时候就不需要fsync了，只会write到这个文件系统的page cache中就够了。 通常我们说MySQL的双1配置，指的就是sync_binlog和innodb_flush_log_at_trx_commit都设置成1。也就说，一个事务完整提交前，需要等待两次刷盘，一次是redo log(prepare),一次是binlog。 这意味着MySQL看到TPS是每秒两万的话，每秒就会写四万次磁盘。但是，用测试工具测试出来，磁盘能力也就是两万左右，怎么能实现两万的TPS？ 用到组提交(group commit)机制了。首先介绍日志逻辑序列号(log sequence number,LSN)的概念。LSN是单调递增的，用来对应redo log的一个个写入点。每次写入的长度为length的redo log，LSN的值就会加上length。 LSN也会写到InnoDB的数据页中，来确保数据页不会被多次执行重复的redo log。关于LSN 和redo log、checkpoint的关系，后面会详细展开。 三个并发事务(trx1,trx2,trx3)在prepare阶段，都写完redo log buffer，持久化到磁盘的过程，对应的LSN分别是50、120和160。 trx1是第一个到达的，会被选为这个组的leader; 等trx1要开始写盘的时候，这个组里面已经有三个事务，这时候LSN变成了160； trx1去写盘的时候，带的就是LSN=160，因此等trx1返回时，所有LSN小于等于160的redo log，都已经被持久化到磁盘了； 这时候trx2和trx3就可以直接返回了。 所以，一次组提交里面，组员越多，节约磁盘IOPS的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。 在并发更新场景下，第一事务写完redo log buffer以后，接下来这个fsync越晚调用，组员可能越多，节约IOPS的效果就越好。 为了让一次fsync带的组员更多，MySQL有一个有趣的优化：拖时间。 MySQL为了让组提交的效果更好，把redo log做fsync的时间拖到了步骤1之后，也就是说。 这样一来，binlog也可以组提交了。第4步binlog fsync到磁盘时，如果有多个事务的binlog已经写完了，也时一起持久化的，这样可以减少IOPS的消耗。 不过通常情况下第3步执行得会很快，所以binlog的write和fsync间的间隔时间短，导致能集合到一起持久化的binlog比较少，因此binlog的组提交的效果通常不如redo log的效果那么好。 如果你想提升binlog组提交的效果，可以通过设置binlog_group_commit_sync_delay和binlog_group_commit_sync_no_delay_count来实现。 binlog_group_commit_sync_delay参数，便是延迟多少微妙后才调用fsync； binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync。 这个两个条件是或的关系，也就说只要满足条件就会调用fsync。 所以当binlog_group_commit_sync_delay设置为0的时候，binglog_group_commit_sync_no_delay_count也无效了。 WAL机制主要得益于两个方面：1.redo log和binlog都是顺序写，磁盘的顺序写比随机写速度快；2. 组提交机制，可以大幅度降低磁盘IOPS消耗。 如果你的MySQL现在出现了性能瓶颈，而且瓶颈在IO上，可以通过哪些方法来提升性能呢？ 设置binlog_group_commit_sync_delay和binlog_group_commit_sync_no_delay_count参数，减少binlog的写盘次数。这个方法是基于“额外来的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。 将sync_binlog设置为大于1的值（比较常见的是100～1000）。这样做的风险是，主机down之后会丢失binlog日志。 将innodb_flush_log_at_trx_commit设置为2。这样做的风险是，主机down的时候会丢失数据。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL实践篇-MySQL有哪些“饮鸩止渴”提高性能的方法？","slug":"数据库/MySQL/mysql｜18MySQL有哪些“饮鸩止渴”提高性能的方法","date":"2020-02-25T03:38:10.413Z","updated":"2020-04-23T01:23:36.776Z","comments":true,"path":"2020/02/25/数据库/MySQL/mysql｜18MySQL有哪些“饮鸩止渴”提高性能的方法/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/25/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C18MySQL%E6%9C%89%E5%93%AA%E4%BA%9B%E2%80%9C%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E2%80%9D%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E6%96%B9%E6%B3%95/","excerpt":"","text":"MySQL实践篇-MySQL有哪些“饮鸩止渴”提高性能的方法？短连接风暴正常的短连接模式就是连接到数据库后，执行很少的SQL语句断开，下次需要的时候再重新连，如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。 MySQL建立连接的过程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。 在数据库压力很小的时候，这些额外的成本并不明显。 但是，短连接模型存在一个风险，就是一旦数据库处理的慢一些，连接数就会暴涨。 max_connections参数，用来控制一个MySQL实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。对于被拒绝连接的请求来说，从业务交付看就是数据库不可用。 在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长。这时，再有新建连接的话，就可能会超过max_connections的限制。 碰到这种情况时，一个比较自然的想法，就是调高max_connections的值。但这样做是有风险的。因为设计max_connections这个参数的目的是想保护MySQL，如果我们把它改得太大，让更多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源消耗在权限验证等逻辑上，如果可能是适得其反，已经连接的线程拿不到CPU资源去执行业务的SQL的请求。 第一种方法：先处理掉哪些站着连接但是不工作的线程。max_connections的计算，不是看谁在running，是只要连着就占用一个计数位置。对于哪些不需要保持的连接，我们可以通过kill connection 主动踢掉。这个行为跟事先设置wait_timeout的效果是一样的。设置wait_timeout参数表示的是，一个线程空闲wait_timeout这么多秒之后，就会被MySQL直接断开连接。 但是需要注意，在show processlist的结果里，踢掉显示为sleep的线程，可能是有损的。 上面这个例子里，如果断开sessionA的连接，因为这个时候sessionA还没有提交，所以MySQL只能按照回滚事务来处理；而断开sessionB的连接，就没什么大影响。所以，如果按照优先级来说，你应该优先断开像sessionB这样的事务外空闲的连接 但是，怎么判断哪些是事务外的空闲呢？sessionC在T时刻之后的30秒执行show processlist，看到的结果是这样的。 图中id=4 和id=5的两回话都是Sleep状态。而要看事务具体状态的话，你可以查information_schema库innodb_trx表。 这个结果里，trx_mysql_thread_id=4,表示id=4的线程还处在事务中。 因此，如果是连接数过多，可以优先判断事务外空闲太久的连接；如果这样还不够，在考虑断开事务内空闲太久的连接。 从服务端断开连接使用的是kill connection + id 的命令，一个客户端处于sleep状态时，它的连接被服务端主动断开后，这个库护短并不会马上知道。知道客户端子啊发起下一个请求的时候，才会收到这样的报错”ERROR 2013 (HY000):Lost connection to MySQL server during query”。 从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端开上去，“MySQL一直没恢复”。 第二种方法：减少连接过程的消耗。有的业务代码会在短时间内先大量申请数据库连接备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。 跳过权限验证的方法是：重启数据库，并使用-skip-grant-tables参数启动。这样，整个MySQL会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。 但是这种方法特别符合标题说的“饮鸩止渴”，风险极高，是特别不建议使用的方案。尤其你的库外网可以访问的话，就更不能这么做了。 在MySQL 8.0版本里，如果你启动-skip-grant-tables参数，MySQL还会默认把–skip-networking参数打开，表示这时候数据库只能被本地的客户端连接。 除了短连接数暴增可能会带来性能问题外，实际上，我们线上碰到更多的是查询或者更新语句导致的性能问题。其中，查询问题比较典型的有两类，一类是由新出现的慢查询导致的，一类是由QPS突增导致的。而关于更新语句导致的性能问题，后面会介绍。 慢查询性能问题在MySQL中，会引发性能问题的慢查询，大体有以下三种可能： 索引没有设计好； SQL语句没写好； MySQL选错了索引； 接下来，具体分析一下这三种可能,以及应对的解决方案。 导致慢查询的第一种可能是，索引没有设计好。 导致慢查询的第一种可能是，索引没有设计好这种场景一般就是通过紧急创建索引解决。MySQL5.6版本以后，创建索引都支持Online DDL了，对于这种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行alter table语句。 比较理想的是能在备库执行。假设你现在的服务是一主一备，主库A、备库B，这个方案的大致流程是这样： 在备库B执行set sql_log_bin = off,也就是不写binlog，然后执行alter table 语句加上索引； 执行猪备切换； 这时候主库是B，备库是A。在A上执行set sql_log_bin = off，然后执行alter table 语句加上索引。 这个一个“古老”的DDL方案。平时的做变更的时候，你应该考虑类似gh-ost这样的方案，更加稳妥。但是在需要紧急处理时，上面这个方案的效率更高。 导致慢查询的第二种可能是，语句没写好。这时，我们可以通过改写SQL语句处理。MySQL5.7提供了query_rewrite功能，可以把输入的一种语句改写成另外一种模式。 比如，语句备错误的写成了select * from t where id+1 = 10000，你可以通过下面的方式，增加以恶搞语句改写规则。 1234 insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values (&quot;select * from t where id + 1 = ?&quot;, &quot;select * from t where id = ? - 1&quot;, &quot;db1&quot;);call query_rewrite.flush_rewrite_rules(); 这里，call query_rewrite.flush_rewrite_rules()这个存储过程，是让插入的新规则生效，也就是我们说的“查询重写”。 导致慢查询的第三种可能，就是碰上了我们在MySQL为什么会选错索引 中提到的情况，这个时候，应急方案就是给这个语句加上force index。同样的，使用查询重写功能，给原来的语句加上force index，也可以解决这个问题。 上面讨论的由慢查询导致性能问题的三种情况，实际上出现做多的是前两种，即：索引没设计好和语句没写好。而这两种情况，恰恰是完全可以避免的。 上线前，在测试环境，把慢查询日志(slow log)打开，并且把long_query_time设置成0，确保每个语句都会被记录入慢查询日志； 在测试表里插入模拟线上的数据，做一遍回归测试； 观察慢查询日志里每类语句的输出，特别留意Rows_examined字段是否与预期一致。 不要吝啬这段花在上线前的“额外”时间，因为这会帮你省下很多故障复盘的时间。 如果新增的SQL语句不多，手动跑一下就可以。而如果是新项目的话，或者是修改了原有项目的表结构设计，全量回归测试都是必要的。这时候，你需要工具帮你检查所有的sql语句的返回结果。可以使用开源工具pt-query-digest https://www.percona.com/doc/percona-toolkit/3.0/pt-query-digest.html QPS突增问题有时候由于业务突然出现高峰，或者应用程序bug，导致某个语句的QPS突然暴涨，也可能导致MySQL压力过大，影响服务。 一类情况是，由一个新功能的bug导致的，当然，最理想的情况是让业务把这个功能下掉，服务自然就会恢复。 一种是由全新的业务的bug导致的。假设你的DB运维是比较规范的，也就是生活很好白名单是一个一个加的。这个种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没有那么快，那么就可以从数据库端直接把白名单去掉。 如果这个新功能使用的单独的数据库用户，那么管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的QPS就会变成0。 如果这个新增的功能跟主体功能都是部署在一起的，那么只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的SQL语句直接重写成“select 1” 返回。 当然，这个操作的风险很高，需要特别细致。他可能存在两个副作用： 如果别的功能里面也用到这个SQL语句模版，会误伤； 很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这个语句以select1 的结果返回的话，可能会导致后面的业务逻辑一起失败。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL实践篇-为什么只改一行语句，锁那么多？","slug":"数据库/MySQL/mysql｜17为什么改一行语句，锁那么多","date":"2020-02-16T12:44:22.432Z","updated":"2020-04-23T01:23:36.776Z","comments":true,"path":"2020/02/16/数据库/MySQL/mysql｜17为什么改一行语句，锁那么多/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/16/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C17%E4%B8%BA%E4%BB%80%E4%B9%88%E6%94%B9%E4%B8%80%E8%A1%8C%E8%AF%AD%E5%8F%A5%EF%BC%8C%E9%94%81%E9%82%A3%E4%B9%88%E5%A4%9A/","excerpt":"","text":"为什么只改一行语句，锁那么多？主要说明 语句的加锁规则。 MySQL后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即5.X系列&lt;=5.7.24，8.0系列&lt;=8.0.13。 因为间隙锁在可重复读隔离级别下才有效，所以以下的描述中，除了特别说明，默认是可重复读隔离级别。 加锁规则里面，包含了两个“原则”、“两个优化”和一个“bug” 原则1:加锁的基本单位是next-key lock。next-key lock是前开后闭区间。 原则2:查找过程中访问到的对象才会加锁。 优化1:索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。 优化2:索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。 一个bug:唯一索引上的范围查询会访问到不满足条件的第一个值为止。 1234567891011CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25); 案例一:等值查询间隙锁 由于表t中没有id=7的记录，所以用上面提到的加锁规则判断一下的话: 根据原则1，加锁的单位是next-key lock，sessionA加锁的范围是（5，10]; 同时根据优化2，这是一个等值查询(id=7)，而id=10不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是(5,10) 所以，sessionB要往这个间隙里面插入id=8的记录会被锁住，但是sessionC修改的id=10这行是可以的。 案例二：非唯一索引等值锁关于覆盖索引上的锁： 看到这个例子，有一种“该锁的不锁，不该锁的乱锁”的感觉？ 这里sessionA给索引c上的c=5的这行加上读锁。 根据原则1，加锁的单位是next-key lock，因此会给(0,5]加上next-key lock。 要注意c是普通索引，因此仅访问c=5这条记录是不能马上停下来的，需要向右遍历，查到c=10才放弃。根据原则2，访问到的都要加锁，因此要给(5,10]加上next-key lock。 但是同时这个符合优化2:等值判断，向右遍历，最后一个值不满足c=5这个等值条件，因此退化成间隙锁(5,10). 根据原则2，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么sessionB的update语句可以执行完成。 但sessionC要插入一个(7,7,7)的记录，就会被sessionA的间隙锁(5,10)锁住。 需要注意，这个例子中，lock in share mode只锁覆盖索引，但是如果是for update就不一样了。执行for update时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。 这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用lock in share mode来给行加读锁避免数据被更新的话，就必须绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。 案例三:主键索引范围锁关于范围查询 思考：下面两条查询语句，加锁范围相同吗？ 123mysql&gt; select * from t where id=10 for update;mysql&gt; select * from t where id&gt;=10 and id&lt;11 for update; 逻辑上，这两条查询语句肯定是等价的，但是它们的加锁规则不太一样。 开始执行的时候，要找到第一个id=10的行，因此本该是next-key lock(5,10]。根据优化1，主键id上的等值条件，退化成行锁，只加了id=10这一行的行锁。 范围查找就往后继续找，找到id=15这行停下来，因此需要加next-key lock(10,15]。 所以sessionA这时候加锁的范围就是主键索引上，行锁id=10和next-key lock(10,15]。这样，sessionB和sessionC的结果就容易理解了。 这里需要注意，首次sessionA定位查找id=10的行的时候，是当作等值查询来判断的，而向右扫描到id=15的时候，用的是范围查询判断。 案例四:非唯一索引范围锁 这次sessionA用字段c来判断。加锁规则跟案例三唯一的不同是:在第一次用c=10定位记录的时候，索引c上加了(5,10]这个next-key lock后，由于索引c是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终sessionA加的锁是，索引c的(5,10]和(10,15]这两个next-key lock。 这里扫描到c=15才能停止扫描，是合理的，因为InnoDB要扫到c=15，才知道不需要就绪往后找了。 案例五:唯一索引范围锁bug sessionA是一个范围查询，按照原则1的话，应该是索引id上只加(10,15]这个next-key lock，并且因为id是唯一键，所以循环判断到id15这一行就应该停止。 但是现实上，InnoDB会往前扫到第一个不满足条件为止，也就是id=20.而且由于这是范围扫描，因此索引id上的(15,20]这个next-key lock也会被锁上。 所以看到了，sessionB要更新id=20这一行，是会被锁住的。同样的，sessionC要插入id=16的行，也会被锁住的。 照理说，这里锁住id=20这行的行为，其实是没有必要的。因为扫描到id=15，就可以确定不用再往后找了。但实现上还是这么做了，因此认为这是个bug。 案例六:非唯一索引上存在“等值”的例子为了更好地说明“间隙”这个概念。这里，我给表插入一条新记录。 12mysql&gt; insert into t values(30,10,30); 新插入的这一行c=10，也就是说现在表里有两个c=10的行。那么，这时候索引c上的间隙时候什么状态呢？由于非唯一索引上包含主键的值，所以是不可能存在“相同”的两行的。 可以看到，虽然有两个c=10，但是它们的主键值id是不同的(分别是10和30)，因此这两个c=10的记录之间，也是有间隙的。 用delete语句来验证。注意：delete语句加锁的逻辑，其实跟select…for update是类似的，也就是在文章开头总结的两个原则两个优化和一个bug。 这是sessionA在遍历的时候，先访问第一个c=10的记录，根据规则1，这里加的是(c=5,id=5)到(c=10，id=10)这个next-key lock。 然后，sessionA向右查找，直到碰到(c=15,id=15)这一行，循环才结束。根据优化2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成(c=10,id=10)到(c=15，id=15)的间隙锁。 也就说这个delete语句在索引c上的加锁范围，就是下面蓝色的区域。 这个蓝色区域左右两边都是虚线，表示开区间。 案例七：limit语句加锁这个例子里，sessionA的delete语句加了limit2。你知道表t里c=10的记录其实i之i有两条，因此加不加limit2，删除的效果都是一样的，但是加锁的效果却不同。可以看到，sessionB的insert语句执行通过了，跟案例六的结果不同。 这是因为，案例七的delete语句明确加了limit2的限制，因此在遍历到(c=10,id=30)这一行之后，满足条件的语句已经有两条，循环就结束了。 因此，索引c上的加锁范围就变成了从(c=5,id=5)到(c=10,id=30)这个前开后闭区间。 可以看到，(c=10,id=30)之后的这个间隙并没有在加锁范围里，因此insert语句插入c=12是可以执行成功的。 这个例子对我们的指导意义：在删除数据的时候尽量加limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加搜的范围。 案例八：一个死锁的例子说明：next-key lock 实际上是间隙锁和行锁加起来的结果 sessionA启动事务后执行查询语句加lock in share mode，在索引c上加next-key lock(5,10]和(10,15)间隙锁； sessionB的update语句也要在索引c上加next-key lock (5,10],进入锁等待； 然后sessionA要插入一行(8,8,8)这一行，被sessionB的间隙锁锁住。由于出现了死锁，InnoDB 让sessionB回滚。 sessionB的next-key lock 不是没有申请成功吗？ 其实，sessionB的“加 next-key lock(5,10]”操作，实际上分成了两步，先是加(5,10)的间隙锁，加锁成功；然后加c=10的行锁，这时候才被锁住的。 也就说，我们在分析加锁规则的时候可以用next-key lock 来分析。但是要知道，具体执行的时候是要分成间隙锁和行锁两段来执行。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL实践篇-幻读是什么，幻读有什么问题","slug":"数据库/MySQL/mysql｜16幻读是什么，幻读有什么问题","date":"2020-02-12T15:00:59.409Z","updated":"2020-04-23T01:23:36.775Z","comments":true,"path":"2020/02/12/数据库/MySQL/mysql｜16幻读是什么，幻读有什么问题/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/12/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C16%E5%B9%BB%E8%AF%BB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%8C%E5%B9%BB%E8%AF%BB%E6%9C%89%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98/","excerpt":"","text":"幻读是什么，幻读有什么问题？🌰： 1234567891011CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25); 这个表除了主键id外，还有一个索引c，初始化语句在表中插入了6行数据。 问题：下列语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？ 1234begin;select * from t where d=5 for update;commit; 这个语句会命中d=5的这一行，对应的主键id=5，因此在select语句执行完成后，id=5这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会执行commit语句的时候释放。 由于字段d上没有索引，因此这条查询语句会做全表扫描，那么，其他被扫描到的，但是不满足条的5行记录上，会不会被加锁呢？ InnoDB的默认事务隔离级别是可重复读，所以我们都是在可重读读隔离级别下讨论问题。 幻读是什么？如果只在id=5这一行加锁，而其他行不加锁的话； 假设是以下场景： 可以看到sessionA里执行了三次查询，分别是Q1、Q2和Q3。它们的SQL语句相同，都是select * from t where d=5 for update。这个语句的意思就是，查所有d=5的行，而且使用的是当前读，并且加上了写锁。 Q1只返回id=5这一行； 在T2时刻，sessionB 把id=0这一行的d值改成了5，因此T3时刻Q2查出来的是id=0和id=5这两行。 在T4时刻，sessionC又插入一行(1,1,5)，因此T5时刻Q3查出来的是id=0、id=1和id=5这两行。 其中Q3读到id=1这一行的现象，被称为幻读。也就是说，幻读值的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。 对“幻读”做一个说明： 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的，因此，幻读在“当前读“才会出现。 上面sessionB的修改结果，被sessionA之后的select语句当作”当前读“看到，不能称为幻读。幻读仅专指”新插入的行“ 因为这个三个查询都是加入了for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且 sessionB和sessionC的两条语句，执行后就会提交，所以Q2和Q3就是应该看到和这个两个事务的操作效果，而且也看到了，这个跟事务的可见性规则并不矛盾。 幻读有什么问题？首先语义上：sessionA在T1时刻就声明了，“我要把所有d=5的行锁住,不准别的事务进行读写操作”。而实际上，这个语义被破坏了。 sessionB的第二条语句update t set c=5 where id=0，语义是“我把id=0、d=5这一行的c值，改成5”。 由于在T1时刻，sessionA还只是给id=5这一行加了行锁，并没有给id=0这行加上锁。因此，sessionB在T2时刻，是可以执行这两条update语句的。这样，就破坏了sessionA里Q1语句要锁住所有d=5的行的加锁声明。 sessionC也是一样的道理，对id=1这行的修改，也是破坏了Q1的加锁声明。 数据一致性问题。我们知道，锁的设计是为了保证数据的一致性。而这个一致性，不只是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。 为了说明这个问题，我给session A在T1时刻再加上一个更新语句，即：update t set d=100 where d=5。 update的加锁语义和select…for update是一致的，所以这个时候加上这条update语句也很合理。sessionA声明说“要给d=5的语句加上锁”，就是为了要更新数据，新加的这条update语句就是把它认为加上了锁的这行的d值修改成了100。 经过T1时刻，id=5这一行变成(5,5,100)，当然这个结果最终是在T6时刻正式提交的； 经过T2时刻，id=0这一行变成(0,5,5); 经过T4时刻，表里面多了一行(1,5,5); 其他行跟这个执行序列无关，保持不变。 这样看，这些数据也没啥问题，但是我们再来看看这个时候binlog里面的内容。 T2时刻，sessionB事务提交，写入两条语句； T4时刻，sessionC事务提交，写入两条语句； T6时刻，sessionA事务提交，写入了update t set d=100 where d=5这条语句。 12345678update t set d=5 where id=0; /*(0,0,5)*/update t set c=5 where id=0; /*(0,5,5)*/insert into t values(1,1,5); /*(1,1,5)*/update t set c=5 where id=1; /*(1,5,5)*/update t set d=100 where d=5;/*所有d=5的行，d改成100*/ 这个语句序列，不论是拿到备库去执行，还是以后用binlog来克隆一个库，这三行的结果，都变成了(0,5,100)、(1,5,100)和(5,5,100)。 也就是说，id=0和id=1这两行，发生了数据不一致。 我们来分析一下，数据不一致到底是怎么引入的，假设“select * from where d=5 for update 这条语句只给d=5这一行，也就是id=5这一行加锁”导致的。 所以上面的假设都不合理，改成扫描过程中碰到的行，也都加上写锁。再看看执行效果。 由于sessionA把所有的行都加了写锁，所以sessionB在执行一个update语句的时候就被锁住了。需要等到T6时刻sessionA提交以后，sessionB才能继续执行。 这样对于id=0这一行，在数据库里的最终结果还是(0,0,5)。在binlog里面，执行序列是这样的。 12345678insert into t values(1,1,5); /*(1,1,5)*/update t set c=5 where id=1; /*(1,5,5)*/update t set d=100 where d=5;/*所有d=5的行，d改成100*/update t set d=5 where id=0; /*(0,0,5)*/update t set c=5 where id=0; /*(0,5,5)*/ 可以看到，按照日志的顺序执行行，id=0这一行的最终结果也是(0,0,5)所以，id=0这一行的问题解决了。 但同时，id=1这一行，在数据库里面的结果是(1,5,5),而根据binlog的执行结果是(1,5,100),也就是说幻读的问题还是没有解决。 也就说，即使把所有的记录都加上锁，还是阻止不了新插入的记录，这也是为什么“幻读”会被单独拿出来解决的原因。 如何解决幻读？产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)。 顾名思义，间隙锁，锁的就两个值之间的空隙。比如文章开头的表t，初始化插入6个记录，这就产生了7个间隙。 这样当你select * from t where d=5 for update的时候，就不止是给数据库中已有的6个记录加上行锁。还同时加了7个间隙锁。这样就确保无法再插入新的记录。 也就说这时候，在一行行扫描的过程中，不仅仅将给行上加了行锁，还给行两边的空隙，也加上了间隙锁。 数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之间碰到过的锁都不太一样。 比如行锁，分成读锁和写锁。 也就说，跟行锁冲突关系的是“另外一个行锁” 但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间不存在冲突关系。 这里sessionB并不会被堵住。因为表t里并没有c=7这个记录，因此sessionA加的是间隙锁(5,10)。而sessionB也是在这个间隙加的间隙锁。它们有共同的目标，即：保护和这个间隙，不允许插入值。但是它们之间不冲突。 间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间。也就说，我们表t初始化以后，如果用select * from t for update要把整个表所有记录锁起来，就形成了7个next-key lock，分别是(-∞，0]、(0，5]、(5，10]、(10，15]、(15，20]、(20，25]、(25，supremum]。 间隙锁和next-key lock的引入，帮助我们解决了幻读的问题，但同时也带来了一些“困扰”。 业务逻辑：任意锁住一行，如果这一行不存在的话就插入，如果存在这一行就更新它的数据。 12345678910begin;select * from t where id=N for update;/*如果行不存在*/insert into t values(N,N,N);/*如果行存在*/update t set d=N set id=N;commit; 可能你会说，这个不是insert…on duplicate key update就能解决吗？但其实在有多个唯一键的时候，这个方法是不能满足这个需求的。 这个逻辑一旦有并发，就会碰到死锁。这个逻辑每次操作前用for update锁起来，已经是最严格的模式了，怎么会有死锁呢？ 其实都不需要用到的update语句，就已经形成死锁了。我们按照语句执行顺序来分析一下： sessionA执行select…for update语句，由于id=9这一行并不存在，因此会加上间隙锁(5,10) sessionB执行select…for update语句，同样会加上间隙锁(5,10),间隙锁之间不会冲突，因此这个语句可以执行成功； sessionB试图插入一行(9,9,9),被sessionA的间隙锁挡住了，只好进入等待； sessionA试图插入一行(9,9,9),被sessionB的间隙锁挡住了。 至此，两个sessiion进入相互等待状态，形成死锁。当然，InnoDB的死锁检测马上就发现了这对死锁关系，让sessionA的insert报错返回了。 间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的 间隙锁是在可重读隔离级别下才会生效的。所以，如果把隔离级别设置成读提交的话，就没有间隙锁了，但同时，你要解决可能出现的数据和日志不一致问题，需要把binlog格式设置为row。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL实践篇-慢查询","slug":"数据库/MySQL/mysql｜15为什么只查询一行的语句，也执行很慢","date":"2020-02-11T13:04:48.078Z","updated":"2020-04-23T01:23:36.775Z","comments":true,"path":"2020/02/11/数据库/MySQL/mysql｜15为什么只查询一行的语句，也执行很慢/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/11/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C15%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AA%E6%9F%A5%E8%AF%A2%E4%B8%80%E8%A1%8C%E7%9A%84%E8%AF%AD%E5%8F%A5%EF%BC%8C%E4%B9%9F%E6%89%A7%E8%A1%8C%E5%BE%88%E6%85%A2/","excerpt":"","text":"为什么只查一行的语句，也执行这么慢？如果是MySQL数据库本身就有很大的压力，导致数据库服务器CPU占用绿很高或ioutil(IO利用率)很高，这种情况下所有的语句的执行都有可能很慢，这里不讨论。 为了便于描述，我还是构造一个表，基于这个表来说明问题。这个表有两个字段id和c，并且我在里面插入了10万行记录。 1234567891011121314151617181920mysql&gt; CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;delimiter ;;create procedure idata()begin declare i int; set i=1; while(i&lt;=100000) do insert into t values(i,i); set i=i+1; end while;end;;delimiter ;call idata(); 第一类：查询长时间不返回执行sql 12mysql&gt; select * from t where id=1; 查询结果上时间不返回。 一般碰到这种情况的话，大概率是表t被锁住了。一般都是首先执行一下show processlist命令，看看当前语句处于什么状态。 然后针对每种状态，分析产生的原因，如何复现，以及如何处理。 等MDL锁使用show processlist命令查看Waiting for table metadata lock的示意图。 出现这个状态表示的是，现在有一个线程正在表t上请求或者持有MDL写锁，把select语句堵住了。 这类问题的处理方式，就是找到谁持有MDL写锁，然后把它kill掉。 但是，由于在show processlist的结果里面，sessionA的Command列是“Sleep”，导致查找起来不方便。不过有了performance_schema和sys系统库以后，就方便多了。(MySQL启动时需要设置performance_schema=on,相比于设置为off会有10%左右的性能损失) 通过查询sys.schema_table_lock_waits这张表，我们就可以直接找出造成阻塞的process id，把这个连接用kill命令断开即可。 等flush在表t上，执行下面的SQL语句： 12mysql&gt; select * from information_schema.processlist where id=1; 这个状态表示的是，现在有一个线程正要对表t做flush操作。MySQL里面对表做flush操作的用法，一般有一下两个： 1234flush tables t with read lock;flush tables with read lock; 这两个flush语句，如果指定表t的话，代表的是只关闭表t；如果没有指定具体的表名，则表示关闭MySQL里所有打开的表。 但是正常这个两个语句执行起来都很快，除非他们呢被别的线程堵住了。 所以，出现Waiting for table flush状态的可能情况是：有一个flush tables命令被别的语句堵住了，然后它又堵住了我们的select 语句。 复现步骤： 在sessionA中，故意没行都调用一次sleep(1),这样这个语句默认要执行10万秒，在这期间表t一直被sessionA”打开”着。然后，sessionB的flush tables t命令再要去关闭表t，就需要等sessionA的查询结果，这样session C要再次查询的话，就会被flush命令堵住了。 通过show processlist命令查看的结果： 等行锁12mysql&gt; select * from t where id=1 lock in share mode; 由于访问id=1这个记录时要加读锁，如果这个时候已经有事务在这行记录上持有一个写锁，select会被堵住。 复现步骤如下： session A启动了事务，占有写锁，还提交，是导致sessionB被堵住的原因。 如果是MySQL5.7版本，可以通过sys.innodb_lock_waits表查到。 12mysql&gt; select * from t sys.innodb_lock_waits where locked_table=&#x27;`test`.`t`&#x27;\\G 可以看到，4号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是KILL QUERY 4或KILL 4。 实际上，KILL 4 才有效，也就说直接断开这个连接。这里隐含的一个逻辑就是，连接断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了id=1上的行锁。 第二类：查询慢12mysql&gt; select * from t where c=50000 limit 1; 由于字段c上没有索引，这个语句只能走id主键顺序扫描，因此需要扫描5万行。 注意：为了把所有语句记录到show log里，我在连接后先执行了set long_query_time=0,将慢查询日志的时间阀值设置为0。 Rows_examined显示扫描了50000行。坏查询不一定是慢查询 12mysql&gt; select * from t where id=1； 虽然扫描行数是1，但执行时间却长达800毫秒。 如果执行语句： 1mysql&gt; select * from t where id=1 lock in share mode; 执行扫描行数也是1行，执行时间是0.2毫秒。 按理说 lock in share mode还要加锁，时间应该更长才对。 第一个语句的查询结果里c=1,带lock in share mode的语句返回的是c=1000001。 复现步骤： sessionA先用start transaction with consistent snapshot 命令启动了一个事务，之后session B才开始执行update语句。 sessionB执行完100万次update语句后 ID=1这行什么状态？ sessionB更新完100万次，生成了100万个回滚日志(undo log)。 带lock in share mode 的SQL语句，是当前读，因此会直接读到1000001这个结果，所以速度很快；而select * from t where id =1这个语句，是一致性读，因此需要从1000001开始，依次执行undo log，执行了100万次后，才将1这个结果返回。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL实践篇-SQL逻辑相同，性能却差异巨大","slug":"数据库/MySQL/mysql｜14SQL语句逻辑相同,性能却差异巨大","date":"2020-02-09T07:14:50.933Z","updated":"2020-04-23T01:23:36.775Z","comments":true,"path":"2020/02/09/数据库/MySQL/mysql｜14SQL语句逻辑相同,性能却差异巨大/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/09/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C14SQL%E8%AF%AD%E5%8F%A5%E9%80%BB%E8%BE%91%E7%9B%B8%E5%90%8C,%E6%80%A7%E8%83%BD%E5%8D%B4%E5%B7%AE%E5%BC%82%E5%B7%A8%E5%A4%A7/","excerpt":"","text":"为什么这些SQL语句逻辑相同，性能却差异巨大？案例一：条件字段函数操作假设你现在维护了一个交易系统，其中交易记录表tradelog包含交易流水号(tradeid)、交易员id(operator)、交易时间(t_modified)等字段。 12345678910mysql&gt; CREATE TABLE `tradelog` ( `id` int(11) NOT NULL, `tradeid` varchar(32) DEFAULT NULL, `operator` int(11) DEFAULT NULL, `t_modified` datetime DEFAULT NULL, PRIMARY KEY (`id`), KEY `tradeid` (`tradeid`), KEY `t_modified` (`t_modified`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 现在已经记录了从2016年初到2018年底的所有数据，运营部门有一个需求，要统计发生在所有年份中7月份的交易记录总数。 12mysql&gt; select count(*) from tradelog where month(t_modified)=7; 由于t_modified字段上有索引，直接执行SQL，却发现执行很久，才能返回结果。 如果你对字段做了函数计算，就用不上索引了，这是MySQL的规定 下面是这个t_modified索引的示意图，方框上面的数字是month()函数对应的值。 如果计算mouth()函数的话，传入7的时候，第一层就不知道该接下来如何处理了。 对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能 优化器不是要放弃使用这个索引，放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引t_modified,优化器对比索引大小后发现，索引t_modified更小，遍历这个索引比遍历主键索引来的更快。最终还是会选择索引t_modified. 使用explain命令 key=‘t_modified’表示的是，使用了t_modified这个索引；在测试表数据中插入10万行数据，rows=100335，说明这条扫描了整个索引的所有值；Extra字段的Using index，表示的是使用了覆盖索引。 也就是说，由于在t_modified字段加了month()函数操作，导致了全索引扫描。为了能够用上索引的快速定位能力，我们把SQL语句改成基于字段本身的范围查询。按照下面这个写法，优化器就能按照我们预期的，用户是那个t_modified索引的快速定位能力了。 12345mysql&gt; select count(*) from tradelog where -&gt; (t_modified &gt;= &#x27;2016-7-1&#x27; and t_modified&lt;&#x27;2016-8-1&#x27;) or -&gt; (t_modified &gt;= &#x27;2017-7-1&#x27; and t_modified&lt;&#x27;2017-8-1&#x27;) or -&gt; (t_modified &gt;= &#x27;2018-7-1&#x27; and t_modified&lt;&#x27;2018-8-1&#x27;); 案例二：隐式类型转换12mysql&gt; select * from tradelog where tradeid=110717; 交易编号tradeid这个字段上，本来就有索引，但是explain的结果却显示，这条语句需要走全表扫描。你可能发现了，tradeid的字段类型是varchar(32),而输入的参数却是整型，所以需要做类型转换。 现在这里有两个问题： 数据类型转换的规则是什么？ 为什么有数据类型转换，就需要走全索引扫描? 这里有一个简单的方法，看select “10”&gt;9的结果： 如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是1； 如果规则是“将数字转成字符串”，那么就做字符串比较，结果应该是0; 在MySQL中，字符串和数字做比较的话，是将字符串转成数字。 这时全表扫描的语句： 12mysql&gt; select * from tradelog where tradeid=110717; 对于优化器来说，相当于 12mysql&gt; select * from tradelog where CAST(tradid AS signed int) = 110717; 也就说，这条语句出发上面提到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。 案例三：隐式字符编码转换假设系统还有另外一个表，trade_detail，用于记录交易的操作细节。为了便于量化分析和复现，交易日志表tradelog和交易详情表trade_detail这两个表插入一些数据。 12345678910111213141516171819202122232425mysql&gt; CREATE TABLE `trade_detail` ( `id` int(11) NOT NULL, `tradeid` varchar(32) DEFAULT NULL, `trade_step` int(11) DEFAULT NULL, /*操作步骤*/ `step_info` varchar(32) DEFAULT NULL, /*步骤信息*/ PRIMARY KEY (`id`), KEY `tradeid` (`tradeid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into tradelog values(1, &#x27;aaaaaaaa&#x27;, 1000, now());insert into tradelog values(2, &#x27;aaaaaaab&#x27;, 1000, now());insert into tradelog values(3, &#x27;aaaaaaac&#x27;, 1000, now());insert into trade_detail values(1, &#x27;aaaaaaaa&#x27;, 1, &#x27;add&#x27;);insert into trade_detail values(2, &#x27;aaaaaaaa&#x27;, 2, &#x27;update&#x27;);insert into trade_detail values(3, &#x27;aaaaaaaa&#x27;, 3, &#x27;commit&#x27;);insert into trade_detail values(4, &#x27;aaaaaaab&#x27;, 1, &#x27;add&#x27;);insert into trade_detail values(5, &#x27;aaaaaaab&#x27;, 2, &#x27;update&#x27;);insert into trade_detail values(6, &#x27;aaaaaaab&#x27;, 3, &#x27;update again&#x27;);insert into trade_detail values(7, &#x27;aaaaaaab&#x27;, 4, &#x27;commit&#x27;);insert into trade_detail values(8, &#x27;aaaaaaac&#x27;, 1, &#x27;add&#x27;);insert into trade_detail values(9, &#x27;aaaaaaac&#x27;, 2, &#x27;update&#x27;);insert into trade_detail values(10, &#x27;aaaaaaac&#x27;, 3, &#x27;update again&#x27;);insert into trade_detail values(11, &#x27;aaaaaaac&#x27;, 4, &#x27;commit&#x27;); 这时候，如果要查询id=2的交易的所有操作步骤信息，SQL语句可以这么写： 12mysql&gt; select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/ 我们一起来看一下这个结果： 第一行显示优化器会先在交易记录表tradelog上查到id=2的行，这个步骤用上了主键索引，rows=1表示扫描一行； 第二行key=NULL，表示没有用上交易详情表trade_detail上的tradeid索引，进行了全表扫描。 在这个执行计划里，是从tradelog表中取tradeid字段，再去trade_detail表里查询匹配字段。因此，我们把tradelog称为驱动表，把trade_detail称为被驱动表，把tradeid称为关联字段。 我们看一下这个explain结果的执行流程： 图中： 第一步，是根据id在tradelog表里找到L2这行； 第二步，是从L2中取出tradeid字段的值； 第三步，是根据tradeid值到trade_detail表中查找条件匹配的行。explain的结果里面第二行的key=NULL表示的就是，这个过程是通过遍历主键索引的方式，一个一个地判断tradeid的值是否匹配。 进行到这里，你会发现第3步不符合我们的预期，因为表trade_detail里tradeid字段上是有索引的，我们本来是希望通过使用tradeid索引能够快速定位到等值的行。 这个两个表的字符集不同，一个是utf8，一个是utf8mb4,所以做表连接查询的时候用不上关联字段的索引。 我们说问题是出在执行步骤的第3步，如果单独把这个步骤改成SQL语句的话，那就是： 12mysql&gt; select * from trade_detail where tradeid=$L2.tradeid.value; 其中，$L2.tradeid.value的字符集是utf8mb4。 字符集utf8mb4是utf8的超集，当这两个类型的字符串在做比较的时候，MySQL内部的操作是，先把utf8字符串转成utf8mb4字符集，再做比较。 这个设定很好理解，utf8mb4是utf8的超集。类似地，在程序设计语言里面，做自动类型转换的时候，为了避免数据在转换过程中由于截断导致数据错误，也都是“按数据长度增加的方向”进行转换的。 也就是说，实际上这个语句等同于下面这个写法： 12select * from trade_detail where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; CONVERT()函数，在这里的意思是把输入的字符串转成utf8mb4字符集。 这就再次触发了我们上面说到的原则：对索引字段做函数操作，优化器会放弃走树搜索功能。 连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。 作为对比验证，“查找trade_detail表里id=4的操作，对应的操作者是谁” 12mysql&gt;select l.operator from tradelog l , trade_detail d where d.tradeid=l.tradeid and d.id=4; 这个语句里trade_detail表变成了驱动表，但是explain结果的第二行显示，这次的查询操作用上了被驱动表tradelog里的索引(tradeid),扫描行数是1。 这也是两个tradeid字段的join操作，为什么这次能用上被驱动表的tradeid索引呢？ 假设驱动表trade_detail里id=4的行记为R4，那么在连接的时候，被驱动表tradelog上执行的就是类似这样的SQL语句： 12select operator from tradelog where traideid =$R4.tradeid.value; 这时候$R4.tradeid.value的字符集是utf8，按照字符集转换规则(因为utf8mb4是utf8的超集，所以要将utf8转成utf8mb4)，要转成utf8mb4，所以这个过程被改写成： 12select operator from tradelog where traideid =CONVERT($R4.tradeid.value USING utf8mb4); 这里的CONVERT函数是加在输入参数上的，这样就可以用上被驱动表tradeid索引。 理解原理以后，就可以用来指导操作了。如果优化语句 12select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; 的执行过程，有两种方法： 比较常见的优化方法是，把trade_detail表上的tradeid字段的字符集也改成utf8mb4，这样就没有字符集转换的问题了。12alter table trade_detail modify tradeid varchar(32) CHARACTER SET utf8mb4 default null; 如果能够修改字段的字符集的话，是最好不过了，但如果数据量比较大，或者业务上暂时不能做这个DDL的话，那就只能采用修改SQL语句的方法了。1mysql&gt; select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; 这里，主动把l.tradeid转成utf8，就避免了被驱动表上的字符编码转换，从explain结果可以看到，这次索引走对了。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL实践篇-order by","slug":"数据库/MySQL/mysql｜13order by","date":"2020-02-08T07:04:46.439Z","updated":"2020-04-23T01:23:36.774Z","comments":true,"path":"2020/02/08/数据库/MySQL/mysql｜13order by/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/08/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C13order%20by/","excerpt":"","text":"order by是怎么工作的？按照名字排序返回前1000个人的姓名、年龄。 假设这个表的是这样的 12345678910CREATE TABLE `t` ( `id` int(11) NOT NULL, `city` varchar(16) NOT NULL, `name` varchar(16) NOT NULL, `age` int(11) NOT NULL, `addr` varchar(128) DEFAULT NULL, PRIMARY KEY (`id`), KEY `city` (`city`)) ENGINE=InnoDB; SQL语句 12select city,name,age from t where city=&#x27;杭州&#x27; order by name limit 1000 ; 全字段排序在city字段上创建索引之后，用explain命令来看看这个语句的执行情况。Extra 这个字段中“Using filesort”表示的就是需要排序，MySQL会给每个线程分配一块内存用于排序，称为sort_buffer。 满足city=“杭州”条件的行，是从ID_X到ID_(X+N)的这些记录。 通常情况下，语句的执行流程如下： 初始化sort_buffer,确定放入name，city，age这三个字段； 从索引city找到第一个满足city=“杭州”条件的主键id，也就是图中的ID_X; 到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中； 从索引city取下一个记录的主键id； 重复步骤3、4知道city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y; 对sort_buffer中的数据按照字段name做快速排序； 按照排序结果取前1000行返回给客户端。 这个排序过程，称为全字段排序。 图中按name排序这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数sort_buffer_size。 sort_buffer_size,就是MySQL为排序开辟的内存(sort_buffer)的大小。如果要排序的数据量小于sort_buffer_size，排序就在内存中完成。但是如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。 123456789101112131415161718/* 打开optimizer_trace，只对本线程有效 */SET optimizer_trace=&#x27;enabled=on&#x27;; /* @a保存Innodb_rows_read的初始值 */select VARIABLE_VALUE into @a from performance_schema.session_status where variable_name = &#x27;Innodb_rows_read&#x27;;/* 执行语句 */select city, name,age from t where city=&#x27;杭州&#x27; order by name limit 1000; /* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G/* @b保存Innodb_rows_read的当前值 */select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = &#x27;Innodb_rows_read&#x27;;/* 计算Innodb_rows_read差值 */select @b-@a; 这个方法是通过OPTIMIZER_TRACE的结果来确认的，可以从number_of_tmp_files中看到是否使用了临时文件。 number_of_tmp_files表示的是，排序过程中使用的临时文件数。外部排序一般使用归并排序算法。 MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中，然后把这12个有序文件再合并成一个有序的大文件。 如果sort_buffer_size超过了需要排序的数据量的大小，number_of_tmp_files就是0，表示排序可以直接在内存中完成。 否则就需要放在临时文件中排序。sort_buffer_size越小，需要分成份数越多，number_of_tmp_files的值就越大。 上图的内容： 示例表中有4000条满足city=‘杭州’的记录，所以你可以看到examined_rows=4000.表示参与排序的行数是4000行。 sort_model里面的packed_additional_fields的意思是，排序过程中对字符串做了“紧凑”处理。即使name字段的定义是varchar(16),在排序过程中还是按照实际长度来分配空间的。 对原表的数据读了以便，剩下的操作都是在sort_buffer和临时文件中执行。如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段数太多，这样内存里能同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。 rowid排序如果MySQL认为排序的单行长度太大会怎么做呢？ 12SET max_length_for_sort_data = 16; max_length_for_sort_data，是Mysql中专门控制用于排序的行数据的长度的一个参数。如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。 city、name、age这三个字段的定义长度是36，把max_length_for_sort_data设置为16。 新的算法放入sort_buffer的字段，只有要排序的列(即name字段)和主键id。 但这时，排序的结果积极因为少了city和age字段的值，不能直接返回了，整个执行流程就变成了如下这样： 初始化sort_buffer，确定放如两个字段，即name和id； 从索引city找到第一个满足city=‘杭州’条件的主键id，也就是图中的ID_X; 到主键id索引取出整行，取name、id这两个字段，存入sort_buffer中； 从索引city取下一个记录的主键id； 重复步骤3、4直到不满足city=‘杭州’条件为止，也就是图中的ID_Y; 对sort_buffer中的数据按照字段name排序； 遍历排序结果、取前1000行，并按照id的值回到原表中取出city、name和age三个字返回给客户端。 从OPYIMIZER_TRACE的结果： sort_mode变成了&lt;sort_key,rowid&gt;，表示参与排序的只有name和id这两个字段。 number_of_tmp_files变成10了，是因为这个时候参与排序的行数虽然仍然是4000行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。 全字段排序VSrowid排序如果MySQL实在是担心排序内存大小，会影响排序效率，才会采用rowid排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。 如果MySQL认为内存足够大，会优先选择全字段排序，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。 体现了MySQL的一个设计思想L如果内存够，就要多利用内存，尽量少磁盘访问。 对于InnoDB表来说，rowid排序会要求回表多造成磁盘度，因此不会优先选择。 如果能够保证city这个索引上取出来的行，天然就是按照name递增排序的话，就可以不用再排序了。 12alter table t add index city_user(city, name); 可以创建一个city和name的联合索引 这样查询流程就变成了： 从索引(city，name)找到第一个满足的city=‘杭州’条件的主键id； 到主键id索引取出整行，取name，city、age三个字段的值，作为结果集的一部分直接返回。 从索引(city,name)取下一个记录主键id； 重读步骤2、3直到查到第1000条记录，或者是不满足city=‘杭州’条件时循环结束。 可以看到Extra字段中没有Using filesort了，也就是不需要排序了。由于联合索引(city,name)本身有序，所以查询也不用把4000行全部读一遍。 可以用覆盖索引进一步优化 12alter table t add index city_user_age(city, name, age); 这时，对于city字段的值相同的行来说，还是按照name字段的值递增排序的，此时的查询语句也就不需要排序了。 这时查询语句的执行流程就变成了： 从索引(city,name,age)找到第一个满足city=‘杭州’条件的记录，取出其中的city、name、age这三个字段的值，作为结果集的一部分直接返回； 从索引(city,name,age)取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回； 重复执行步骤2，直接到查到第1000条记录，或者是不满足city=‘杭州’条件时循环结束。 Extra字段多了Using index，表示的就是使用了覆盖索引，性能上会快很多。 另外一种需求，当需要随机滚动查询时，如何来设计SQL语句。直接从单词表中随机选出三个单词 1234567891011121314151617181920mysql&gt; CREATE TABLE `words` ( `id` int(11) NOT NULL AUTO_INCREMENT, `word` varchar(64) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;delimiter ;;create procedure idata()begin declare i int; set i=0; while i&lt;10000 do insert into words(word) values(concat(char(97+(i div 1000)), char(97+(i % 1000 div 100)), char(97+(i % 100 div 10)), char(97+(i % 10)))); set i=i+1; end while;end;;delimiter ;call idata(); 内存临时表使用order by rand()来实现这个逻辑。 12mysql&gt; select word from words order by rand() limit 3; 随机排序取前3个。 explain命令来查看语句的执行情况。 Extra字段显示Using temporary，表示的是需要使用临时表；Using filesort，表示是需要执行排序操作。 对于InnoDB表来说，临时内存表，执行全字段排序会减少磁盘访问，因此会被优先选择。 对于内存表，回表过程只是简单地根据数据行的为止，直接访问内存得到数据，根本不会导致多访磁盘。优化器没有了这一层顾虑，那么它会优先考虑，就是用于排序的行越小越好。所以MySQL这时就会选择rowid排序。 这条语句的执行流程： 创建一个临时表。这个临时表使用的是memory引擎，表里有两个字段，第一个字段是double类型，为了后面描述方便，记为字段R，第二个字段是varchar(64)类型，记为字段W。并且，这个表没有建索引。 从words表，按主键顺序取出所有的word值，对于每一个word值，调用rand()函数生成一个大于0小于1的随机小数，并把这个随机小数和word分别存入临时表的R和W字段中，到此，扫描行数是10000。 现在临时表有10000行数据了，接下来你要是在这个没有索引的内存临时表上，按照字段R排序。 初始化sort_buffer。sort_buffer中有两个字段，一个是double类型，另一个是整型。 在内存临时表中一行一行地取出R值和位置信息(位置信息？)，分别存入sort_buffer中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加10000，变为20000。 在sort_buffer中根据R的值进行排序。这个过程没有涉及到表操作，所以不会增加扫描行数。 排序完成后，取出前三个结果的位置信息，依次在内存临时表取出word值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了20003。 通过满查询日志(show log)来验证一下我们分析得到的扫描行数是否正确。 1234# Query_time: 0.900376 Lock_time: 0.000347 Rows_sent: 3 Rows_examined: 20003SET timestamp=1541402277;select word from words order by rand() limit 3; MySQL的表是用什么方法来定位”一行数据”的如果把InnoDB表的主键删掉，就没有主键了，就没办法回表了。 如果你创建的表有主键，或者把这个表的主键删掉了，那么InnoDB会自己生成一个长度为6字节的rowid来作主键。 这也就是排序模式里面，rowid名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。 对于有主键的InnoDB表来说，这个rowid就是主键ID； 对于没有主键的InnoDB表来说，这个rowid就是由系统生成的； MEMORY引擎不是索引组织表，这个例子里面，你可以认为他就是一个数组，因此，这个rowid其实就是数组的下标。 order by rand()使用了内存临时表，内存临时表排序的时候使用了rowid排序方法啊。 磁盘临时表tmp_table_size这个配置限制了内存临时表的大小，默认值是16M。如果临时表大小超过了tmp_table_size,那么内存临时表就会转换成磁盘临时表。 磁盘临时表使用的引擎默认是InnoDB，是由参数internal_tmp_disk_storage_engine控制的。 当使用磁盘临时表的时候，对应的就是一个没有显示索引的InnoDB表的排序过程。 为了复现这个过程，我把tmp_table_size设置成1024，把sort_buffer_size设置成32768，把max_length_for_sort_data设置成16。 123456789101112set tmp_table_size=1024;set sort_buffer_size=32768;set max_length_for_sort_data=16;/* 打开 optimizer_trace，只对本线程有效 */SET optimizer_trace=&#x27;enabled=on&#x27;; /* 执行语句 */select word from words order by rand() limit 3;/* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G 因为将max_length_for_sort_data设置成16，小于word字段的长度定义，所以看到sort_mode里面显示的rowid排序，这个是符合预期的，参与排序的是随机值R字段和rowid字段组成的行。 filesort_priority_queue_optimization这个部分的chosen=true，表示使用了优先队列算法。这个过程中不需要临时文件，因此对应number_of_tmp_files是0。 R字段存放的随机值就是8个字节，rowid是6个字节(为什么是6个呢？),数据总行数是10000，这样算出来就有140000字节，超过了sort_buffer_size定义的32768字节了。但是，number_of_tmp_files的值居然是0。难道是需要用临时文件吗？ 这个语句采用了新的排序算法，优先队列排序算法。为什么没有使用临时文件的算法—–归并排序算法，而是采用了优先队列排序算法。 其实，SQL语句只需要取R值最小的3个rowid。但是如果使用归并排序算法的话，虽然最终也能得到前3个值，但是这个算法结束后，已经将10000行数据都排好序了。 优先队列算法，就可以精确地只得到三个最小值 对10000个准备排序的(R,rowid),先取前三行，构造一个堆； 取下一行(R’,rowid’),跟当前堆里面最大的R 比较，如果R‘小于R，把这个(R,rowid)从堆中去掉换成(R’,rowid’); 重复第2步，直到第10000个(R’,rowid’)完成比较。 随机排序方法如果只所以1个word值。 取得这个表的主键的最大值M和最小值N； 用随机函数生成一个最大值到最小值之间的数X=(M-N)*rand+N; 取小于X的第一个ID的行。 这个算法，暂时称作随机算法1. 1234mysql&gt; select max(id),min(id) into @M,@N from t ;set @X= floor((@M-@N+1)*rand() + @N);select * from t where id &gt;= @X limit 1; 这个方法效率很高，因为取max(id)和min(id)都不需要扫描索引，而第三步的select也可以用索引快速定位，可以认为就只扫描了3行。 这个算法不够严谨，因为ID中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。 为了得到严格随机的结果，需要下面的流程： 取得整个表的行数，并记为C； 取得Y=floor(C*rand())。floor函数在这里的作用，就是取整数部分。 再用limitY，1取一行。 这个算法称为随机算法2 1234567mysql&gt; select count(*) into @C from t;set @Y = floor(@C * rand());set @sql = concat(&quot;select * from t limit &quot;, @Y, &quot;,1&quot;);prepare stmt from @sql;execute stmt;DEALLOCATE prepare stmt; 由于limit后面的参数不能直接跟变量，所以在代码中使用了prepare+execute的方法。 MySQL处理limit Y，1的做法是按照顺序一个一个地读出来，丢掉前Y个，然后把下一个记录作为返回结果。因此这一步需要扫描Y+1行。再加上，第一步扫描的C行，总共需要扫描C+Y+1行，执行代价比随机算法1的代价要高。 按照随机算法2的思路，要随机取3个word值 取得整行表的行数，记为C； 根据相同的随机算法得到Y1，Y2，Y3; 再执行三个limitY，1语句得到三行数据。 12345678mysql&gt; select count(*) into @C from t;set @Y1 = floor(@C * rand());set @Y2 = floor(@C * rand());set @Y3 = floor(@C * rand());select * from t limit @Y1，1； //在应用代码里面取Y1、Y2、Y3值，拼出SQL后执行select * from t limit @Y2，1；select * from t limit @Y3，1；","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL实践篇-count(*)分析","slug":"数据库/MySQL/mysql｜12count(*)的分析","date":"2020-02-08T02:30:43.720Z","updated":"2020-04-23T01:23:36.774Z","comments":true,"path":"2020/02/08/数据库/MySQL/mysql｜12count(*)的分析/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/08/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C12count(*)%E7%9A%84%E5%88%86%E6%9E%90/","excerpt":"","text":"count(*)这么慢，该怎么办?count(*)的实现方式首先在MySQL引擎中，count(*)有不同的实现方式。 MyISAM引擎把一个表的总行数存在磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高； 而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行的从引擎里面读出来，然后累积计数。 这里讨论的是没有过滤条件的count(*),如果是加入了where条件的话，MyISAM表也是不能返回得这么快的。 为什么InnoDB不跟MyISAM一样，也把数字存起来呢？因为即使是在同一个时刻的多个查询，由于多版本并发控制(MVCC)的原因，InnoDB表”应该放回多少行”也是不确定的。 假设表t中现在有10000条记录，设计三个用户并行回话。 回话A先启动事务并查询一次表的总行数； 回话B启动事务，插入一行记录后，查询表的总行数； 回话C先启动一个单独的语句，插入一行记录后，查询表的总行数。 这和InnoDB的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是MVCC来实现的。每一行记录都要判断自己是否对这个回话可见，因此对于count(*)请求来说，InnoDB只好把数据一行一行地一次判断出来，可见的行能用于计算“基于这个查询”的表的总行数。 InnoDB是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会知道最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。 show table status 执行后结果里面有一个TABLE_ROWS用于显示这个表当前有多少行，这个命令执行挺快的，那这个TABLE_ROWS不能代替count(*); 索引统计的值是通过采样估算的。TABLE_ROWS就是从这个采样估算出来的，因此它也不准。官方误差在40%-50% MyISAM表虽然count(*)很快，但是不支持事务； show table status 命令虽然返回很快，但是不准确； InnoDB表直接count(*)会遍历全表，虽然结果准确，但会导致性能问题。 用缓存系统保存计数利用redis做为总记录数的缓存，但是不能保证准确性，除了丢失更新的问题，即使Redis正常工作，这个值还是逻辑上不精确的。 查到100行结果里面有新插入的记录，而Redis的计数里还没有加1； 查到100行记过里面没有新插入的记录，而Redis的计数里已经加1； 会话A是一个插入交易记录的逻辑，往数据表插入一行R，然后Redis计数加1；会话B就是查询页面显示时需要的数据。 T3时刻会话B来查询的时候，会显示出新插入的R这个记录，答案是Redis的计数还没有加1.这时候，就会出现我们说的数据不一致。 如果是先加Redis再插入数据，那么数据还是不一致。 在数据库保存计数缓存计数不精确，如果我们把这个计数直接放到数据库里单独的一张计数C中，又会怎么样呢？ 首先，这解决了崩溃丢失的问题，InnoDB是支持崩溃恢复不丢数据的。 计数精确的问题我们利用事务来保证 虽然回话B的读操作仍然是在T3执行，但是因为这时候更新事务还没有提交，所以计数值加1这个操作对会话B还是不可见的。 不同count用法count()的语义。count()是一个聚合函数，对于返回的结果集，一行一行地判断，如果count函数的参数不null，累计值就加1，否则不加。最后返回累计值。 所以，count(*)、count(主键ID)和count(1)都表示返回满足条件的结果集的总行数；而count(字段)，则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。 至于分析性能差别的时候，有这么几个原则： server层要什么就给什么； InnoDB只给必要的值； 现在的优化器只优化了count(*)的语义为“取行数”，其他“显而易见”的优化并没有做。 对于count(主键id)来说InnoDB引擎会遍历整张表，把每一行的id值取出来，返回给server层。server层拿到id后，判断是不可能为空的，按行累加。 对于count(1)来说InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字1进去，判断是不可能为空的，按行累加。 对于count(字段)来说 如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加； 如果这个“字段”定于允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。 count(*)是例外并不会把全部字段取出来，而是专门做了优化，不取值。count(*)肯定不是null，按行累加。 所以结论是：按照效率排序的话，count(字段)&lt;count(主键ID)&lt;count(1)～count(),所以建议使用count();","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL实践篇-数据库表的空间回收","slug":"数据库/MySQL/mysql｜11数据库表的空间回收","date":"2020-02-07T12:30:19.143Z","updated":"2020-04-23T01:23:36.774Z","comments":true,"path":"2020/02/07/数据库/MySQL/mysql｜11数据库表的空间回收/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/07/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C11%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%9A%84%E7%A9%BA%E9%97%B4%E5%9B%9E%E6%94%B6/","excerpt":"","text":"为什么表数据删掉一半，表文件大小不变?参数innodb_file_pre_table表数据既可以存在共享表空间，也可以是单独的文件。这个行为是由参数innodb_file_pre_table控制的： 这个参数设置为OFF表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起； 这个参数设置为ON表示的是，每个InnoDB表数据存储在一个以.ibd为后缀的文件中。 从MySQL 5.6.6版本开始，它的默认值就是ON了。 建议设置为ON，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过drop table命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删除了，空间也不会回收。 数据删除流程InnoDB里的数据都是用B+树的结构组织。 假如，我们要删掉R4这个记录，InnoDB引擎只会把R4这个记录标记为删除。如果之后要再插入一个ID为300和600之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小 InnoDB的数据是按页存储的，如果我们删掉了一个数据页上的所有记录，整个数据页就可以被复用了。 数据页的复用跟记录的复用是不同 记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4这个条记录被删除后，如果插入一个ID是400的行，可以直接复用这个空间。但是如果插入的是一个ID是800的行，就不能复用这个位置了。 当整个页从B+树里面摘掉以后，可以复用到任何位置。以图1为例，如果将数据页pageA上的所有记录删除以后，page A会被标记为可复用。这时候如果要插入一条ID=50的记录需要使用新页的时候，page A是可以被复用。 如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到一个页上，另外一个数据页就被标记为可复用。 我们用delete命令把整个表的数据删除，所有的数据页都会被标记为可复用。但是磁盘上，文件大小不会改变。 delete命令其实只是把记录的位置，或者数据页标记为“可复用”，但是词筽安文件的大小是不会变的。通过delete命令是不能收回表空间的，这个可以复用，而没有被使用的空间，看起来就像是“空洞” 不止是删除数据会造成空洞，插入数据也会如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但是如果数据是随机插入的，就可以造成索引的数据页分裂。 由于Page A满了，再插入一个ID是550的数据时，就不得不再申请一个新的页面page B来保存数据了，页分裂完成后，page A的末尾就留下空洞。(注意：实际上，可能不止1个记录的位置是空洞的) 更新索引上的值，可以理解为删除旧的值，再插入一个新的值。这种页会造成空洞。 重建表可以使用alter table A engine = InnoDB命令来重建表。 在MySQL5.5版本之前，这个命令的执行流程如下： MySQL会自动完成转存数据、交换表名、删除旧表的操作。 图三 花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到A表的花，就会造成数据丢失。因此，在整个DDL过程中，表A中不能有更新。也就说这个DDL不是Online的。 在MySQL5.6版本开始引入的OnlineDDL，对这个操作流程做了优化 建立一个临时文件，扫描表A主键的所有数据页； 用数据页中表A的记录生成B+树，存储到临时文件中； 生成临时文件的过程中，将所有对A的操作记录在一个日志文件(row log)中，对应的是下图中的state2的状态； 临时文件生成后，将日志文件中的操作应用到临时文件，等到一个逻辑数据上与表A相同的数据文件，对应的图中的state3的状态； 用临时表文件替换A的数据文件。 图四 DDL之前是要拿到MDL写锁的，就是在alter语句在启动的时候需要获取MDL写锁，但是这个写锁在真正拷贝数据之前就已经退化成读锁了。为了实现Online，MDL读锁不会阻塞增删改操作，但是为了保护自己阻止其他线程对表同时做DDL，因为MDL读写是互斥的 对于一个大表来说，Online DDL最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个DDL过程来说，锁的时间非常短。对业务来说，就可以认为是Online。 如果是线上服务，大表来说，这个操作是消耗IO和CPU资源的。GitHub开源的gh-ost来操作。 Online和inplaceMySQL5.5以前的版本，数据导出来存放的文职叫做tmp_table。这是一个临时表，是在server层创建的。 MySQL5.6以后的版本，重建出来的数据都是放在“tmp_file”里面，这个临时文件是InnoDB在内部创建出来的。整个DDL过程都在InnoDB内部完成。对于sercer层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。 重建表的这个语句alter table t engine= InnoDB，其实隐含的意思是： 1alter table t engine=innodb,ALGORITHM=inplace; 跟inplace对应的就是拷贝表的方式了： 1alter table t engine=innodb,ALGORITHM=copy; 表示的是强制拷贝表，对应的是在server层的操作。 DDL过程如果是Online的，就一定是inplace的； 反过来未必，也就说inplace的DDL，有可能不是Online的。截止到MySQL8.0，添加全文索引(FULLTEXT index)和空间索引(SPATIAL index)就是属于这种情况。 optimize table、analyze table和alter table这三种方式重建表的 区别 从MySQL5.6版本开始，alter table t engine = InnoDB(也就是recreate)默认的就是图四的流程。 analyze table t其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁。 optimize table t 等于recreate+analyze。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL实践篇-为什么MySQL会”抖“一下","slug":"数据库/MySQL/mysql｜10MySQL为什么会抖一下","date":"2020-02-07T05:00:18.236Z","updated":"2020-04-23T01:23:36.774Z","comments":true,"path":"2020/02/07/数据库/MySQL/mysql｜10MySQL为什么会抖一下/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/07/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C10MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E6%8A%96%E4%B8%80%E4%B8%8B/","excerpt":"","text":"你的SQL语句为什么变慢了？通过WAL机制，知道了，InnoDB在处理更新语句的时候，只做了写日志这个磁盘操作。这个日志叫 redo log(重做日志)、也就是掌柜用来记账的粉板，在更新完内存写完redo log后，就返回给客户端，本次更新成功。 类比一下：掌柜记账的账本是数据文件，记账用的粉板是日志文件(redo log),掌柜的记忆就是内存。 掌柜总要找时间把账本更新一下，对应的就是把内存里的输入写入磁盘的过程，术语就是flush。在这个flush操作执行之前，孔乙己的赊账总额，其实和掌柜手中的账本里面的记录是不一致的，因为孔乙己今天的赊账金额还只在粉板上，而账本里的记录是老的，还没把今天的赊账算进去。 当内存数据页跟磁盘数据页内容不一致的时候，我们称内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页” 平时执行很快的更新操作，其实就是在写内存和日志，而MySQL偶尔会“抖”一下的那个瞬间，可能就是在刷脏页(flush)。 想一想：掌柜在什么情况下会把粉板上的赊账记录改到账本上？ 第一种场景，粉板写满了，记不下了。这时候如果再有人来赊账，掌柜就只能放下手里的活儿，将粉板上的记录擦掉一些，流出空位以便继续记账。当然擦掉之前，必须先将正确的账目记录到账本中才行。对应的场景就是InnoDB的redo log写满了。这个时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。checkpoint可不是随便往前修改下一个位置就可以的，把checkpoint位置从cp推进到CP’，就需要将两个点之间的日志(浅绿色部分),对应的所有脏页都flush到磁盘上。之后，图中write pos到CP‘之间就是可以再写入redo log的区域。 第二种场景，这一天生意太好了，要记住的事情太多，掌柜发现自己快记不住了，赶紧找出账本把孔乙己这笔帐先加进去。这种场景，对应的就是系统内存不足，当需要新的内存页，而内存不够的时候，就要淘汰一些数据页，空出来内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿redo log出来应用不就行了？这里其实是从性能考虑的，如果刷脏页一定会写盘，就保证每个数据页有两种状态： 一种是内存里存在，内存里就肯定是正确的结果，直接返回。 另一种是内存没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。 第三种场景，生意不忙的时候，或者打烊之后，这时候柜台没事，掌柜闲着，不如更新账本。这种场景，对应的就是MySQL认为系统“空闲”的时候，MySQL”这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间。 第四种场景，年底了酒店关门，需要把账节结清一下。这种场景，对应的MySQL正常关闭的情况。这时候，MySQL会把内存的脏页flush到磁盘上。 接下来分析一下四种场景对性能的影响： 主要关注第一种，和第二种。 第一种是“redo log写满了，要flush脏页“，这种情况是InnoDB要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，搜有的更新都必须堵住。 第二种是”内存不够用了，要先将脏页写到磁盘“，这中情况其实是常态。**InnoDB用缓冲池(buffer pool)**管理内存，缓冲池中的内存页有三种状态： 第一种，还没使用的； 第二种，使用了并且是干净页； 第三种，使用了并且是脏页。 InnoDB的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。 当要读入的数据页没有内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；如果是脏页，就必须将脏页先刷到磁盘，变成干净页后才能复用。 所以，刷脏页虽然是常态，但是出现以下两种情况，就会明显影响性能： 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长； 日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。 所以，InnoDB需要有控制脏页比例的机制，来尽量避免上面这个两种情况。 InnoDB刷脏页的控制策略首先，要正确告诉InnoDB所在主机的IO能力，这样InnoDB才能知道需要全力刷脏页的时候，可以刷多快。 这就要用到innodb_io_capacity这个参数，它会告诉InnoDB你到磁盘能力。这个值设置称磁盘的IOPS。词筽安的IOPS可以通过fio这个工具来测试，下面的语句用来测试磁盘随机读写的命令： 12fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 其实，因为没能正确地设置innodb_io_capacity参数，而导致的性能问题也比比皆是。MySQL的写入速度很慢，TPS很低，但是数据库主机的IO压力并不大。经过排查，发现罪魁祸首就是这个参数的设置出现了问题。 主机磁盘用的SSD，但是innodb_io_capacity的值设置是300。于是，InnoDB认为系统能力就这么差，所以刷脏页刷的特别慢，甚至比脏页生成的速度还慢，这就造成脏页累积，影响了查询和更新性能。 虽然我们现在已经定义了“全力刷脏页”的行为，但平时总不能一直是全力刷吧？毕竟磁盘能力不能只用来刷脏页，还需要服务用户请求。所以接下来，我们讨论InnoDB怎么控制引擎按照“全力”的百分百来刷脏页。 如果设计策略控制刷脏页的速度，会参考哪些因素？ 刷的慢会导致，内存脏页太多，其次是redo log写满。 所以，InnoDB的刷盘速度就要参考这个两个因素：一个是脏页比例，一个是redo log写盘速度。 InnoDB会根据这个两个因素先单独算出两个数字。 参数innodb_max_dirty_pages_pct是脏页比例上限，默认值是75%。InnoDB会根据当前的脏页比例(假设为M),算出一个范围在0到100之间的数字，计算这个数字的伪代码类似这样： 123456F1(M)&#123; if M&gt;&#x3D;innodb_max_dirty_pages_pct then return 100; return 100*M&#x2F;innodb_max_dirty_pages_pct;&#125; InnoDB每次写入的日志都有一个序号，当前写入的需要跟checkpoint对应的序号之间的差值，我们假设为N。InnoDB会根据这个N算出一个范围在0到100之间的数字，这个计算公式记为F2(N)。 根据上述算得的F1(M)和F2(N)这两个值，取其中比较大的值记为R，之后引擎就可以按照innodb_io_capacity定义的能力乘以R%来控制刷脏页的速度。 InnoDB会在后台刷脏页，而刷脏页的过程是将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用IO资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到MySQL“抖”了一下的原因。 要尽量避免这种情况，要合理地设置innodb_io-capacity的值，并且平时要多关注脏页比例，不要让它经常接近75%。 脏页比例是通过Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total得到的。 1234mysql&gt; select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = &#x27;Innodb_buffer_pool_pages_dirty&#x27;;select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = &#x27;Innodb_buffer_pool_pages_total&#x27;;select @a/@b; 一旦一个查询请求需要在执行过程中先flush掉一个脏页时，这个查询就可能要比平时慢了。而MySQL中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以蔓延，也就是对每个邻居数据页，如果跟他相邻的数据页也还是脏页的话，也会被放到一起刷。 在InnoDB中，innodb_flush_neighbors参数就是用来控制这个行为的，值为1的时候会有上述事务“连坐”机制，值为0时表示不找邻居，自己刷自己的。 找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机IO。机械硬盘的随机IOPS一般只有几百，相同的逻辑曹祖耦减少随机IO就意味着系统性能的大幅度提升。 而如果使用的SSD这类IOPS比较高的设备的话，建议把innodb_flush_neighbors的值设置成0.因为这时候IOPS往往不是瓶颈，而是“只刷自己”,就能更快地执行完必要的刷脏页操作，减少SQL语句响应时间。 一个内存配置为128GB、innodb_io_capacity设置成20000的大规格实例，建议将redo log设置成4个1GB文件。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL实践篇-字符串字段加索引","slug":"数据库/MySQL/mysql｜09给字符串字段加索引","date":"2020-02-05T13:50:14.083Z","updated":"2020-04-23T01:23:36.773Z","comments":true,"path":"2020/02/05/数据库/MySQL/mysql｜09给字符串字段加索引/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/05/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C09%E7%BB%99%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AD%97%E6%AE%B5%E5%8A%A0%E7%B4%A2%E5%BC%95/","excerpt":"","text":"怎么给字符串字段加索引?现在 几乎所有的系统都支持邮箱登录，如何在邮箱这样的字段上建立合理的索引？ MySQL是支持前缀索引的，也就说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就包含整个字符串。 1234mysql&gt; alter table SUser add index index1(email);或mysql&gt; alter table SUser add index index2(email(6)); 第一句创建的index1索引里面，包含了每个记录的整个字符串；在第二句语句创建的index2索引李曼，对于每个记录都是只取前6个字节。 由于email(6)这个索引结构中每个邮箱字段都只取前6个字节，所以占用的空间更小，这就是使用前缀索引的优势。 但是损失是，可能会增加额外的记录扫描次数。 1select id,name,email from SUser where email=&#x27;zhangssxyz@xxx.com&#x27;; 如果使用的index1 从index1索引树周到满足索引值是“&#x7a;&#x68;&#x61;&#110;&#103;&#115;&#115;&#x78;&#x79;&#122;&#x40;&#x78;&#x78;&#120;&#x2e;&#99;&#111;&#109;”的这条记录，取值ID2的值； 到主键上查到主键值是ID2的行，判断email的值是正确的，将这行记录加入结果集； 取index1索引树上刚刚查到的位置下一条记录，发现已经不满足email=‘&#122;&#104;&#x61;&#x6e;&#x67;&#x73;&#x73;&#120;&#121;&#122;&#x40;&#120;&#x78;&#x78;&#46;&#99;&#x6f;&#x6d;’的条件，循环结束。 如果使用的是index2 从index2索引树找到满足索引值是‘zhangs’的记录，找到的第一个ID1； 到主键上查到主键值是ID1的行，判断出email的值不是‘&#x7a;&#104;&#x61;&#110;&#103;&#115;&#115;&#x78;&#121;&#x7a;&#x40;&#120;&#120;&#120;&#46;&#x63;&#x6f;&#x6d;’，这行记录丢弃； 取index2上刚刚查到的位置的下一条记录，发现仍然是’zhangs‘，取出ID2，再到索引ID上取整行然后判断，这次值对了，将这行记录加入结果集； 重复上一步，知道index2上取到的值不是’zhangs‘时，循环结束。 使用前缀索引，定义好长度，就可以做到既节省空间，有不用额外增加太多的查询成本。 可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。 1234567mysql&gt; select count(distinct left(email,4)）as L4, count(distinct left(email,5)）as L5, count(distinct left(email,6)）as L6, count(distinct left(email,7)）as L7,from SUser; 前缀索引对覆盖索引的影响如果利用覆盖索引，只查询邮箱和id，从index1查到结果之后就直接放回了，不需要回到ID索引再取查一次。 如果利用前缀索引，即使索引的内容已经是全部的字段信息，也必须要回到ID索引再去判断email字段的值，因为系统并不确定前缀索引的定义是否截断了完整信息。 其他方式索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索效率也就会越低。 针对身份证号码而言： 第一种方式就是使用倒序存储： 12mysql&gt; select field_list from t where id_card = reverse(&#x27;input_id_card_string&#x27;); 由于身份证的最后6位没有地址码这样的重复逻辑，所以最后6位很可能就提供了足够的区分度。当然，实践中你不要忘记使用count(distinct)方法做验证。 第二种方式就是使用hash字段： 在表上再创建一个整数字段，老保存身份证的校验码，同时在这个字段上创建索引。 12mysql&gt; alter table t add id_card_crc int unsigned, add index(id_card_crc); 然后每次插入新纪录的时候，都同时用crc32()这个函数得到校验码填到这个新字段，由于校验码可能存在冲突，也就说两个不同的身份证号通过crc32()函数得到的结果可能是相同，所以你的查询语句where 部分要判断id_card的值是不是精确相同。 12mysql&gt; select field_list from t where id_card_crc=crc32(&#x27;input_id_card_string&#x27;) and id_card=&#x27;input_id_card_string&#x27; 使用倒序存储和使用hash字段这两种方法的异同点相同点：都不支持范围查询。 倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在范围之间的所有市民了。同样的，hash字段的方式也只能支持等值查询。 区别： 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而hash字段方法需要增加一个字段。当然，倒序存储方式使用4个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个hash字段也差不多抵消了。 在CPU消耗方面，倒序方式每次读和写的时候，都需要额外一次reverse函数，而hash字段的方式需要额外调用一次crc32()函数。如果只从这个两个函数的计算复杂度来看的话，reverse函数额外消耗的CPU资源会更小。 从查询效率上看，使用hash字段方式的查询性能相对稳定一些，因为crc32算出来的值虽然有点冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。而倒序存储方式毕竟还是用的前缀索引的方式，会增加回表查询的扫描行数。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL实践篇-MySQL索引选择","slug":"数据库/MySQL/mysql｜08MySQL选择索引","date":"2020-02-05T06:51:43.541Z","updated":"2020-04-23T01:23:36.773Z","comments":true,"path":"2020/02/05/数据库/MySQL/mysql｜08MySQL选择索引/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/05/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C08MySQL%E9%80%89%E6%8B%A9%E7%B4%A2%E5%BC%95/","excerpt":"","text":"MySQL为什么有时候会选错索引?🌰：我们先建一个简单的表，表里面有a、b两个字段，分别建上索引； 123456789CREATE TABLE `t` ( `id` int(11) NOT NULL, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `a` (`a`), KEY `b` (`b`)) ENGINE=InnoDB； 然后，在表t中插入10万行记录，取值按整数递增，(1,1,1),(2,2,2)… 插入的存储过程 12345678910111213delimiter ;;create procedure idata()begin declare i int; set i=1; while(i&lt;=100000)do insert into t values(i, i, i); set i=i+1; end while;end;;delimiter ;call idata(); 接下来分析一条SQL语句： 12mysql&gt; select * from t where a between 10000 and 20000; 结果就是会直接a的索引。 假如做如下操作： 这个时候sessionB的查询语句select * from t where a between 10000 and 20000就不会在选择索引a了。可以痛殴满查询日志(show log)来查看一下具体的执行情况。 1234set long_query_time=0;select * from t where a between 10000 and 20000; /*Q1*/select * from t force index(a) where a between 10000 and 20000;/*Q2*/ 第一句，是将慢查询日志的阀值设置为0，表示这个线程接下来的语句都会被记录入慢查询日志中； 第二句，Q1是session B原来的查询； 第三句，Q2是加了force index(a)来和session B原来的查询语句执行情况对比。 可以看到Q1扫描了10万行，显然是走了全表扫描，执行时间是40毫秒。Q2扫描了10001行，执行了21毫秒。也就是说在没有强制使用了 force index的时候，MySQL用错了索引，导致了更长的执行时间。 这个例子对应的是平常不断的删除历史数据和新增数据的场景。 优化器的逻辑选择索引时候优化器的工作。 优化器选择索引的目的，是找到最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数时候影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的cpu资源越少。 扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。 扫描行数是怎么判断的？MySQL在真正开始执行语句之前，并不能精确到地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。 这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数(cardinality)”.也就是说，这个基数越大，索引的区分度越好。 可以通过使用show index方法，看到一个索引的基数。这三个索引的基数值并不同，而且其实都不准确。 MySQL是怎样得到索引的基数呢？通过MySQL采用统计的方法来获得。 InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面书，就等到了这个索引的基数。 数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过1/M的时候，会自动触发重新做一次索引统计。 在MySQL中，有两种存储索引统计的方式，可以通过设置参数innodb_stats_persistent的值来选择： 设置为on的时候，表示统计信息会持久化存储，这是，默认的N是20，M是10. 设置为off的时候，表示统计信息只存储在内存中。这时默认的N是8，M是16. 其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。 rows这个字段表示的是预计扫描行数。 其中Q1的结果还是符合预期的，rows的值是104620；但是Q2的rows值是37116，偏差就大了。而我们最开始explain命令看到的rows是只有10001行，是这个偏差误导了优化器的判断。 为什么优化器，没有选择扫描行数少的执行计划呢？ 如果使用索引a，之后每一次查询都需要回表到主键索引查询出整行数据，会增加代价。优化器认为直接扫描主键索引更快。从结果来看，这个选择并不是最优的 统计信息不多，就利用 analyze table t 命令，可以用来重新统计索引信息。 依然是基于这个表t，我们看看另外一个语句： 12mysql&gt; select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1; 从条件上看，这个查询没有符合条件的记录，因此会返回空集合。 因为使用b作为排序值，所以优化器会选择b索引作为索引进行查询。 索引选择异常和处理优化器没有选择正确的索引，采用force index强行选择一个索引。存在问题： 对于代码来说存在硬编码问题，索引名字以及语法的兼容受到平台限制。 使用force index 一般是线上有问题再修改的过程，所以开发的时候也不会先写上。 通过修改语句，引导MySQL使用我们期望的索引。把order by b limit 1 改成 order by b，a limit 1.语义的逻辑是相同。 之前优化器选择使用索引b，是因为它认为使用索引b可以避免排序(b本身是索引，已经是有序的了，如果选择索引b的话，不需要在做排序，只需要遍历)，所以即使扫描行数多，也判定为代价更小。 现在order by b，a这种写法，要求按照b，a排序，就意味着使用这两个索引都需要排序。因此，扫描行数成了影响决策的主要条件，于是此时优化器选了只需要扫描1000行的索引a。 在这些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL实践篇-普通索引和唯一索引","slug":"数据库/MySQL/mysql｜07普通索引和唯一索引","date":"2020-02-04T16:23:38.369Z","updated":"2020-04-23T01:23:36.773Z","comments":true,"path":"2020/02/05/数据库/MySQL/mysql｜07普通索引和唯一索引/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/05/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C07%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95/","excerpt":"","text":"普通索引和唯一索引，应该怎么选?🌰：假设维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号码。如果市民系统需要按照身份证号查姓名，就会执行类似这样的SQL语句： 12select name from CUser where id_card = &#x27;xxxxxxxyyyyyyzzzzz&#x27;; 由于身份证号字段太大，不适合当作主键，这样其他索引创建会非常占内存。 查询过程 对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。 更新过程为了说明普通索引和唯一索引对更新语句性能的影响这个问题，先介绍一下change buffer。 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这个种方式就能保证这个数据逻辑的正确性。 说明：虽然名字叫change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中的拷贝，也会被写入磁盘上。 将change buffer中操作应用到原数据页，得到的最新结果的过程称为merge。除了访问这个数据页会触发，merge外，系统有后台线程会定期merge。在数据库正常关闭的过程中，也会执行merge操作。 如果能够将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的。所以这种方式还能够避免占用内存，提高内存利用率。 什么情况下可以使用change buffer呢？对于唯一索引来说，所有的更新操作都先判断这个操作是否违反唯一性约束。所以需要先判断唯一索引的值是否在表中存在，就需要先将数据页读入内存判断。如果都已经读入内存了，那直接更新内存会更快，就没必要使用change buffer了。 因此唯一索引的更新就不能使用change buffer，实际上页只有普通索引可以使用。 change buffer用的是buffer pool里的内存，因此不能无限增大。change buffer的大小，可以通过参数innodb_change+buffer_max_size来动态设置，这个参数设置好为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。 如果要在表中插入一行新记录的话，InnoDB的处理流程是怎样的。第一种情况：这个记录要更新的目标页在内存中。 对于唯一索引来说，找到对应的位置，判断有没有冲突，插入这个值，语句执行结束； 对于普通索引来说，找到对应的位置，插入这个值，语句执行结束。 第二种情况：这个记录要更新的目标页不再内存中。 对于唯一索引来说，需要将数据页读入内存，判断没有冲突，插入这个值，语句执行结束； 对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。 将数据从磁盘读入内存设计随机IO的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了磁盘的随机访问，所以对更新性能的提升会很明显。 change buffer的使用场景通过分析已经直到使用change buffer对更新过程的加速作用，也清楚了change buffer只限于用在普通索引的场景下，而不适合用于唯一索引。普通索引的所有场景，使用change buffer都可以起到加速作用吗？ 因为merge的时候是真正进行数据更新的时刻，而change buffer的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做merge之前，change buffer记录的变更越多越好。 因此，对于写多读少的业务来说，页面在写完以后马上就被访问到的概率比较小。此时change buffer 的使用效果最好。常见的是就是账单、日志类的系统。 假设一个业务的更新模式是写入之后马上就做查询，那么即使满足了条件，将更新先记录change buffer，但之后由于马上需要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。 索引选择和实践普通索引和唯一索引，在查询能力上没差别，主要是考虑是对更新性能的影响。所以，建议尽量选择普通索引。 如果所有的更新后面，都马上伴随着对这个记录的查询，那么应该关闭change buffer。而其他的情况下，change buffer都能提升更新性能。 change buffer 和redo log🌰： 12mysql&gt; insert into t(id,k) values(id1,k1),(id2,k2); 假设当前k索引树的状态，查找到位置后，k1所在的数据页在内存(InnoDB buffer pool)中，k2所在数据页不在内存中。如图 内存，redo log(ib_log_fileX)、数据表空间(t.ibd)、系统表空间(ibdata1)。 这条更新语句做如下操作： Page1在内存中，直接更新内存； Page2没在内存中，就在内存的change buffer区域，记录下“我要往Page2插入一行”这个信息 将上述两个动作计入redo log中。 之后读请求，要怎么处理？ select * from t where k in（k1，k2）。 从图中可以看到： 读Page1的时候，直接从内存返回。 要读Page2的时候，需要把Page2从磁盘读入内存中，然后应用change buffer离main的操作日志，生成一个正确版本并返回结果。 redo log主要节省的是随机写磁盘的IO消耗(转成顺序写)，而change buffer主要节省的则是随机读磁盘的IO消耗。 merge 的执行过程： 从磁盘读入数据页到内存； 从change buffer 里找到这个数据页的change buffer记录，依次应用，得到新版数据页； 写redo log。这个redo log包含了数据的变更和change buffer的变更。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL基础篇-事务到底是隔离还是不隔离","slug":"数据库/MySQL/mysql｜06事务到底是不是隔离的","date":"2020-02-03T11:39:07.959Z","updated":"2020-04-23T01:23:36.773Z","comments":true,"path":"2020/02/03/数据库/MySQL/mysql｜06事务到底是不是隔离的/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/03/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C06%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E4%B8%8D%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84/","excerpt":"","text":"事务到底是隔离的还是不隔离的？12345678mysql&gt; CREATE TABLE `t` ( `id` int(11) NOT NULL, `k` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(id, k) values(1,1),(2,2); 🌰： 图一 注意事务的启动时机，begin/start transaction命令并不是一个事务的起点，在执行到它们之后的第一操作InnoDB表的语句，事务才真正启动。如果你想马上启动一个事务，可以使用start transaction with consistent snapshot这个命令。 第一种启动方式，一致性视图是在执行第一个快照读语句时创建的； 第二种方式，一致性视图是在执行start transaction with consistent snapshot时创建的。 在这个🌰中，事务C没有显示的使用begin/commit，表示这个update语句本身就是一个事务，语句完成的时候会自动提交。事务B在更新了之后查询；事务A在一个只读事务中查询，并且时间顺序上是在事务B的查询之后。 这时事务B查到的K的值是3，而事务A查到的K的值是1。 MySQL里，有两个视图的概念： 一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果，创建视图的语法是create view，而它的查询方法和表一样。 另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC(Read committed,读提交)和RR(repeatable Read,可重复读)隔离界别的实现。 “快照”在MVCC里面是怎么工作的？在可重复读隔离级别下，事务在启动的时候就是“拍了个快照”。这个快照是基于整库的 InnoDB里面每个事务有一个唯一的事务ID，叫做transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。 而每行数据也都是有多个版本的，每次事务更新数据的时候，都会生成一个新的数据版本，并切把transaction id赋值给这个数据版本的事务ID，记为row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。 也就是说，数据表中的一行记录，其实可能有多个版本(row)，每个版本都有自己的row trx_id. 图二 图中虚线框里是同一行数据的4个版本，当前最新版本的V4，k的值是22，它是被transaction id 为25的事务更新的，因此它的row trx_id也是25. 图中三个虚线箭头，就是更新会产生undo log，V1，V2，V3并不是物理上真是存在的，而每次需要的时候根据当前版本和undo log计算出来的。 按照可重复读的定义，一个事务启动的时候，能够看到所有已经提交的事务结果。但是之后，这个事务执行期间，其他事务的更新对它不可见。 因此，一个事务只需要在启动的时候申明说，“以我启动的时刻为准，如果一个数据版本是在我启动之前生成的，就认；如果是我启动以后才生成的，我就不认，我必须要找到它的上一个版本”。如果上一个版本不可见的话，那就继续往前找。如果是这个事务自己更新的数据，它自己还是要认的。 在实现上，InnoDB为每一个事务构造了一个数组，用来保存这个事务启动瞬间，当前已经启动但是没有提交的所有事务ID。 数组里面事务ID的最小值记为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。 这个视图数组和高水位，就组成了当前事务的一致性视图(read-view)。 而数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的对比结果得到的。 这个视图数组把所有的row trx_id分成几种不同的情况。 图三 如果落在绿色部分，表示这个版本是已经提交的事务或者是当前事务自己生成的，这个数据是可见的。 如果落在红色部分，表示这个版本是由将来启动的事务生成，是肯定不可见的。 如果落在黄色部分，那就是有两种情况： 若row trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见； 若row trx_id不在数组中，表示这个版本是已经提交了的事务生成的，可见。 继续图一中的🌰： 假设： 事务A开始前，系统里面只有一个活跃事务ID是99； 事务A、B、C的版本号分别是100、101、102，且当前系统里面只有这四个事务； 三个事务开始前，（1，1）这行数据的row trx_id是90. 这样事务A的视图数组就是[99,100],事务B的视图数组是[99，100，101]，事务C的视图数组是[99，100，101，102]。 图四---事务A查询逻辑 第一个有效更新是事务C，把数据从（1，1）改成了（1，2）。这时数据的最新版本的row trx_id是102，而90这个版本已经称为了历史版本。 第二个有效更新是事务B，把数据从(1,2)改成(1,3)。这时数据的最新版本(row trx_id)是101，而102又变成了历史版本。 在事务A查询的时候，其实事务B还没有提交，但是它生成的(1,3)这个版本已经变成当前版本了。但是这个版本对事务A必须是不可见的，否则就办成脏读了。 事务A要读数据了，它的视图数组是[99,100]。读数据都是从当前版本读起的，所以事务A查询语句的读数据流程是这样的： 找到(1,3)的时候，判断出row trx_id=101,比高水位大，处于红色区域，不可见； 接着，找到上一个历史版本，row trx_id=102,比高水位大，处于红色区域，不可见 再往前找，终于找到(1,1),它的row trx_id = 90，比低水位小，处于绿色区域，可见。 这样执行下来，虽然期间这一行数据被修改过，但是事务A不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。 一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况： 版本未提交，不可见； 版本已提交，但是在视图创建之后提交的，不可见 版本一提交，而且是在事务视图创建前提交的，可见。 更新逻辑更新数据都是先读后写的，而这个读，只能读当前的值，称为当前读。 因此 在更新的时候，当前读拿到的数据是(1,2),更新后生成了新版的数据(1,3)，这个新版本的row trx_id 是101. 所以执行事务B查询语句的时候，一般自己的版本号是101，最新数据的版本号也是101，是自己更新的，可以直接使用。 除了update语句外，select语句如果加锁，也是当前读 1234# 共享锁--S锁select k from t where id=1 lock in share mode;# 排她锁--X锁select k from t where id=1 for update; 假设事务C不是马上提交，而是变成下面的事务C‘ 这个时候主要考虑两阶段锁协议，事务C’没提交，也就说(1,2)这个版本上的写锁还没释放。而事务B是当前读，必须要读最新的版本，而且必须加锁，因此就被锁住了，必须等事务C’释放锁，才能继续她的当前读。 读提交的逻辑和可重复读的逻辑区别： 可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里面的其他逻辑查询都共用这个一致性视图； 读提交隔离级别下，每一个语句执行前都会重新计算出一个新视图。 在读提交隔离级别下，start transaction with consistent snapshot 从这个语句开始，创建一个持续整个事务的一致性快照，就和start transaction 一样了。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL基础篇-全局锁、表锁及行锁","slug":"数据库/MySQL/mysql｜05全局锁、表锁及行锁","date":"2020-02-02T06:47:17.118Z","updated":"2020-04-23T01:23:36.773Z","comments":true,"path":"2020/02/02/数据库/MySQL/mysql｜05全局锁、表锁及行锁/","link":"","permalink":"https://vincentxin-scott.github.io/2020/02/02/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C05%E5%85%A8%E5%B1%80%E9%94%81%E3%80%81%E8%A1%A8%E9%94%81%E5%8F%8A%E8%A1%8C%E9%94%81/","excerpt":"","text":"全局锁和表锁：给表加个字段怎么这么多阻碍？数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。 根据加锁的范围，MySQL里面的锁大致可以分成全局锁，表级锁和行锁三类。 全局锁全局锁就是对整个数据库实例加锁，MySQL提供了一个加全局读锁的方法，命令是Flush tables with read lock（FTWRL）。当你需要让整个数据库处于只读状态的时候，可以使用这个命令，之后其他线程下的语句会被阻塞：数据的增删改、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都select出来存成文本。 整库只读，是非常危险的： 如果在主库上备份，那么在备份期间都不能执行更新，业务基本是那个就要停摆； 如果你在从库备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟。 如果不加锁的化，备份系统备份得到的库不是一个逻辑时间点，这个视图逻辑是不一致的。 回忆一可重复读的隔离级别，在事务启动的时候，创建一个视图，保证视图内数据的一致性。 官方自带的逻辑备份工具mysqldump。当mysqldump使用参数-single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。 一致性读是好的，但是前提是引擎支持这个隔离级别，所以single-transaction方法只适用于所有的表使用事务引擎的库。 如果有的表使用了不支持事务的引擎，那么备份就只能通过FTWRL。 既然要全库只读，为什么不实用 set global readonly = true 的方式呢？ 在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大。 在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常跟新的状态。 表级锁MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁(meta data lock,MDL) 表锁的语法是 lock tables ··· read/write。与FTWRL类似，可以用unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。 需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象 举例：如果在某个线程A中执行lock tables t1 read，t2 write；这个语句，则其他线程写t1、读写t2的语句都会被阻塞。同时，线程A在执行unlock tables之前，也只能执行读t1，读写t2的操作。自然也不能访问其他表。 另一类表级的锁是MDL(metadata lock)MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。 在MySQL5.5版本中引入MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表结构变更操作的事耦，加MDL写锁。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 假设表t是一个小表，给小表加一个字段： 我们可以看到sessionA先启动，这时候会对表t加一个MDL读锁。由于sessionB需要的也是MDL读锁，因此可以正常执行。 之后sessionC会被blocked，是因为sessionA的NDL读锁还没有释放，而sessionC需要MDL写锁，因此会被阻塞。 如果只有sessionC自己被阻塞还没关系，但是之后所有要在表t上新申请MDL读锁的请求也会被sessionC阻塞。所有对表的增删改查操作都需要先申请MDL读锁，就都被锁住，等于这个表在完全不可读写的状态了。 如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新session在请求的话，这个库的线程很快就会爆满。 事务中的MDL锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而是会在整个事务提交之后再释放。 如何安全地给小表加字段 首先，要解决长事务，事务不提交，就会一直占着MDL锁。 理想的处理机制，在alter table 语句里面设定等待时间，如果在这个指定等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。 MariaDB 已经合并了AliSQL的这个功能，所以这两个开源分支目前都支持DDL NOWAIT/WAIT n 这个语法。 123ALTER TABLE tbl_name NOWAIT add column ...ALTER TABLE tbl_name WAIT N add column ... 行锁功过：怎么减少行锁对性能的影响MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，MyISAM引擎就是不支持行锁。不支持行锁意味这并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这会影响到业务并发度。InnoDB是支持行锁的。 两阶段锁🌰：事务B的update语句执行时会什么现象？假设字段id是表t的主键。 这个问题的结论取决与事务A在执行完两条update语句后，持有哪些锁，以及在什么时候释放锁。 实际上事务B的update语句会被阻塞，直到事务A执行commit之后，事务B才能继续执行。 也就是说，在InnoDB事务中，行锁是在需要的时候才加上，但并不是不需要了就立刻释放，而是等到事务结束时才释放。这个就是两阶段锁协议。 如果你的事务中需要锁多行，要把最可能造成锁冲突、做可能印象并发度的锁尽量往后放。 🌰：假设实现一个电影票在线交易业务，顾客A要在影院B购买电影票。我们简化一点，这个业务需要涉及到一下操作： 从顾客A账户余额中扣除电影票价； 给电影院B的账户余额增加这张电影票价； 记录一条交易日志。 也就是说，要完成这个交易，我们需要update两条记录，并insert一条记录。为了保证交易原子性，我们要把这三个操作放在一个事务中。 试想如果同时有另外一个顾客C要在影院B买票，那么这两个事务冲突的部分就是语句2了。因为需要更新同一个影院账户的余额，需要修改统一行数据。 根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放，所以，如果把语句2安排到最后，按照3、1、2这样的顺序，那么影院账户余额这行的锁时间最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。 死锁和死锁检测当并发系统中不通线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这个几个线程进入无线等待的状态，称为死锁。 🌰： 这个时候，事务A在等待事务B释放id=2的行锁，而事务B在等待事务A释放id=1的行锁。事务A和事务B在互相等待对方的资源释放，就进入了死锁状态。 当出现死锁后有两种策略： 直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout来设置。（默认50s） 发起死锁检测，发现思索后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect 设置为on，表示开启这个逻辑。 由于MySQL默认的死锁超时时间是50s，这样效率太低，如果设置的时间很小，又会将普通的锁等待时间打乱。 所以一般情况下采用第二种策略：主动死锁检测，而且innodb_deadlock_detect的默认值本身就是on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是又额外负担的。 怎么解决由热点行更新导致的性能问题呢？问题在于，死锁检查要耗费大量的CPU资源。 一种头疼医头的方法，即使如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身有一定的风险，因为业务涉及的时候一般不会把死锁当作一个严重错误，毕竟出现了死锁，就回滚，然后通过业务充实一般就没问题了，这是业务无损的。而关掉死锁检测意味可能会出现大量的超时，这是业务有损的。 另一种思路是控制并发度根据上面的分析，如果能够控制并发，比如同一行同时更新最多只有是个线程，那么死锁检测的成本很低，就不会出现这个问题，一个直接的想法就是，在客户端做并发控制，但是，你很快就会发现这个方法不太可行，因为客户端很多。多个客户端累计之后数量很多。 因此，并发控制要做在数据库服务端。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作。 在设计上的优化 可以考虑通过将一行改成逻辑上的多行来减少冲突。还是以影院账户为例，可以考虑放在多条记录上，比如10个记录，影院的账户总额等于这是个记录的值的总和，这样每次要给影院账户加金额的时候，随机选其中一个记录来加。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL基础篇-索引","slug":"数据库/MySQL/mysql｜04深入浅出索引","date":"2020-01-31T14:25:42.962Z","updated":"2020-04-23T01:23:36.773Z","comments":true,"path":"2020/01/31/数据库/MySQL/mysql｜04深入浅出索引/","link":"","permalink":"https://vincentxin-scott.github.io/2020/01/31/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C04%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95/","excerpt":"","text":"深入浅出索引索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。 索引的常见模型索引的出现是为了提高查询效率，但是实现索引的方式却是有很多钟，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，常见也比较简单的数据结构，它们分别是哈希表、有序数组和搜索树 哈希表是一种以键-值（key-value）存储数据的结构，我们只要输入待查找的值即key，就可以找到其对应的值Value。 这种数据结构的弊端： key经过hash换算，会出现同一个值的情况。需要使用链表来维护 哈希表这种结构适合用户只有等值查询的场景—-NoSQL引擎。 有序数组有序数组在等值查询和范围查询场景中的性能就都非常优秀 这种数据结构的弊端： 查询方便但是更新数据的时候就麻烦了，在中间插入的时候就必须挪动后面所有的记录，成本很高。 有序数组索引只适用于静态存储引擎。 二叉搜索树特点：每个节点的左儿子小于父节点，父节点又小于右儿子。时间复杂度O(log(N)) 为了维持O(log(N))的查询复杂度，你就需要保持这颗树是平衡二叉树。为了做这个保证，更新的时间复杂度也是O(log(N)) 平衡二叉树：其中每一个节点的左子树和右子树的高度差至多等于1 二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不知存在内存中，还要写在磁盘上。 N叉树由于在读写上的性能又带你，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。 在MySQL中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。而即使多个存储引擎支持同一种类型的索引，其底层的实现也可能不同。由于InnoDB存储引擎在MySQL数据库中使用最为广泛。 InnoDB的索引模型InnoDB使用了B+树索引模型，所以数据都是存储在B+树中的。 每个索引在InnoDB里面对应一颗B+树。 假设，我们有一个主键列为ID的表，表中有字段K，并且存在k上有索引 建表语句： 12345678mysql&gt; create table T(id int primary key, k int not null, name varchar(16),index (k))engine=InnoDB; 表中R1～R5的（ID，K）值分别为(100,1)、(200,2)、(300,3)、(500,5)、(600,6)，两棵树的示例示意图 主键索引的叶子节点存储的是整行的数据。在InnoDB里，主键索引也被称为聚簇索引(clustered index). 非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引(secondary index). 基于主键索引和普通索引的查询有什么区别？ 如果语句是select * from T where ID = 500，即主键查询方式，则只需要搜索ID这颗B+树； 如果语句是select * from T where K= 5 ，即普通索引查询方式，则需要先搜索K索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。 也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，在应用中应该尽量使用主键查询。 索引维护B+树为了维护索引有序性，在插入新值的时候需要做必要的维护，如果插入新的行ID值为700，则需要在R5的记录后面插入一个新记录。如果新插入的ID值为400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。 更糟糕的情况是，如果R5所在的数据页已经满了，根据B+树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页的分裂。在这种情况下，性能自然会受到影响。 除了性能外，页分裂操作还影响数据页的利用率，原本放在一个页的数据，现在分到两个页中，整体空间利用率降低了50%。 当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是的分裂过程的逆过程。 在一些建表规范中见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，接下来分析一下哪些场景应该使用自增主键，而哪些场景下不应该。 自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的：NOT NULL PRIMARY KEY AUTO_INCREMENT. 插入新纪录的时候可以不指定ID的值，系统会获取当前ID最大值加1作为下一条 记录的ID值。 也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新纪录，都是追加操作，都不涉及到挪动其他的记录，也不会触发叶子节点的分裂。 而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本对象较高。 除了考虑性能外，我们还从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证做主键，还是用自增字段做主键呢？ 由于每个非主键索引的叶子节点上都是主键的值。如果用身份证好做主键，那么每个耳机索引的叶子节点占用约20个字符，而如果用整型做主键，则只要4个字符，如果是长整型(bigint)则是8个字符. 显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小 只有一个索引，该索引必须是唯一索引。这种情况下可以用业务字段直接做主键。 类似KV场景。 SQL语句重建索引123alter table T drop index k;alter table T add index(k); 1234alter table T drop primary key;alter table T add primary key(id); 重建主键是不合理的，不论是删除主键还是创建主键，都会将整个表重建。 可以用一句话代替 1alter table T engine = InnoDB MySQL索引有关概念我们要执行select * from T where K between 3 and 5，需要执行几次树的搜索操作，会扫描多少行？ 123456789mysql&gt; create table T (ID int primary key,k int NOT NULL DEFAULT 0, s varchar(16) NOT NULL DEFAULT &#x27;&#x27;,index k(k))engine=InnoDB;insert into T values(100,1, &#x27;aa&#x27;),(200,2,&#x27;bb&#x27;),(300,3,&#x27;cc&#x27;),(500,5,&#x27;ee&#x27;),(600,6,&#x27;ff&#x27;),(700,7,&#x27;gg&#x27;); 这条SQL查询语句的执行流程： 在k索引树上找到k=3的记录，取得ID=300； 再到ID搜索树查找到ID=300对应的R3； 在k索引树取下一个值k=5，取得ID=500； 再回到ID索引树查找到ID=500对应的R4； 在k索引树取下一个值k=6，不满主条件； 循环结束。 在这个过程中，回到主键索引树搜索的过程，我们称为回表。（在实际生产中如何避免回表呢？） 覆盖索引如果执行的语句是select ID from T where k between 3 and 5，这时只需要查询ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经覆盖了我们的查询需求，我们称为覆盖索引 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。 在引擎内部使用覆盖索引在索引k上其实读了三个记录，R3～R5(对应的索引k上的记录项)，但是对于MySQL的server层来说，它就是找引擎拿到两条记录，因此MySQL认为扫描行数是2. 在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？1234567891011CREATE TABLE `tuser` ( `id` int(11) NOT NULL, `id_card` varchar(32) DEFAULT NULL, `name` varchar(32) DEFAULT NULL, `age` int(11) DEFAULT NULL, `ismale` tinyint(1) DEFAULT NULL, PRIMARY KEY (`id`), KEY `id_card` (`id_card`), KEY `name_age` (`name`,`age`)) ENGINE=InnoDB 我们知道，身份证是使命的唯一标识。也就是说，如果根据身份证号查询市民信息的需求，我们只要身份证号字段上建立索引就够了。而在建立一个（身份证号、姓名）的联合索引，是不是浪费空间呢？ 如果现在有一个高频请求，要根据市民身份证号码查询他的姓名，这个联合索引就有意义了。它可以在这个高频请求上用到覆盖索引，不再需要回表查整行记录，减少语句的执行时间。 最左前缀原则B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。 为了直观地说明这个概念，我们用（name，age）这个联合索引来分析。 可以看到，索引项是按照索引定义里面出现的字段顺序排序的。 当逻辑需求是查到所有名字是“张三“的人时，可以快速定位到ID4，然后向后便利得到所有需要的结果。 如果你要查的所有名字第一个字是”张“的人，你的SQL语句的条件是where name like ‘张%’。这时，你也能够用上这个索引，查找到第一个符合条件的记录是ID3，然后向后遍历，直到不满足条件为止。 基于最左前缀索引的说明： 第一原则，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。 联合索引，如果查询条件只有b的语句，是无法使用（a，b）这个联合索引的。 需要考虑的原则就是空间了。是否设置单字段索引b 索引下推满足最左前缀原则的情况下的查询，如果后面的查询条件中还有包含的联合索引的其他的值，则会利用联合索引进行索引下推去判断，而不会直接回表。 问题思考当备库用-single-transaction做逻辑备份的时候，如果从主库的binlog传来一个DDL语句会怎么样？ 12345678910111213Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;Q2:START TRANSACTION WITH CONSISTENT SNAPSHOT；/* other tables */Q3:SAVEPOINT sp;/* 时刻 1 */Q4:show create table `t1`;/* 时刻 2 */Q5:SELECT * FROM `t1`;/* 时刻 3 */Q6:ROLLBACK TO SAVEPOINT sp;/* 时刻 4 *//* other tables */ 在备份开始的时候，为了确保RR隔离级别，在设置一次RR隔离级别(Q1) 启动事务，这里用with consistent snapshot确保这个语句执行完就可以得到一个一致性视图(Q2) 设置一个保存点，这个很重要(Q3) show create 是为了拿到表结构(Q4),然后正式导数据(Q5),回滚导savepoint sp，在这里的作用是释放t1的MDL锁(Q6)。 DDL从主库传递过来的时间按照效果不通，假设四个时刻。 如果在Q4语句执行之前就到达，现象：没有影响，备份拿到的是DDL之后的表结构。 如果在“时刻2”到达，则表结果被改过，Q5执行的时候，报Table definition has changed，please retry transaction，现象：mysqldump终止； 如果在“时刻2”和“时刻3”之间到达的，mysqldump占着t1的MDL读锁，binlog被阻塞，现象：主从延迟，直到Q6执行完成。 从“时刻4”开始，mysqldump释放了MDL读锁，现象：没有影响，备份拿到的是DDL前的表结构。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL基础篇-事务隔离","slug":"数据库/MySQL/mysql｜03事务隔离","date":"2020-01-31T08:07:17.778Z","updated":"2020-04-23T01:23:36.773Z","comments":true,"path":"2020/01/31/数据库/MySQL/mysql｜03事务隔离/","link":"","permalink":"https://vincentxin-scott.github.io/2020/01/31/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C03%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/","excerpt":"","text":"事务隔离：为什么你改了我还看不见？隔离性与隔离级别提到事务，马上联想到ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）。这里主要介绍隔离性 当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复度（non-repeatable）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。 SQL标准的事务隔离界别 读未提交（read uncommitted） 一个事务还没有提交时，它做的变更就能被别的事务看到。 读提交（read committed）一个事务提交之后，它的变更才会被其他事务看到。 可重复读（repeatable read）一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务是不可见的。 串行化（serializable）对于同一行记录，写 会加写锁，读会加读锁。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 假设数据库表T中只有一列，其中一行的值为1，按照时间顺序执行两个事务的行为。 123create table T(c int) engine=InnoDB;insert into T(c) values(1); 若隔离级别是“读未提交”，则V1的值就是2，这个时候事务B虽然还没有提交，但是结果已经被A看到了。因此V2，V3都是2； 若隔离级别是“读提交”，则V1是1，V2的值是2.事务B的更新在提交之后才能被A看到，所以V3的值也是2。 若隔离级别是“可重复读”，则V1、V2是1，V3是2。之所以V2还是1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。 若隔离级别是“串行化”，则事务B执行“将1改成2”的时候，会被锁住。知道事务A提交之后，事务B才能继续执行。所以从A的角度看，V1、V2值都是1，V3的值是2。 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。 在“可重复读”隔离级别下，这个视图是在事务启动的时候创建，整个事务存在期间都用这个视图。 在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。 在“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念； 在“串行化”隔离级别下直接用加锁的方式来避免并行访问。 MySQL 的默认事务隔离级别是可重复读 Oracle默认事务隔离级别是读提交 MySQL配置和Oracle一致的设置： 将启动参数 transaction-isolation的值设置成READ-COMMITTED。你可以用show variables来查看当前的值 123456789101112mysql&gt; show variables like &#x27;transaction_isolation&#x27;;+-----------------------+----------------+| Variable_name | Value |+-----------------------+----------------+| transaction_isolation | READ-COMMITTED |+-----------------------+----------------+ 事务隔离的实现在MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。 假设一个值从1被按照顺讯改成了2、3、4，在回滚日志里面就会有类似下面的记录。 当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不通的read-view。 如图中看到的，在视图A、B、C里面，这个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，但是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须要将当前值一次执行图中所有的回滚操作得到。 这些回滚日志会在没有事务需要用到的时候删除，也就是当系统中没有比这个回滚日志更早的read-view的时候。 不建议使用长事务： 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以在事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致占用存储空间 事务的启动方式MySQL的事务启动方式有一下几种： 显示启动事务语句，begin或者start transaction。配套的提交语句是commit，回滚语句是rollback set autocommit = 0，这个命令会将这个线程自动提交关闭。以为着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在知道你主动执行commit或rollback语句，或者断开连接","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"MySQL基础篇-日志系统","slug":"数据库/MySQL/mysql｜02日志系统","date":"2020-01-30T15:19:07.226Z","updated":"2020-04-23T01:23:36.773Z","comments":true,"path":"2020/01/30/数据库/MySQL/mysql｜02日志系统/","link":"","permalink":"https://vincentxin-scott.github.io/2020/01/30/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C02%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/","excerpt":"","text":"日志系统：一条SQL更新语句是如何执行的重要的日志模块：redo log redo log是InnoDB引擎特有的日志—重做日志 WAL技术，全称Write-Ahead Logging，他的关键点就是先写日志，再写磁盘。 具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候就算完成了。同时，InnoDB引擎会是在适当的时候，将这个操作记录更新到磁盘里面。 InnoDB的redo log是固定大小的，比如可以配置伟一组4个文件，每个文件大小都是1GB，从头开始写，写到末尾就又回到开头循环写。 write pos 是当前记录的位置，一边写一边后移。 check point 是当前要擦除的位置，也是往后推移并循环的。 中间的位置就是还没有记录的空间 有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。 重要的日志模块：binlogbinlog是server层自己的日志—归档日志 因为最开始MySQL里并没有InnoDB引擎。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只能依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套体制系统 两种日志的不同 redo log 是InnoDB引擎特有的；binlog是MySQL的server 层实现的，所有引擎都可以使用。 redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑。 redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 执行器与InnoDB引擎在执行update语句时的内部流程 执行器先找引擎取ID=2这一行，ID是主键，引擎直接用树搜索找到这一行，如果ID=2这一行所有的数据页本来就在内存中，就直接返回给执行器；否则需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在是N+1，得到新的一行数据，在调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，可以随时提交事务。 执行器生成这个操作的binlog，并把binlog写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log 改成提交 commit状态，更新完成。 两阶段提交两阶段提交是为了让两份日志之间的逻辑一致。 如何让数据库恢复到半月之内任意一秒的状态 如果需要恢复数据库，那么说明备份系统中会保存近半个月的多有binlog。 首先找到最近一次全量备份，从这个备份恢复到临时库。 从备份的时间点开始，将备份的binlog一次取出来，重新放到中午误删表之前的那个时刻。 此处的commit值的是当前更新语句作为一个事务的commit步骤，不是作为事务的commit语句存在的。 两阶段提交如果在不同时刻，MySQL重启会出现什么现象。 如果是在图中时刻A的地方，也就是写了redo log处于prepare阶段之后、写binlog之前，发生了崩溃，由于此时binlog还没有写，redo log还没有提交，所以奔溃恢复的时候，这个事务会回滚。这时候binlog还没写，所以不会传都备库。 如果时刻B发生了奔溃，也就是binlog写完，redo log还没commit前发生。 如果redo log里面的事务是完整的，也就是已经有了commit标识，直接提交； 如果redo log里面的事务只有完整的prepare，则判断对应的事务binlog是否存在并完整： 如果是，则提交事务； 否则，回滚事务。 MySQL怎么知道binlog是完整的？一个事务的binlog是有完整格式的： sratement格式binlog，最后会有commit； row格式的binlog，最后会有一个XID event。在MySQL5.6.2版本以后，还引入了binlog-checksum参数，用来验证binlog内容的正确性。对于binlog日志由于磁盘原因，可能会在日志中间出错误的情况，MySQL可以通过校验checksum的结果来发现。 redo log 和binlog 是怎么关联起来的？它们有一个共同的数据字段，XID，崩溃恢复的时候，会顺序扫描redo log 如果碰到既有prepare、又有commit的redo log，就直接提交。 如果碰到只有prepare、而没有commit的redo log，就拿着XID去binlog找对应的事务。 处于prepare阶段的redo log加上完整binlog，重启就能恢复，MySQL为什么要这么设计？采用这样的策略可以让主库和备库的数据保证一致性。 如果是这样的话，为什么还要两阶段提交呢？干脆先redo log写完，再写binlog。崩溃恢复的时候，必须得两个日志都完整才可以。两阶段提交是经典的分布式系统问题。 这个问题的是事务的持久性问题。 对于InnoDB引擎来说，如果redo log提交完成，事务就不能回滚了(如果回滚就可能覆盖掉别的事务的更新)。而入伏哦redo log直接提交，然后binlog写入失败。InnoDB又回滚不了，数据和binlog日志就不一致了。 不引入两个日志，也就没有两阶段提交的必要了。只用binlog来支持崩溃恢复，又能支持归档，不久可以吗？binlog没有能力恢复“数据页”。 如果图中标的位置，也就是binlog2写完了，但是整个事务还没有commit的时候，MySQL发生了crash。 重启后，引擎内部事务2会回滚，然后应用binlog2可以不回来；但是对于事务1来说，系统已经认为提交完成了，不会再应用一次binlog1。 但是InnoDB引擎使用的是WAL技术，执行事务的时候，写完内存和日志，事务就算完成了，如果之后崩溃，要依赖日志来恢复数据页。 也就是说，在图中位置发生崩溃的话，事务1也是可能丢失了的，而且是数据页级的丢失。 那能不能只用redo log 不用binlog？如果是从崩溃的角度来讲是可以的，这样就没有两阶段提交了，但系统依然是crash-safe的。 binlog 有归档的功能，redo log是一个循环写，日志无法完整保留。 MySQL系统依赖与binlog。binlog作为MySQL一开始就有的功能，被用在了很多地方，MySQL系统高可用的基础，就是binlog复制。主备–主从 redo log 一般设置多大直接将redo log设置为4个文件、每个文件1GB吧。这个TB的磁盘。 正常运行中的实例，数据写入后的最终落盘，是从redo log更新过来的还是从buffer pool更新过来的？ 如果正常运行的实例，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程与redo log毫无关系。 在崩溃恢复场景中，InnoDB如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后redo log更新内存内容。更新完后，内存页变成脏页，就回到了第一种情况的状态。 redo log buffer是什么，？是先修改内存，还是先写redo log文件？12345begin;insert into t1 ...insert into t2 ...commit; 这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没commit的时候就直接写到redo log文件里。 所以 redo log buffer就是一块内存，用来先存redo日志的。也就是说，在执行第一个insert的时候，数据的内存被修改了，redo log buffer页写入了日志。 但是，真正把日志写到redo log文件(文件名是ib_logfile+数字)，是在执行commit语句的时候做的。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"Mac安装npm源管理工具","slug":"Mac/Mac安装npm源管理工具","date":"2019-11-16T16:04:25.208Z","updated":"2019-12-11T06:48:15.085Z","comments":true,"path":"2019/11/17/Mac/Mac安装npm源管理工具/","link":"","permalink":"https://vincentxin-scott.github.io/2019/11/17/Mac/Mac%E5%AE%89%E8%A3%85npm%E6%BA%90%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/","excerpt":"","text":"nrm 安装","categories":[{"name":"Mac","slug":"Mac","permalink":"https://vincentxin-scott.github.io/categories/Mac/"}],"tags":[{"name":"npm","slug":"npm","permalink":"https://vincentxin-scott.github.io/tags/npm/"}]},{"title":"Mac安装Node.js版本管理工具","slug":"Mac/Mac安装Node.js版本管理工具","date":"2019-11-16T16:01:49.230Z","updated":"2019-12-11T06:49:09.393Z","comments":true,"path":"2019/11/17/Mac/Mac安装Node.js版本管理工具/","link":"","permalink":"https://vincentxin-scott.github.io/2019/11/17/Mac/Mac%E5%AE%89%E8%A3%85Node.js%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/","excerpt":"","text":"nvm 安装配置启动shell","categories":[{"name":"Mac","slug":"Mac","permalink":"https://vincentxin-scott.github.io/categories/Mac/"}],"tags":[{"name":"nvm","slug":"nvm","permalink":"https://vincentxin-scott.github.io/tags/nvm/"}]},{"title":"Oh-my-zsh安装","slug":"Mac/Oh-my-zsh安装","date":"2019-11-16T15:59:27.987Z","updated":"2020-12-08T09:08:10.803Z","comments":true,"path":"2019/11/16/Mac/Oh-my-zsh安装/","link":"","permalink":"https://vincentxin-scott.github.io/2019/11/16/Mac/Oh-my-zsh%E5%AE%89%E8%A3%85/","excerpt":"","text":"什么是Oh My Zsh Oh My Zsh是一款社区驱动的命令行工具，正如它的主页上说的，Oh My Zsh 是一种生活方式。它基于zsh命令行，提供了主题配置，插件机制，已经内置的便捷操作。给我们一种全新的方式使用命令行。 Oh My Zsh这个名字听起来就很有意思，它是基于zsh命令行的一个扩展工具集，提供了丰富的扩展功能。 Oh My Zsh只是一个对zsh命令行环境的配置包装框架，但它不提供命令行窗口，更不是一个独立的APP。 更详细介绍可到官网了解，Oh My Zsh官网：http://ohmyz.sh 安装Oh-my-zsh切换系统默认shell配置主题以及插件","categories":[{"name":"Mac","slug":"Mac","permalink":"https://vincentxin-scott.github.io/categories/Mac/"}],"tags":[{"name":"Oh-my-zsh","slug":"Oh-my-zsh","permalink":"https://vincentxin-scott.github.io/tags/Oh-my-zsh/"}]},{"title":"Mac安装JDK版本管理工具","slug":"Mac/Mac安装JDK版本管理工具","date":"2019-11-16T14:28:52.526Z","updated":"2020-12-08T09:08:06.620Z","comments":true,"path":"2019/11/16/Mac/Mac安装JDK版本管理工具/","link":"","permalink":"https://vincentxin-scott.github.io/2019/11/16/Mac/Mac%E5%AE%89%E8%A3%85JDK%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/","excerpt":"","text":"通过brew 安装JDK版本工具jenv1brew install jenv 为123# jenv java环境切换管理export PATH=&quot;$HOME/.jenv/bin:$PATH&quot;eval &quot;$(jenv init -)&quot; 查询JDK安装路径及版本打开终端，执行 /usr/libexec/java_home -V 结果:","categories":[{"name":"Mac","slug":"Mac","permalink":"https://vincentxin-scott.github.io/categories/Mac/"}],"tags":[{"name":"JDK","slug":"JDK","permalink":"https://vincentxin-scott.github.io/tags/JDK/"}]},{"title":"Lua基础学习(一)","slug":"Lua/Lua基础学习(一)","date":"2019-11-12T05:00:46.849Z","updated":"2020-01-30T15:27:07.250Z","comments":true,"path":"2019/11/12/Lua/Lua基础学习(一)/","link":"","permalink":"https://vincentxin-scott.github.io/2019/11/12/Lua/Lua%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0(%E4%B8%80)/","excerpt":"","text":"简介Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能 特性 轻量级：它用标准C语言编写并以源代码形式开放，编译后仅仅一百余K，可以很方便的嵌入别的程序里。 可扩展：Lua提供了非常易于使用的扩展接口和机制：由宿主语言(通常是C或C++)提供这些功能，Lua可以使用它们，就像是本来就内置的功能一样。 其他特性： 支持面向过程(procedure-oriented)编程和函数式编程(functional programming)； 自动内存管理；只提供了一种通用类型的表（table），用它可以实现数组，哈希表，集合，对象； 语言内置模式匹配；闭包(closure)；函数也可以看做一个值；提供多线程（协同进程，并非操作系统所支持的线程）支持； 通过闭包和table可以很方便地支持面向对象编程所需要的一些关键机制，比如数据抽象，虚函数，继承和重载等。应用场景 游戏开发 独立应用脚本 Web 应用脚本 扩展和数据库插件如：MySQL Proxy 和 MySQL WorkBench 安全系统，如入侵检测系统环境安装mac 安装环境1brew install lua 基础语法交互式编程Lua 交互式编程模式可以通过命令 lua -i 或 lua 来启用：1234Lua 5.3.5 Copyright (C) 1994-2018 Lua.org, PUC-Rio&gt; print(&#x27;vincentxin&#x27;)vincentxin&gt; 脚本式编程我们可以将 Lua 程序代码保持到一个以 lua 结尾的文件，并执行，该模式称为脚本式编程，如我们将如下代码存储在名为 hello.lua 的脚本文件中123456789vim hello.lua-- 编写如下代码print(&quot;Hello World！&quot;)print(&quot;www.runoob.com&quot;)-- 执行lua hello.lua-- 输出内容Hello World！www.runoob.com 标识符Lua 标示符用于定义一个变量，函数获取其他用户定义的项。标示符以一个字母 A 到 Z 或 a 到 z 或下划线 _ 开头后加上0个或多个字母，下划线，数字（0到9）。 最好不要使用下划线加大写字母的标示符，因为Lua的保留字也是这样的。 Lua 不允许使用特殊字符如 @, $, 和 % 来定义标示符。 Lua 是一个区分大小写的编程语言。因此在 Lua 中 Runoob 与 runoob 是两个不同的标示符。以下列出了一些正确的标示符： 关键字以下列出了 Lua 的保留关键字。保留关键字不能作为常量或变量或其他用户自定义标示符： 数据类型Lua 是动态类型语言，变量不要类型定义,只需要为变量赋值。 值可以存储在变量中，作为参数传递或结果返回。 Lua 中有 8 个基本类型分别为：nil、boolean、number、string、userdata、function、thread 和 table。 nilnil 类型表示一种没有任何有效值，它只有一个值 – nil，例如打印一个没有赋值的变量，便会输出一个 nil 值： 123456&gt;type(x)nil&gt;type(x) == nilfalse&gt;type(x) ==&#x27;nil&#x27;true booleanboolean 类型只有两个可选值：true（真） 和 false（假），Lua 把 false 和 nil 看作是”假”，其他的都为”真”: numberLua 默认只有一种 number 类型 – double（双精度）类型（默认类型可以修改 luaconf.h 里的定义），以下几种写法都被看作是 number 类型： string1.字符串有一对双引号或单引号来表示；2.可以用两个方括号”[[]]”来表示“一块字符串”；3.在对一个数字字符串上进行算术操作时，Lua 会尝试将这个数字字符串转成一个数字:4.字符串连接用..5.使用#来计算字符串的长度，放在字符串的前面 table在 Lua 里，table 的创建是通过”构造表达式”来完成，最简单构造表达式是{}，用来创建一个空表。也可以在表里添加一些数据，直接初始化表:Lua 中的表（table）其实是一个”关联数组”（associative arrays），数组的索引可以是数字或者是字符串。在lua里表的默认初始索引一般以1开始table不会固定长度大小，有新数据添加时table长度会自动增长,没有初始的table都是nil。 function在Lua中，函数是被看作是“第一类值”，函数可以存在变量里function可以以匿名函数的方式通过参数传递 thread在 Lua 里，最主要的线程是协同程序（coroutine）。它跟线程（thread）差不多，拥有自己独立的栈、局部变量和指令指针，可以跟其他协同程序共享全局变量和其他大部分东西。 线程跟协程的区别：线程可以同时多个运行，而协程任意时刻只能运行一个，并且处于运行状态的协程只有被挂起（suspend）时才会暂停。 userdatauserdata 是一种用户自定义数据，用于表示一种由应用程序或 C/C++ 语言库所创建的类型，可以将任意 C/C++ 的任意数据类型的数据（通常是 struct 和 指针）存储到 Lua 变量中调用。 Lua变量Lua 变量有三种类型：全局变量、局部变量、表中的域。 Lua 中的变量全是全局变量，那怕是语句块或是函数里，除非用 local 显式声明为局部变量。 局部变量的作用域为从声明位置开始到所在语句块结束。 变量的默认值均为 nil。 赋值语句Lua 可以对多个变量同时赋值，变量列表和值列表的各个元素用逗号分开，赋值语句右边的值会依次赋给左边的变量。 遇到赋值语句Lua会先计算右边所有的值然后再执行赋值操作，所以我们可以这样进行交换变量的值： 当变量个数和值的个数不一致时，Lua会一直以变量个数为基础采取以下策略： 多值赋值经常用来交换变量，或将函数调用返回给变量： f()返回两个值，第一个赋给a，第二个赋给b。 应该尽可能的使用局部变量，有两个好处： 避免命名冲突。 访问局部变量的速度比全局变量更快。索引对 table 的索引使用方括号 []。Lua 也提供了 . 操作。123t[i]t.i -- 当索引为字符串类型时的一种简化写法gettable_event(t,i) -- 采用索引访问本质上是一个类似这样的函数调用 循环while循环1234while(condition)do statementsend for循环数值循环var 从 exp1 变化到 exp2，每次变化以 exp3 为步长递增 var，并执行一次 “执行体”。exp3 是可选的，如果不指定，默认为1。123for var=exp1,exp2,exp3 do &lt;执行体&gt; end 泛型循环泛型 for 循环通过一个迭代器函数来遍历所有值，类似 java 中的 foreach 语句。 Lua 编程语言中泛型 for 循环语法格式: 12345--打印数组a的所有值 a = &#123;&quot;one&quot;, &quot;two&quot;, &quot;three&quot;&#125;for i, v in ipairs(a) do print(i, v)end i是数组索引值，v是对应索引的数组元素值。ipairs是Lua提供的一个迭代器函数，用来迭代数组。 repeat循环循环是在结束的时候判断是否满足要求 123repeat statementsuntil( condition ) goto语句 流程控制语句控制结构的条件表达式结果可以是任何值，Lua认为false和nil为假，true和非nil为真。 要注意的是Lua中 0 为 true： 1234567891011121314if( 布尔表达式 1)then --[ 在布尔表达式 1 为 true 时执行该语句块 --]elseif( 布尔表达式 2)then --[ 在布尔表达式 2 为 true 时执行该语句块 --]elseif( 布尔表达式 3)then --[ 在布尔表达式 3 为 true 时执行该语句块 --]else --[ 如果以上布尔表达式都不为 true 则执行该语句块 --]end 函数Lua 函数主要有两种用途： 1.完成指定的任务，这种情况下函数作为调用语句使用；2.计算并返回值，这种情况下函数作为赋值语句的表达式使用。 1234optional_function_scope function function_name( argument1, argument2, argument3..., argumentn) function_body return result_params_comma_separatedend 解析： optional_function_scope: 该参数是可选的制定函数是全局函数还是局部函数，未设置该参数默认为全局函数，如果你需要设置函数为局部函数需要使用关键字 local。 function_name: 指定函数名称。 argument1, argument2, argument3…, argumentn: 函数参数，多个参数以逗号隔开，函数也可以不带参数。 function_body: 函数体，函数中需要执行的代码语句块。 result_params_comma_separated: 函数返回值，Lua语言函数可以返回多个值，每个值以逗号隔开。 Lua中我们可以将函数作为参数传递给函数 123456789101112myprint = function(param) print(&quot;这是打印函数 - ##&quot;,param,&quot;##&quot;)endfunction add(num1,num2,functionPrint) result = num1 + num2 -- 调用传递的函数参数 functionPrint(result)endmyprint(10)-- myprint 函数作为参数传递add(2,5,myprint) Lua函数可以返回多个结果值，比如string.find，其返回匹配串”开始和结束的下标”（如果不存在匹配串返回nil）。 123&gt; s, e = string.find(&quot;www.runoob.com&quot;, &quot;runoob&quot;) &gt; print(s, e)5 10 Lua 函数可以接受可变数目的参数，和 C 语言类似，在函数参数列表中使用三点 … 表示函数有可变的参数。 我们也可以通过 select(“#”,…) 来获取可变参数的数量: 有时候我们可能需要几个固定参数加上可变参数，固定参数必须放在变长参数之前: 123456function fwrite(fmt, ...) ---&gt; 固定的参数fmt return io.write(string.format(fmt, ...)) endfwrite(&quot;runoob\\n&quot;) ---&gt;fmt = &quot;runoob&quot;, 没有变长参数。 fwrite(&quot;%d%d\\n&quot;, 1, 2) ---&gt;fmt = &quot;%d%d&quot;, 变长参数为 1 和 2 通常在遍历变长参数的时候只需要使用 {…}，然而变长参数可能会包含一些 nil，那么就可以用 select 函数来访问变长参数了：select(‘#’, …) 或者 select(n, …) select(‘#’, …) 返回可变参数的长度select(n, …) 用于访问 n 到 select(‘#’,…) 的参数调用select时，必须传入一个固定实参selector(选择开关)和一系列变长参数。如果selector为数字n,那么select返回它的第n个可变实参，否则只能为字符串”#”,这样select会返回变长参数的总数。例子代码： 12345678910do function foo(...) for i = 1, select(&#x27;#&#x27;, ...) do --&gt;获取参数总数 local arg = select(i, ...); --&gt;读取参数 print(&quot;arg&quot;, arg); end end foo(1, 2, 3, 4); end 运算算术运算符 关系运算符","categories":[{"name":"脚本语言","slug":"脚本语言","permalink":"https://vincentxin-scott.github.io/categories/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://vincentxin-scott.github.io/tags/Lua/"}]},{"title":"Redis应用学习(六)布隆过滤器","slug":"Redis/Redis｜06应用学习(六)布隆过滤器","date":"2019-11-06T09:25:57.618Z","updated":"2021-01-28T07:49:44.750Z","comments":true,"path":"2019/11/06/Redis/Redis｜06应用学习(六)布隆过滤器/","link":"","permalink":"https://vincentxin-scott.github.io/2019/11/06/Redis/Redis%EF%BD%9C06%E5%BA%94%E7%94%A8%E5%AD%A6%E4%B9%A0(%E5%85%AD)%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","excerpt":"","text":"介绍但是如果我们想知道某一个值是不是已经在 HyperLogLog 结构里面了，它就无能为力了，它只提供了 pfadd 和 pfcount 方法，没有提供 pfcontains 这种方法。 讲个使用场景，比如我们在使用新闻客户端看新闻时，它会给我们不停地推荐新的内容，它每次推荐时要去重，去掉那些已经看过的内容。问题来了，新闻客户端推荐系统如何实现推送去重的？ 你会想到服务器记录了用户看过的所有历史记录，当推荐系统推荐新闻时会从每个用户的历史记录里进行筛选，过滤掉那些已经存在的记录。问题是当用户量很大，每个用户看过的新闻又很多的情况下，这种方式，推荐系统的去重工作在性能上跟的上么？ 由于关系型数据库受到并发IO的限制，所以用关系型数据库去存储用户历史数据频繁的读取是非常不利于系统性能的。如果使用纯内存对用户历史数据进行存储在用户量很大和用户使用周期很长的情况下对内存的占用非常高，需要不断追加内存。方案不可取 因此布隆过滤器诞生解决这个问题，它是准们用来解决去重问题的同时，在空间上还能节省百分之九十以上。只是稍微有点点不精确，也就是有一定的误判概率 布隆过滤器是什么？布隆过滤器可以理解为一个不怎么精确的set结构，当布隆过滤器说某个值存在时，这个值可不能不存在;当它说不存在时候，那就肯定不存在。 布隆过滤器能准确过滤掉那些已经看过的内容，那些没有看过的新内容，它也会过滤掉极小一部分 (误判)，但是绝大多数新内容它都能准确识别。这样就可以完全保证推荐给用户的内容都是无重复的。 Redis中的布隆过滤器","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://vincentxin-scott.github.io/tags/Redis/"}]},{"title":"Redis应用学习(五)HyperLoglog","slug":"Redis/Redis｜05应用学习(五)HyperLoglog","date":"2019-11-06T06:55:07.137Z","updated":"2021-01-28T07:49:36.323Z","comments":true,"path":"2019/11/06/Redis/Redis｜05应用学习(五)HyperLoglog/","link":"","permalink":"https://vincentxin-scott.github.io/2019/11/06/Redis/Redis%EF%BD%9C05%E5%BA%94%E7%94%A8%E5%AD%A6%E4%B9%A0(%E4%BA%94)HyperLoglog/","excerpt":"","text":"介绍在开始这一节之前，我们先思考一个常见的业务问题：如果你负责开发维护一个大型的网站，有一天老板找产品经理要网站每个网页每天的 UV 数据，然后让你来开发这个统计模块，你会如何实现？ 如果统计 PV 那非常好办，给每个网页一个独立的 Redis 计数器就可以了，这个计数器的 key 后缀加上当天的日期。这样来一个请求，incrby 一次，最终就可以统计出所有的 PV 数据。 但是 UV 不一样，它要去重，同一个用户一天之内的多次访问请求只能计数一次。这就要求每一个网页请求都需要带上用户的 ID，无论是登陆用户还是未登陆用户都需要一个唯一 ID 来标识。 你也许已经想到了一个简单的方案，那就是为每一个页面一个独立的 set 集合来存储所有当天访问过此页面的用户 ID。当一个请求过来时，我们使用 sadd 将用户 ID 塞进去就可以了。通过 scard 可以取出这个集合的大小，这个数字就是这个页面的 UV 数据。没错，这是一个非常简单的方案。 但是，如果你的页面访问量非常大，比如一个爆款页面几千万的 UV，你需要一个很大的 set 集合来统计，这就非常浪费空间。如果这样的页面很多，那所需要的存储空间是惊人的。为这样一个去重功能就耗费这样多的存储空间，值得么？其实老板需要的数据又不需要太精确，105w 和 106w 这两个数字对于老板们来说并没有多大区别，So，有没有更好的解决方案呢？ 这就是本节要引入的一个解决方案，Redis 提供了 HyperLogLog 数据结构就是用来解决这种统计问题的。HyperLogLog 提供不精确的去重计数方案，虽然不精确但是也不是非常不精确，标准误差是 0.81%，这样的精确度已经可以满足上面的 UV 统计需求了。 HyperLogLog 数据结构是 Redis 的高级数据结构，它非常有用，但是令人感到意外的是，使用过它的人非常少。 使用方法HyperLoglog 提供了两个指令pfadd和pfcount，根据字面意思很好理解，一个是增加计数，一个是获取计数。pfadd用法和set集合的sadd是一样的，来一个用户ID，就将用户ID塞进去就是。pfcount和scard用法是一样的。直接获取计数值。 12345678910111213141516171819202122232425262728127.0.0.1:6379&gt; pfadd codehole user1(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 1127.0.0.1:6379&gt; pfadd codehole user2(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 2127.0.0.1:6379&gt; pfadd codehole user3(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 3127.0.0.1:6379&gt; pfadd codehole user4(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 4127.0.0.1:6379&gt; pfadd codehole user5(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 5127.0.0.1:6379&gt; pfadd codehole user6(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 6127.0.0.1:6379&gt; pfadd codehole user7 user8 user9 user10(integer) 1127.0.0.1:6379&gt; pfcount codehole(integer) 10 简单试了一下，发现还蛮精确的，一个没多也一个没少。接下来我们使用脚本，往里面灌更多的数据，看看它是否还可以继续精确下去，如果不能精确，差距有多大。人生苦短，我用 Python！Python 脚本走起来！😄Python 123456789import redisclient = redis.StrictRedis()for i in range(1000): client.pfadd(&quot;codehole&quot;, &quot;user%d&quot; % i) total = client.pfcount(&quot;codehole&quot;) if total != i+1: print total, i+1 break Java 1234567891011121314public class PfTest &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(); for (int i = 0; i &lt; 1000; i++) &#123; jedis.pfadd(&quot;codehole&quot;, &quot;user&quot; + i); long total = jedis.pfcount(&quot;codehole&quot;); if (total != i + 1) &#123; System.out.printf(&quot;%d %d\\n&quot;, total, i + 1); break; &#125; &#125; jedis.close(); &#125;&#125; pfadd 这个pf是什么意思？它是 HyperLogLog 这个数据结构的发明人 Philippe Flajolet 的首字母缩写，老师觉得他发型很酷，看起来是个佛系教授。 pfmerge 适合什么场合用？HyperLogLog 除了上面的 pfadd 和 pfcount 之外，还提供了第三个指令 pfmerge，用于将多个 pf 计数值累加在一起形成一个新的 pf 值。 比如在网站中我们有两个内容差不多的页面，运营说需要这两个页面的数据进行合并。其中页面的 UV 访问量也需要合并，那这个时候 pfmerge 就可以派上用场了。 注意事项HyperLogLog 这个数据结构不是免费的，不是说使用这个数据结构要花钱，它需要占据一定 12k 的存储空间，所以它不适合统计单个用户相关的数据。如果你的用户上亿，可以算算，这个空间成本是非常惊人的。但是相比 set 存储方案，HyperLogLog 所使用的空间那真是可以使用千斤对比四两来形容了。 不过你也不必过于担心，因为 Redis 对 HyperLogLog 的存储进行了优化，在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://vincentxin-scott.github.io/tags/Redis/"}]},{"title":"Redis应用学习(三)延时队列","slug":"Redis/Redis｜03应用学习(三)延时队列","date":"2019-11-06T06:50:23.829Z","updated":"2021-01-28T07:49:08.712Z","comments":true,"path":"2019/11/06/Redis/Redis｜03应用学习(三)延时队列/","link":"","permalink":"https://vincentxin-scott.github.io/2019/11/06/Redis/Redis%EF%BD%9C03%E5%BA%94%E7%94%A8%E5%AD%A6%E4%B9%A0(%E4%B8%89)%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97/","excerpt":"","text":"介绍我们平时习惯于使用 Rabbitmq 和 Kafka 作为消息队列中间件，来给应用程序之间增加异步消息传递功能。这两个中间件都是专业的消息队列中间件，特性之多超出了大多数人的理解能力。 使用过 Rabbitmq 的同学知道它使用起来有多复杂，发消息之前要创建 Exchange，再创建 Queue，还要将 Queue 和 Exchange 通过某种规则绑定起来，发消息的时候要指定 routing-key，还要控制头部信息。消费者在消费消息之前也要进行上面一系列的繁琐过程。但是绝大多数情况下，虽然我们的消息队列只有一组消费者，但还是需要经历上面这些繁琐的过程。 有了 Redis，它就可以让我们解脱出来，对于那些只有一组消费者的消息队列，使用 Redis 就可以非常轻松的搞定。Redis 的消息队列不是专业的消息队列，它没有非常多的高级特性，没有 ack 保证，如果对消息的可靠性有着极致的追求，那么它就不适合使用。 异步消息队列Redis 的 list(列表) 数据结构常用来作为异步消息队列使用，使用rpush/lpush操作入队列，使用lpop 和 rpop来出队列。 123456789101112131415161718&gt; rpush notify-queue apple banana pear(integer) 3&gt; llen notify-queue(integer) 3&gt; lpop notify-queue&quot;apple&quot;&gt; llen notify-queue(integer) 2&gt; lpop notify-queue&quot;banana&quot;&gt; llen notify-queue(integer) 1&gt; lpop notify-queue&quot;pear&quot;&gt; llen notify-queue(integer) 0&gt; lpop notify-queue(nil) 上面是 rpush 和 lpop 结合使用的例子。还可以使用 lpush 和 rpop 结合使用，效果是一样的。 队列空了怎么办？客户端是通过队列的 pop 操作来获取消息，然后进行处理。处理完了再接着获取消息，再进行处理。如此循环往复，这便是作为队列消费者的客户端的生命周期。 可是如果队列空了，客户端就会陷入 pop 的死循环，不停地 pop，没有数据，接着再 pop，又没有数据。这就是浪费生命的空轮询。空轮询不但拉高了客户端的 CPU，redis 的 QPS 也会被拉高，如果这样空轮询的客户端有几十来个，Redis 的慢查询可能会显著增多。 通常我们使用 sleep 来解决这个问题，让线程睡一会，睡个 1s 钟就可以了。不但客户端的 CPU 能降下来，Redis 的 QPS 也降下来了。 12time.sleep(1) # python 睡 1sThread.sleep(1000) # java 睡 1s","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://vincentxin-scott.github.io/tags/Redis/"}]},{"title":"Redis应用学习(四)位图","slug":"Redis/Redis｜04应用学习(四)位图","date":"2019-11-06T00:42:02.867Z","updated":"2021-01-28T07:49:28.500Z","comments":true,"path":"2019/11/06/Redis/Redis｜04应用学习(四)位图/","link":"","permalink":"https://vincentxin-scott.github.io/2019/11/06/Redis/Redis%EF%BD%9C04%E5%BA%94%E7%94%A8%E5%AD%A6%E4%B9%A0(%E5%9B%9B)%E4%BD%8D%E5%9B%BE/","excerpt":"","text":"介绍在我们平时开发过程中，会有一些 bool 型数据需要存取，比如用户一年的签到记录，签了是 1，没签是 0，要记录 365 天。如果使用普通的 key/value，每个用户要记录 365 个，当用户上亿的时候，需要的存储空间是惊人的。 为了解决这个问题，Redis 提供了位图数据结构，这样每天的签到记录只占据一个位，365 天就是 365 个位，46 个字节 (一个稍长一点的字符串) 就可以完全容纳下，这就大大节约了存储空间。 位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组。我们可以使用普通的 get/set 直接获取和设置整个位图的内容，也可以使用位图操作 getbit/setbit 等将 byte 数组看成「位数组」来处理。 当我们要统计月活的时候，因为需要去重，需要使用 set 来记录所有活跃用户的 id，这非常浪费内存。这时就可以考虑使用位图来标记用户的活跃状态。每个用户会都在这个位图的一个确定位置上，0 表示不活跃，1 表示活跃。然后到月底遍历一次位图就可以得到月度活跃用户数。不过这个方法也是有条件的，那就是 userid 是整数连续的，并且活跃占比较高，否则可能得不偿失。 本节略显枯燥，如果读者看的有点蒙，这是正常现象，读者可以跳过阅读下一节。以老钱的经验，在面试中有 Redis 位图使用经验的同学很少，如果你对 Redis 的位图有所了解，它将会是你的面试加分项。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://vincentxin-scott.github.io/tags/Redis/"}]},{"title":"Redis应用学习(二)分布式锁","slug":"Redis/Redis｜02应用学习(二)分布式锁","date":"2019-11-05T09:02:31.509Z","updated":"2021-01-28T07:49:17.312Z","comments":true,"path":"2019/11/05/Redis/Redis｜02应用学习(二)分布式锁/","link":"","permalink":"https://vincentxin-scott.github.io/2019/11/05/Redis/Redis%EF%BD%9C02%E5%BA%94%E7%94%A8%E5%AD%A6%E4%B9%A0(%E4%BA%8C)%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","excerpt":"","text":"介绍分布式应用进行逻辑处理时经常会遇到并发问题。 比如一个操作要修改用户的状态，修改状态需要先读出用户的状态，在内存里进行修改，改完了再存回去。如果这样的操作同时进行了，就会出现并发问题，因为读取和保存状态这两个操作不是原子的。（Wiki 解释：所谓原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch 线程切换。） 这个时候就要使用到分布式锁来限制程序的并发执行。Redis 分布式锁使用非常广泛，它是面试的重要考点之一，很多同学都知道这个知识，也大致知道分布式锁的原理，但是具体到细节的使用上往往并不完全正确。 分布式锁分布式锁本质上要实现的目标就是在 Redis 里面占一个“茅坑”，当别的进程也要来占时，发现已经有人蹲在那里了，就只好放弃或者稍后再试。 占坑一般是使用 setnx(set if not exists) 指令，只允许被一个客户端占坑。先来先占， 用完了，再调用 del 指令释放茅坑。 123456// 这里的冒号:就是一个普通的字符，没特别含义，它可以是任意其它字符，不要误解&gt; setnx lock:codehole trueOK... do something critical ...&gt; del lock:codehole(integer) 1 但是有个问题，如果逻辑执行到中间出现异常了，可能会导致 del 指令没有被调用，这样就会陷入死锁，锁永远得不到释放。 于是我们在拿到锁之后，再给锁加上一个过期时间，比如 5s，这样即使中间出现异常也可以保证 5 秒之后锁会自动释放。 123456&gt; setnx lock:codehole trueOK&gt; expire lock:codehole 5... do something critical ...&gt; del lock:codehole(integer) 1 但是以上逻辑还有问题。如果在 setnx 和 expire 之间服务器进程突然挂掉了，可能是因为机器掉电或者是被人为杀掉的，就会导致 expire 得不到执行，也会造成死锁。 这种问题的根源就在于 setnx 和 expire 是两条指令而不是原子指令。如果这两条指令可以一起执行就不会出现问题。也许你会想到用 Redis 事务来解决。但是这里不行，因为 expire 是依赖于 setnx 的执行结果的，如果 setnx 没抢到锁，expire 是不应该执行的。事务里没有 if-else 分支逻辑，事务的特点是一口气执行，要么全部执行要么一个都不执行。 为了解决这个疑难，Redis 开源社区涌现了一堆分布式锁的 library，专门用来解决这个问题。实现方法极为复杂，小白用户一般要费很大的精力才可以搞懂。如果你需要使用分布式锁，意味着你不能仅仅使用 Jedis 或者 redis-py 就行了，还得引入分布式锁的 library。 为了治理这个乱象，Redis 2.8 版本中作者加入了 set 指令的扩展参数，使得 setnx 和 expire 指令可以一起执行，彻底解决了分布式锁的乱象。从此以后所有的第三方分布式锁 library 可以休息了。 1234&gt; set lock:codehole true ex 5 nxOK... do something critical ...&gt; del lock:codehole 上面这个指令就是 setnx 和 expire 组合在一起的原子指令，它就是分布式锁的奥义所在。 超时问题Redis 的分布式锁不能解决超时问题，如果在加锁和释放锁之间的逻辑执行的太长，以至于超出了锁的超时限制，就会出现问题。因为这时候第一个线程持有的锁过期了，临界区的逻辑还没有执行完，这个时候第二个线程就提前重新持有了这把锁，导致临界区代码不能得到严格的串行执行。 为了避免这个问题，Redis 分布式锁不要用于较长时间的任务。如果真的偶尔出现了，数据出现的小波错乱可能需要人工介入解决。 12345tag &#x3D; random.nextint() # 随机数if redis.set(key, tag, nx&#x3D;True, ex&#x3D;5): do_something() redis.delifequals(key, tag) # 假想的 delifequals 指令 有一个稍微安全一点的方案是为 set 指令的 value 参数设置为一个随机数，释放锁时先匹配随机数是否一致，然后再删除 key，这是为了确保当前线程占有的锁不会被其它线程释放，除非这个锁是过期了被服务器自动释放的。 但是匹配 value 和删除 key 不是一个原子操作，Redis 也没有提供类似于delifequals这样的指令，这就需要使用 Lua 脚本来处理了，因为 Lua 脚本可以保证连续多个指令的原子性执行。 123456# delifequalsif redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then return redis.call(&quot;del&quot;,KEYS[1])else return 0end 但是这也不是一个完美的方案，它只是相对安全一点，因为如果真的超时了，当前线程的逻辑没有执行完，其它线程也会乘虚而入。 可重入性可重入性是指线程在持有锁的情况下再次请求加锁，如果一个锁支持同一个线程的多次加锁，那么这个锁就是可重入的。比如 Java 语言里有个 ReentrantLock 就是可重入锁。Redis 分布式锁如果要支持可重入，需要对客户端的 set 方法进行包装，使用线程的 Threadlocal 变量存储当前持有锁的计数。 12345678910111213141516171819202122232425262728293031323334353637383940414243# -*- coding: utf-8import redisimport threadinglocks = threading.local()locks.redis = &#123;&#125;def key_for(user_id): return &quot;account_&#123;&#125;&quot;.format(user_id)def _lock(client, key): return bool(client.set(key, True, nx=True, ex=5))def _unlock(client, key): client.delete(key)def lock(client, user_id): key = key_for(user_id) if key in locks.redis: locks.redis[key] += 1 return True ok = _lock(client, key) if not ok: return False locks.redis[key] = 1 return Truedef unlock(client, user_id): key = key_for(user_id) if key in locks.redis: locks.redis[key] -= 1 if locks.redis[key] &lt;= 0: del locks.redis[key] self._unlock(key) return True return Falseclient = redis.StrictRedis()print &quot;lock&quot;, lock(client, &quot;codehole&quot;)print &quot;lock&quot;, lock(client, &quot;codehole&quot;)print &quot;unlock&quot;, unlock(client, &quot;codehole&quot;)print &quot;unlock&quot;, unlock(client, &quot;codehole&quot;) 以上还不是可重入锁的全部，精确一点还需要考虑内存锁计数的过期时间，代码复杂度将会继续升高。老钱不推荐使用可重入锁，它加重了客户端的复杂性，在编写业务方法时注意在逻辑结构上进行调整完全可以不使用可重入锁。下面是 Java 版本的可重入锁 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class RedisWithReentrantLock &#123; private ThreadLocal&lt;Map&lt;String, Integer&gt;&gt; lockers &#x3D; new ThreadLocal&lt;&gt;(); private Jedis jedis; public RedisWithReentrantLock(Jedis jedis) &#123; this.jedis &#x3D; jedis; &#125; private boolean _lock(String key) &#123; return jedis.set(key, &quot;&quot;, &quot;nx&quot;, &quot;ex&quot;, 5L) !&#x3D; null; &#125; private void _unlock(String key) &#123; jedis.del(key); &#125; private Map&lt;String, Integer&gt; currentLockers() &#123; Map&lt;String, Integer&gt; refs &#x3D; lockers.get(); if (refs !&#x3D; null) &#123; return refs; &#125; lockers.set(new HashMap&lt;&gt;()); return lockers.get(); &#125; public boolean lock(String key) &#123; Map&lt;String, Integer&gt; refs &#x3D; currentLockers(); Integer refCnt &#x3D; refs.get(key); if (refCnt !&#x3D; null) &#123; refs.put(key, refCnt + 1); return true; &#125; boolean ok &#x3D; this._lock(key); if (!ok) &#123; return false; &#125; refs.put(key, 1); return true; &#125; public boolean unlock(String key) &#123; Map&lt;String, Integer&gt; refs &#x3D; currentLockers(); Integer refCnt &#x3D; refs.get(key); if (refCnt &#x3D;&#x3D; null) &#123; return false; &#125; refCnt -&#x3D; 1; if (refCnt &gt; 0) &#123; refs.put(key, refCnt); &#125; else &#123; refs.remove(key); this._unlock(key); &#125; return true; &#125; public static void main(String[] args) &#123; Jedis jedis &#x3D; new Jedis(); RedisWithReentrantLock redis &#x3D; new RedisWithReentrantLock(jedis); System.out.println(redis.lock(&quot;codehole&quot;)); System.out.println(redis.lock(&quot;codehole&quot;)); System.out.println(redis.unlock(&quot;codehole&quot;)); System.out.println(redis.unlock(&quot;codehole&quot;)); &#125;&#125;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://vincentxin-scott.github.io/tags/Redis/"}]},{"title":"Docker(一)概要","slug":"Docker/docker | 01入门概要","date":"2019-11-05T02:12:42.325Z","updated":"2020-03-06T02:56:34.574Z","comments":true,"path":"2019/11/05/Docker/docker | 01入门概要/","link":"","permalink":"https://vincentxin-scott.github.io/2019/11/05/Docker/docker%20|%2001%E5%85%A5%E9%97%A8%E6%A6%82%E8%A6%81/","excerpt":"","text":"什么是DockerDocker 是一个开源的应用容器引擎，基于 Go 语言并遵从Apache2.0协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。Docker 利用 Linux 核心中的资源分脱机制，例如 cgroups ，以及 Linux 核心名字空间（name space），来创建独立的软件容器（containers）。 docker是一个开源的软件部署解决方案； docker也是轻量级的应用容器框架； docker可以打包、发布、运行任何的应用。Docker与虚拟机的区别传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为MB 一般为GB 性能 接近原生 弱于原生 系统支持量 单机支持上千容器 一般几十个 Docker能解决什么问题 更高效的利用系统资源由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。 一致的运行环境开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 持续交付和部署对开发和运维（DevOps）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 Dockerfile 来进行镜像构建，并结合 持续集成(Continuous Integration) 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署(Continuous Delivery/Deployment) 系统进行自动部署。而且使用 Dockerfile 使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。 更轻松的迁移由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。 更轻松的维护和扩展Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker 团队同各个开源项目团队一起维护了一大批高质量的官方镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 简化环境管理:传统的软件开发与发布环境复杂，配置繁琐，经常有读者在微信上问：我的代码开发环境可以运行，一旦部署到服务器上就运行不了了。这个问题很常见，也确实很烦人，但是问题总要解决，开发环境、测试环境、生产环境，每个环节都有可能出现这样那样的问题，如果能够在各个环境中实现一键部署，就会方便很多，例如一键安装 linux 、一键安装 mysql、一键安装 nginx 等，docker 彻底解决了这个问题。 虚拟化更加轻量级:说到容器，说到虚拟化，很多人总会想到虚拟机，想到 VMware、VirtualBox 等工具，不同于这些虚拟技术，docker 虚拟化更加轻量级，传统的虚拟机都是先虚拟出一个操作系统，然后在操作系统上完成各种各样的配置，这样并不能充分的利用物理机的性能，docker 则是一种操作系统级别的虚拟技术，它运行在操作系统之上的用户空间，所有的容器都共用一个系统内核甚至公共库，容器引擎提供了进程级别的隔离，让每个容器都像运行在单独的系统之上，但是又能够共享很多底层资源。因此 docker 更为轻量、快速和易于管理。 Web应用的自动化打包和发布。 自动化测试和持续集成、发布。 在服务型环境中部署和调整数据库或其他的后台应用。 从头编译或者扩展现有的OpenShift或Cloud Foundry平台来搭建自己的PaaS环境。 OpenShift:是美国国家航空航天局和Rackspace合作研发的云计算软件，以Apache授权条款授权，并且是自由和开放源代码软件。OpenStack是基础设施即服务（IaaS）软件，让任何人都可以自行创建和提供云计算服务。 Cloud Foundry: Docker基本概念Docker镜像我们都知道，操作系统分为内核和用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而 Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu:18.04 就包含了完整的一套 Ubuntu 18.04 最小系统的 root 文件系统。 Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。 分层存储:因为镜像包含操作系统完整的 root 文件系统，其体积往往是庞大的，因此在 Docker 设计时，就充分利用 Union FS 的技术，将其设计为分层存储的架构。所以严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 Docker容器镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。 前面讲过镜像使用的是分层存储，容器也是如此。每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层，我们可以称这个为容器运行时读写而准备的存储层为 容器存储层。 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。 数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。 Docker Registry Docker仓库镜像构建完成后，可以很容易的在当前宿主机上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。 一个 Docker Registry 中可以包含多个 仓库（Repository）；每个仓库可以包含多个 标签（Tag）；每个标签对应一个镜像。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://vincentxin-scott.github.io/categories/DevOps/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://vincentxin-scott.github.io/tags/Docker/"}]},{"title":"MySQL基础篇-基础架构","slug":"数据库/MySQL/mysql｜01基础架构","date":"2019-10-14T04:29:54.393Z","updated":"2020-04-23T01:23:36.773Z","comments":true,"path":"2019/10/14/数据库/MySQL/mysql｜01基础架构/","link":"","permalink":"https://vincentxin-scott.github.io/2019/10/14/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/mysql%EF%BD%9C01%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/","excerpt":"","text":"基础架构：一条SQL查询语句是如何执行的MySQL 的逻辑架构图 MySQL可以分为Server层和存储引擎两部分: 一、Server层包括连接器、查询缓存、分析器、优化器、执行器等。涵盖MySQL的大多数核心服务功能，以及所有的内置函数（时间，日期，数学和加密函数等），所有跨存储引擎的功能都在这一层实现，存储过程、触发器、视图等。二、存储引擎层 负责数据的存储和提取 其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多种存储和引擎。 连接器第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维护和管理连接。 1mysql -h ip -p port -u user -p password 首先认证用户名密码 之后连接器会到权限表里面查询出你拥有的权限，这个连接里面的权限判断逻辑都依赖于此时读到的权限 也就是说当用户建立连接之后，即使你对这个用户权限做了修改也不会即使有生效，只有再新建连接才会使新的权限生效。 完成连接后 可以通过show processlist命令查看他。 客户端如果太长时间没有动静，连接器就会自动断开，这个时间是由参数wait_timeout控制的，默认值是8小时。 如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒：Lost connection to MySQL server during query。这时候如果你要是继续，就需要重连，然后再执行请求了。 数据库里面： 长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。 短连接则是指每次执行完很少的几次查询就断开连接，下次查询重新建立一个。 建立连接的过程通常是比较复杂的，所以在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。 但是全部使用长连接后，MySQL占用内存涨的贴别快，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累计下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。 怎么解决这个问题呢？可以考虑两种方案 定期断开长连接，使用一段时间，或者程序里面判断执行过过一个占用内存的大查询后，断开连接，之后要查询再重连。 如果你用的是MySQL5.7或者更新版本，可以每次执行一个比较大的操作之后，通过执行mysql_reset_connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 查询缓存MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句机器结果都会以key-value对的形式被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。 实际生产中不要使用查询缓存，只要对一个表更新这个表上所有的查询缓存都会被清空。 MySQL也提供了“按需使用”的方式。你可以将参数query_cache_type设置成DEMAND，这样对于默认的SQL语句都不实用查询缓存。对于你确定要使用查询缓存的语句，可以用SQL_CACHE显示指定。像下面这个语句一样： 12select SQL_CACHE * from T where ID=10； 需要注意，MySQL8.0之后取消了查询缓存的整块功能。 分析器一、 分析器先做“词法分析”。 MySQL 从你输入的“select”这个关键子识别出来，这是个查询语句。他也要把字符串“T”识别成“表名T”，把字符串“ID” 识别成“列ID”。 二、 接着分析器做“语法分析” 根据词法分析结果，语法分析器会根据语法规定，判断你输入的这个SQL语句是否满足MySQL语法。 优化器优化器是在表里面有多个索引的时候，决定使用那个索引；或者在一个语句有多个表关联的时候，决定各个表的连接顺序。 执行器开始执行的时候，要先判断一下你对这个表有没有执行查询的权限，如果没有，就会返回没有权限的错误，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用precheck验证权限。 查询表，ID字段没有索引，那么执行器的执行流程是这样的： 调用InnoDB 引擎接口取这个表的第一行，判断ID值是不是符合，如果不是则跳过，如果是则将这行存在结果集中； 调用引擎接口取下一行，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历姑婆成中所有满足条件的行组成的记录集作为结果返回给客户端。 对于有索引的表，第一次调用的是取满足条件的第一行这个接口，之后循环取满足条件的下一行这个接口（这些接口都是引擎中已经定义好的）。 你会在满查询的日志中看到一个rows_examined的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。 在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"}]},{"title":"Redis基础学习(一)","slug":"Redis/Redis｜01基础学习(一)","date":"2019-09-10T09:08:24.653Z","updated":"2021-01-28T07:48:51.025Z","comments":true,"path":"2019/09/10/Redis/Redis｜01基础学习(一)/","link":"","permalink":"https://vincentxin-scott.github.io/2019/09/10/Redis/Redis%EF%BD%9C01%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0(%E4%B8%80)/","excerpt":"","text":"Redis安装Docker 安装Redis123456# 拉取 redis 镜像&gt; docker pull redis# 运行 redis 容器&gt; docker run --name myredis -d -p6379:6379 redis# 执行容器中的 redis-cli，可以直接使用命令行操作 redis&gt; docker exec -it myredis redis-cli GitHub源码编译方式12345678910# 下载源码&gt; git clone --branch 2.8 --depth 1 git@github.com:antirez/redis.git&gt; cd redis# 编译&gt; make&gt; cd src# 运行服务器，daemonize表示在后台运行&gt; ./redis-server --daemonize yes# 运行命令行&gt; ./redis-cli 直接安装的方式12345678# mac&gt; brew install redis# ubuntu&gt; apt-get install redis# redhat&gt; yum install redis# 运行客户端&gt; redis-cli Redis基础数据结构Redis 有 5 种基础数据结构，分别为：string (字符串)、list (列表)、set (集合)、hash (哈希) 和 zset (有序集合)。熟练掌握这 5 种基本数据结构的使用是 Redis 知识最基础也最重要的部分，它也是在 Redis 面试题中问到最多的内容。 String （字符串）字符串 string 是 Redis 最简单的数据结构。Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。不同类型的数据结构的差异就在于 value 的结构不一样。 内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度。当字符串长度小于1M时，扩容都是加倍现有的空间。如果超过1M，扩容时只会多扩1M的空间。字符串最大长度为512M。 键值对：12345678910&gt; set name codeholeOK&gt; get name&quot;codehole&quot;&gt; exists name(integer) 1&gt; del name(integer) 1&gt; get name(nil) 批量键值对：1234567891011121314可以批量对多个字符串进行读写，节省网络 耗时开销&gt; set name1 codeholeOK&gt; set name2 holycoderOK&gt; mget name1 name2 name3 # 返回一个列表1) &quot;codehole&quot;2) &quot;holycoder&quot;3) (nil)&gt; mset name1 boy name2 girl name3 unknown&gt; mget name1 name2 name31) &quot;boy&quot;2) &quot;girl&quot;3) &quot;unknown&quot; 过期和set命令扩展这个功能常用来控制缓存的失效时间。不过这个「自动删除」的机制是比较复杂的 1234567891011121314151617181920212223&gt; set name codehole&gt; get name&quot;codehole&quot;&gt; expire name 5 # 5s 后过期... # wait for 5s&gt; get name(nil)&gt; setex name 5 codehole # 5s 后过期，等价于 set+expire&gt; get name&quot;codehole&quot;... # wait for 5s&gt; get name(nil)&gt; setnx name codehole # 如果 name 不存在就执行 set 创建(integer) 1&gt; get name&quot;codehole&quot;&gt; setnx name holycoder(integer) 0 # 因为 name 已经存在，所以 set 创建不成功&gt; get name&quot;codehole&quot; # 没有改变 计数：如果 value 值是一个整数，还可以对它进行自增操作。自增是有范围的，它的范围是 signed long 的最大最小值，超过了这个值，Redis 会报错。 123456789101112&gt; set age 30OK&gt; incr age(integer) 31&gt; incrby age 5(integer) 36&gt; incrby age -5(integer) 31&gt; set codehole 9223372036854775807 # Long.MaxOK&gt; incr codehole(error) ERR increment or decrement would overflow 字符串是由多个字节组成，每个字节又是由 8 个 bit 组成，如此便可以将一个字符串看成很多 bit 的组合，这便是 bitmap「位图」数据结构，位图的具体使用会放到后面的章节来讲。 list(列表)Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)，这点让人非常意外。 当列表弹出了最后一个元素之后，该数据结构自动被删除，内存被回收。 Redis 的列表结构常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理。 右边进左边出：队列 (FILO)123456789101112&gt; rpush books python java golang(integer) 3&gt; llen books(integer) 3&gt; lpop books&quot;python&quot;&gt; lpop books&quot;java&quot;&gt; lpop books&quot;golang&quot;&gt; lpop books(nil) 右边进右边出：栈 (FIFO)12345678910&gt; rpush books python java golang(integer) 3&gt; rpop books&quot;golang&quot;&gt; rpop books&quot;java&quot;&gt; rpop books&quot;python&quot;&gt; rpop books(nil) 慢操作lindex 相当于 Java 链表的get(int index)方法，它需要对链表进行遍历，性能随着参数index增大而变差。 ltrim 和字面上的含义不太一样，个人觉得它叫 lretain(保留) 更合适一些，因为 ltrim 跟的两个参数start_index和end_index定义了一个区间，在这个区间内的值，ltrim 要保留，区间之外统统砍掉。我们可以通过ltrim来实现一个定长的链表，这一点非常有用。 index 可以为负数，index=-1表示倒数第一个元素，同样index=-2表示倒数第二个元素。 1234567891011121314151617&gt; rpush books python java golang(integer) 3&gt; lindex books 1 # O(n) 慎用&quot;java&quot;&gt; lrange books 0 -1 # 获取所有元素，O(n) 慎用1) &quot;python&quot;2) &quot;java&quot;3) &quot;golang&quot;&gt; ltrim books 1 -1 # O(n) 慎用OK&gt; lrange books 0 -11) &quot;java&quot;2) &quot;golang&quot;&gt; ltrim books 1 0 # 这其实是清空了整个列表，因为区间范围长度为负OK&gt; llen books(integer) 0 快速列表ziplist 如果再深入一点，你会发现 Redis 底层存储的还不是一个简单的 linkedlist，而是称之为快速链表 quicklist 的一个结构。 首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 ziplist，也即是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当数据量比较多的时候才会改成 quicklist。因为普通的链表需要的附加指针空间太大，会比较浪费空间，而且会加重内存的碎片化。比如这个列表里存的只是 int 类型的数据，结构上还需要两个额外的指针 prev 和 next 。所以 Redis 将链表和 ziplist 结合起来组成了 quicklist。也就是将多个 ziplist 使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。 hash(字典)Redis 的字典相当于 Java 语言里面的 HashMap，它是无序字典。内部实现结构上同 Java 的 HashMap 也是一致的，同样的数组 + 链表二维结构。第一维 hash 的数组位置碰撞时，就会将碰撞的元素使用链表串接起来。 不同的是，Redis 的字典的值只能是字符串，另外它们 rehash 的方式不一样，因为 Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。Redis 为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。 渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个 hash 结构，然后在后续的定时任务中以及 hash 操作指令中，循序渐进地将旧 hash 的内容一点点迁移到新的 hash 结构中。当搬迁完成了，就会使用新的hash结构取而代之。 hash 结构也可以用来存储用户信息，不同于字符串一次性需要全部序列化整个对象，hash 可以对用户结构中的每个字段单独存储。这样当我们需要获取用户信息时可以进行部分获取。而以整个字符串的形式去保存用户信息的话就只能一次性全部读取，这样就会比较浪费网络流量。 hash 也有缺点，hash 结构的存储消耗要高于单个字符串，到底该使用 hash 还是字符串，需要根据实际情况再三权衡。 1234567891011121314151617181920212223&gt; hset books java &quot;think in java&quot; # 命令行的字符串如果包含空格，要用引号括起来(integer) 1&gt; hset books golang &quot;concurrency in go&quot;(integer) 1&gt; hset books python &quot;python cookbook&quot;(integer) 1&gt; hgetall books # entries()，key 和 value 间隔出现1) &quot;java&quot;2) &quot;think in java&quot;3) &quot;golang&quot;4) &quot;concurrency in go&quot;5) &quot;python&quot;6) &quot;python cookbook&quot;&gt; hlen books(integer) 3&gt; hget books java&quot;think in java&quot;&gt; hset books golang &quot;learning go programming&quot; # 因为是更新操作，所以返回 0(integer) 0&gt; hget books golang&quot;learning go programming&quot;&gt; hmset books java &quot;effective java&quot; python &quot;learning python&quot; golang &quot;modern golang programming&quot; # 批量 setOK 同字符串对象一样，hash 结构中的单个子 key 也可以进行计数，它对应的指令是 hincrby，和 incr 使用基本一样。 123# 老钱又老了一岁&gt; hincrby user-laoqian age 1(integer) 30 set(集合)Redis 的集合相当于 Java 语言里面的 HashSet，它内部的键值对是无序的唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值NULL。 set 结构可以用来存储活动中奖的用户 ID，因为有去重功能，可以保证同一个用户不会中奖两次。 123456789101112131415161718&gt; sadd books python(integer) 1&gt; sadd books python # 重复(integer) 0&gt; sadd books java golang(integer) 2&gt; smembers books # 注意顺序，和插入的并不一致，因为 set 是无序的1) &quot;java&quot;2) &quot;python&quot;3) &quot;golang&quot;&gt; sismember books java # 查询某个 value 是否存在，相当于 contains(o)(integer) 1&gt; sismember books rust(integer) 0&gt; scard books # 获取长度相当于 count()(integer) 3&gt; spop books # 弹出一个&quot;java&quot; zset(有序集合)zset 可能是 Redis 提供的最为特色的数据结构，它也是在面试中面试官最爱问的数据结构。它类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫做「跳跃列表」的数据结构。 zset 可以用来存粉丝列表，value 值是粉丝的用户 ID，score 是关注时间。我们可以对粉丝列表按关注时间进行排序。 zset 还可以用来存储学生的成绩，value 值是学生的 ID，score 是他的考试成绩。我们可以对成绩按分数进行排序就可以得到他的名次。 123456789101112131415161718192021222324252627282930313233&gt; zadd books 9.0 &quot;think in java&quot;(integer) 1&gt; zadd books 8.9 &quot;java concurrency&quot;(integer) 1&gt; zadd books 8.6 &quot;java cookbook&quot;(integer) 1&gt; zrange books 0 -1 # 按 score 排序列出，参数区间为排名范围1) &quot;java cookbook&quot;2) &quot;java concurrency&quot;3) &quot;think in java&quot;&gt; zrevrange books 0 -1 # 按 score 逆序列出，参数区间为排名范围1) &quot;think in java&quot;2) &quot;java concurrency&quot;3) &quot;java cookbook&quot;&gt; zcard books # 相当于 count()(integer) 3&gt; zscore books &quot;java concurrency&quot; # 获取指定 value 的 score&quot;8.9000000000000004&quot; # 内部 score 使用 double 类型进行存储，所以存在小数点精度问题&gt; zrank books &quot;java concurrency&quot; # 排名(integer) 1&gt; zrangebyscore books 0 8.91 # 根据分值区间遍历 zset1) &quot;java cookbook&quot;2) &quot;java concurrency&quot;&gt; zrangebyscore books -inf 8.91 withscores # 根据分值区间 (-∞, 8.91] 遍历 zset，同时返回分值。inf 代表 infinite，无穷大的意思。1) &quot;java cookbook&quot;2) &quot;8.5999999999999996&quot;3) &quot;java concurrency&quot;4) &quot;8.9000000000000004&quot;&gt; zrem books &quot;java concurrency&quot; # 删除 value(integer) 1&gt; zrange books 0 -11) &quot;java cookbook&quot;2) &quot;think in java&quot; 跳跃列表：zset 内部的排序功能是通过「跳跃列表」数据结构来实现的，它的结构非常特殊，也比较复杂。 因为 zset 要支持随机的插入和删除，所以它不好使用数组来表示。我们先看一个普通的链表结构。 我们需要这个链表按照 score 值进行排序。这意味着当有新元素需要插入时，要定位到特定位置的插入点，这样才可以继续保证链表是有序的。通常我们会通过二分查找来找到插入点，但是二分查找的对象必须是数组，只有数组才可以支持快速位置定位，链表做不到，那该怎么办？ 想想一个创业公司，刚开始只有几个人，团队成员之间人人平等，都是联合创始人。随着公司的成长，人数渐渐变多，团队沟通成本随之增加。这时候就会引入组长制，对团队进行划分。每个团队会有一个组长。开会的时候分团队进行，多个组长之间还会有自己的会议安排。公司规模进一步扩展，需要再增加一个层级 —— 部门，每个部门会从组长列表中推选出一个代表来作为部长。部长们之间还会有自己的高层会议安排。 跳跃列表就是类似于这种层级制，最下面一层所有的元素都会串起来。然后每隔几个元素挑选出一个代表来，再将这几个代表使用另外一级指针串起来。然后在这些代表里再挑出二级代表，再串起来。最终就形成了金字塔结构。 想想你老家在世界地图中的位置：亚洲–&gt;中国-&gt;安徽省-&gt;安庆市-&gt;枞阳县-&gt;汤沟镇-&gt;田间村-&gt;xxxx号，也是这样一个类似的结构。 「跳跃列表」之所以「跳跃」，是因为内部的元素可能「身兼数职」，比如上图中间的这个元素，同时处于 L0、L1 和 L2 层，可以快速在不同层次之间进行「跳跃」。 定位插入点时，先在顶层进行定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插进去。你也许会问，那新插入的元素如何才有机会「身兼数职」呢？ 跳跃列表采取一个随机策略来决定新元素可以兼职到第几层。 首先 L0 层肯定是 100% 了，L1 层只有 50% 的概率，L2 层只有 25% 的概率，L3 层只有 12.5% 的概率，一直随机到最顶层 L31 层。绝大多数元素都过不了几层，只有极少数元素可以深入到顶层。列表中的元素越多，能够深入的层次就越深，能进入到顶层的概率就会越大。 这还挺公平的，能不能进入中央不是靠拼爹，而是看运气。 容器型数据结构的通用规则list/set/hash/zset 这四种数据结构是容器型数据结构，它们共享下面两条通用规则： create if not exists如果容器不存在，那就创建一个，再进行操作。比如 rpush 操作刚开始是没有列表的，Redis 就会自动创建一个，然后再 rpush 进去新元素。 drop if no elements如果容器里元素没有了，那么立即删除元素，释放内存。这意味着 lpop 操作到最后一个元素，列表就消失了。 过期时间Redis 所有的数据结构都可以设置过期时间，时间到了，Redis 会自动删除相应的对象。需要注意的是过期是以对象为单位，比如一个 hash 结构的过期是整个 hash 对象的过期，而不是其中的某个子 key。 还有一个需要特别注意的地方是如果一个字符串已经设置了过期时间，然后你调用了 set 方法修改了它，它的过期时间会消失 12345678910127.0.0.1:6379&gt; set codehole yoyoOK127.0.0.1:6379&gt; expire codehole 600(integer) 1127.0.0.1:6379&gt; ttl codehole(integer) 597127.0.0.1:6379&gt; set codehole yoyoOK127.0.0.1:6379&gt; ttl codehole(integer) -1","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://vincentxin-scott.github.io/tags/Redis/"}]},{"title":"Idea设置自定义注释的模版","slug":"杂记随笔/Idea设置方法注解模版param脚本","date":"2019-08-14T14:38:44.673Z","updated":"2019-12-11T06:43:03.980Z","comments":true,"path":"2019/08/14/杂记随笔/Idea设置方法注解模版param脚本/","link":"","permalink":"https://vincentxin-scott.github.io/2019/08/14/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/Idea%E8%AE%BE%E7%BD%AE%E6%96%B9%E6%B3%95%E6%B3%A8%E8%A7%A3%E6%A8%A1%E7%89%88param%E8%84%9A%E6%9C%AC/","excerpt":"","text":"进入菜单进入图示菜单，点击左侧➕号，先创建定义分组。 创建分组： 创建注释模版： 设置模版内容：1234567* * @Author Vincentxin * @Description //TODO $end$ * @Date $date$ $time$ $param$ * @return $return$ **/ 设置模版应用的语言：点击上图 黄色感叹号后面的define； 配置模版内容的参数：点击 匹配参数： 1234groovyScript(&quot;def result=&#x27;&#x27;; def Param=\\&quot;$&#123;_1&#125;\\&quot;.replaceAll(&#x27;[\\\\\\\\[|\\\\\\\\]|\\\\\\\\s]&#x27;, &#x27;&#x27;).split(&#x27;,&#x27;).toList(); for(i = 1; i &lt; Param.size() +1; i++) &#123;result+=&#x27;* @param &#x27; + Param[i - 1]+ ((i &lt; Param.size()) ? &#x27;\\\\n &#x27; : &#x27;&#x27;)&#125;; return result&quot;, methodParameters()) groovyScript(&quot;def result=&#x27;&#x27;; def Param=\\&quot;$&#123;_1&#125;\\&quot;.replaceAll(&#x27;[\\\\\\\\[|\\\\\\\\]|\\\\\\\\s]&#x27;, &#x27;&#x27;).split(&#x27;,&#x27;).toList(); for(i = 1; i &lt; Param.size() +1; i++) &#123;result+=&#x27;\\\\n * @param &#x27; + Param[i - 1]&#125;; return result&quot;, methodParameters())","categories":[{"name":"杂记随笔","slug":"杂记随笔","permalink":"https://vincentxin-scott.github.io/categories/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"Idea","slug":"Idea","permalink":"https://vincentxin-scott.github.io/tags/Idea/"}]},{"title":"OKHTTP(五) Interceptors","slug":"HTTP/OKHttp(五) Interceptors","date":"2019-08-12T14:33:54.914Z","updated":"2019-12-11T06:57:06.979Z","comments":true,"path":"2019/08/12/HTTP/OKHttp(五) Interceptors/","link":"","permalink":"https://vincentxin-scott.github.io/2019/08/12/HTTP/OKHttp(%E4%BA%94)%20Interceptors/","excerpt":"","text":"Interceptors拦截器是一种强大的机制，可以监视，重写和重试调用。这是一个简单的拦截器，记录传出请求和传入响应。 1234567891011121314151617class LoggingInterceptor implements Interceptor &#123; @Override public Response intercept(Interceptor.Chain chain) throws IOException &#123; Request request = chain.request(); long t1 = System.nanoTime(); logger.info(String.format(&quot;Sending request %s on %s%n%s&quot;, request.url(), chain.connection(), request.headers())); Response response = chain.proceed(request); long t2 = System.nanoTime(); logger.info(String.format(&quot;Received response for %s in %.1fms%n%s&quot;, response.request().url(), (t2 - t1) / 1e6d, response.headers())); return response; &#125;&#125; 对chain.proceed（request）的调用是每个拦截器实现的关键部分。这种简单的方法是所有HTTP工作发生的地方，产生满足请求的响应。 拦截器可以链式调用。假设您同时拥有压缩拦截器和校验和拦截器：您需要确定数据是否已压缩，然后进行校验和再压缩。OkHttp使用列表来跟踪拦截器，并按顺序调用拦截器。 Application Interceptors拦截器被注册为应用程序或网络拦截器。我们将使用上面定义的LoggingInterceptor来显示差异。 通过在OkHttpClient.Builder上调用addInterceptor（）来注册应用程序拦截器： 1234567891011OkHttpClient client = new OkHttpClient.Builder() .addInterceptor(new LoggingInterceptor()) .build();Request request = new Request.Builder() .url(&quot;http://www.publicobject.com/helloworld.txt&quot;) .header(&quot;User-Agent&quot;, &quot;OkHttp Example&quot;) .build();Response response = client.newCall(request).execute();response.body().close(); URL http://www.publicobject.com/helloworld.txt重定向到https://publicobject.com/helloworld.txt，OkHttp会自动跟随此重定向。我们的应用程序拦截器被调用一次，而从chain.proceed（）返回的响应具有重定向的响应： 1234567INFO: Sending request http://www.publicobject.com/helloworld.txt on nullUser-Agent: OkHttp ExampleINFO: Received response for https://publicobject.com/helloworld.txt in 1179.7msServer: nginx/1.4.6 (Ubuntu)Content-Type: text/plainContent-Length: 1759 我们可以看到我们被重定向，因为response.request（）。url（）与request.url（）不同。这两个日志语句记录了两个不同的URL。 Network Interceptors注册网络拦截器非常相似。调用addNetworkInterceptor（）而不是addInterceptor（）： 1234567891011OkHttpClient client = new OkHttpClient.Builder() .addNetworkInterceptor(new LoggingInterceptor()) .build();Request request = new Request.Builder() .url(&quot;http://www.publicobject.com/helloworld.txt&quot;) .header(&quot;User-Agent&quot;, &quot;OkHttp Example&quot;) .build();Response response = client.newCall(request).execute();response.body().close(); 当我们运行此代码时，拦截器运行两次。一次是对http://www.publicobject.com/helloworld.txt的初始请求，另一次是为了重定向到https://publicobject.com/helloworld.txt 123456789101112131415161718192021222324INFO: Sending request http://www.publicobject.com/helloworld.txt on Connection&#123;www.publicobject.com:80, proxy=DIRECT hostAddress=54.187.32.157 cipherSuite=none protocol=http/1.1&#125;User-Agent: OkHttp ExampleHost: www.publicobject.comConnection: Keep-AliveAccept-Encoding: gzipINFO: Received response for http://www.publicobject.com/helloworld.txt in 115.6msServer: nginx/1.4.6 (Ubuntu)Content-Type: text/htmlContent-Length: 193Connection: keep-aliveLocation: https://publicobject.com/helloworld.txtINFO: Sending request https://publicobject.com/helloworld.txt on Connection&#123;publicobject.com:443, proxy=DIRECT hostAddress=54.187.32.157 cipherSuite=TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA protocol=http/1.1&#125;User-Agent: OkHttp ExampleHost: publicobject.comConnection: Keep-AliveAccept-Encoding: gzipINFO: Received response for https://publicobject.com/helloworld.txt in 80.9msServer: nginx/1.4.6 (Ubuntu)Content-Type: text/plainContent-Length: 1759Connection: keep-alive 网络请求还包含更多数据，例如OkHttp添加的Accept-Encoding：gzip标头，用于通告对响应压缩的支持。网络拦截器的链具有非空连接，可用于询问用于连接到Web服务器的IP地址和TLS配置。 Choosing between application and network interceptors每个拦截链都有相对的优点。 Application interceptors 不需要担心重定向和重试等中间响应。 即使从缓存提供HTTP响应，也始终调用一次。 观察应用程序的原始意图。没有关注OkHttp注入的标题，如If-None-Match。 允许短路而不是调用Chain.proceed（）。 允许重试并对Chain.proceed（）进行多次调用。Network Interceptors 能够对重定向和重试等中间响应进行操作。 未调用使网络短路的缓存响应。 观察数据，就像它将通过网络传输一样。 访问带有请求的Connection。Rewriting Requests拦截器可以添加，删除或替换请求标头。他们还可以转换那些拥有一个请求的主体。例如，如果要连接到已知支持它的Web服务器，则可以使用应用程序拦截器添加请求主体压缩。12345678910111213141516171819202122232425262728293031323334353637/** This interceptor compresses the HTTP request body. Many webservers can&#x27;t handle this! */final class GzipRequestInterceptor implements Interceptor &#123; @Override public Response intercept(Interceptor.Chain chain) throws IOException &#123; Request originalRequest = chain.request(); if (originalRequest.body() == null || originalRequest.header(&quot;Content-Encoding&quot;) != null) &#123; return chain.proceed(originalRequest); &#125; Request compressedRequest = originalRequest.newBuilder() .header(&quot;Content-Encoding&quot;, &quot;gzip&quot;) .method(originalRequest.method(), gzip(originalRequest.body())) .build(); return chain.proceed(compressedRequest); &#125; private RequestBody gzip(final RequestBody body) &#123; return new RequestBody() &#123; @Override public MediaType contentType() &#123; return body.contentType(); &#125; @Override public long contentLength() &#123; return -1; // We don&#x27;t know the compressed length in advance! &#125; @Override public void writeTo(BufferedSink sink) throws IOException &#123; BufferedSink gzipSink = Okio.buffer(new GzipSink(sink)); body.writeTo(gzipSink); gzipSink.close(); &#125; &#125;; &#125;&#125; Rewriting Responses¶同样的，拦截器可以重写响应头并转换响应体。这通常比重写请求标头更危险，因为它可能违反了网络服务器的期望。 如果您处于棘手的情况并准备应对后果，重写响应标头是解决问题的有效方法。例如，您可以修复服务器配置错误的Cache-Control响应标头，以实现更好的响应缓存： 123456789/** Dangerous interceptor that rewrites the server&#x27;s cache-control header. */private static final Interceptor REWRITE_CACHE_CONTROL_INTERCEPTOR = new Interceptor() &#123; @Override public Response intercept(Interceptor.Chain chain) throws IOException &#123; Response originalResponse = chain.proceed(chain.request()); return originalResponse.newBuilder() .header(&quot;Cache-Control&quot;, &quot;max-age=60&quot;) .build(); &#125;&#125;; 通常，这种方法在补充Web服务器上的相应修复时效果最佳！","categories":[{"name":"网络","slug":"网络","permalink":"https://vincentxin-scott.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"OKHTTP","slug":"OKHTTP","permalink":"https://vincentxin-scott.github.io/tags/OKHTTP/"}]},{"title":"OKHTTP(四) Recipes(使用方法)","slug":"HTTP/OKHttp(四) Recipes","date":"2019-08-12T13:47:50.699Z","updated":"2019-12-11T06:57:03.075Z","comments":true,"path":"2019/08/12/HTTP/OKHttp(四) Recipes/","link":"","permalink":"https://vincentxin-scott.github.io/2019/08/12/HTTP/OKHttp(%E5%9B%9B)%20Recipes/","excerpt":"","text":"Recipes我们已经编写了一些使用方法，演示如何使用OkHttp解决常见问题。仔细阅读它们，了解一切如何协同工作。自由剪切和粘贴这些例子; Synchronous Get下载文件，打印其标题，并将其响应正文打印为字符串。响应体上的string（）方法对于小文档来说非常方便有效。但是如果响应体很大（大于1 MiB），请避免使用string（），因为它会将整个文档加载到内存中。在这种情况下，更喜欢将消息体作为流来处理。 123456789101112131415161718private final OkHttpClient client = new OkHttpClient(); public void run() throws Exception &#123; Request request = new Request.Builder() .url(&quot;https://publicobject.com/helloworld.txt&quot;) .build(); try (Response response = client.newCall(request).execute()) &#123; if (!response.isSuccessful()) throw new IOException(&quot;Unexpected code &quot; + response); Headers responseHeaders = response.headers(); for (int i = 0; i &lt; responseHeaders.size(); i++) &#123; System.out.println(responseHeaders.name(i) + &quot;: &quot; + responseHeaders.value(i)); &#125; System.out.println(response.body().string()); &#125; &#125; Asynchronous Get在工作线程上下载文件，并在响应可读时回调。回调是在响应头准备好之后进行的。阅读响应正文可能仍会阻止。OkHttp目前不提供异步API来接收部分响应主体。 12345678910111213141516171819202122232425262728private final OkHttpClient client = new OkHttpClient(); public void run() throws Exception &#123; Request request = new Request.Builder() .url(&quot;http://publicobject.com/helloworld.txt&quot;) .build(); client.newCall(request).enqueue(new Callback() &#123; @Override public void onFailure(Call call, IOException e) &#123; e.printStackTrace(); &#125; @Override public void onResponse(Call call, Response response) throws IOException &#123; try (ResponseBody responseBody = response.body()) &#123; if (!response.isSuccessful()) throw new IOException(&quot;Unexpected code &quot; + response); Headers responseHeaders = response.headers(); for (int i = 0, size = responseHeaders.size(); i &lt; size; i++) &#123; System.out.println(responseHeaders.name(i) + &quot;: &quot; + responseHeaders.value(i)); &#125; System.out.println(responseBody.string()); &#125; &#125; &#125;); &#125; Accessing Headers(访问标题)通常，HTTP标头的工作方式类似于Map &lt;String，String&gt;：每个字段都有一个值或没有。但是一些标题允许多个值，例如Guava的Multimap。例如，HTTP响应提供多个Vary标头是合法且常见的。OkHttp的API试图使两种情况都很舒适。 在编写请求标头时，使用标头（名称，值）将name的唯一出现设置为value。如果存在现有值，则在添加新值之前将删除它们。使用addHeader（name，value）添加标头而不删除已存在的标头。 读取响应标头时，使用标头（名称）返回最后一次出现的命名值。通常这也是唯一的发生！如果没有值，则header（name）将返回null。要将所有字段的值作为列表读取，请使用标题（名称）。 要访问所有标头，请使用支持索引访问的Headers类。 123456789101112131415161718private final OkHttpClient client = new OkHttpClient(); public void run() throws Exception &#123; Request request = new Request.Builder() .url(&quot;https://api.github.com/repos/square/okhttp/issues&quot;) .header(&quot;User-Agent&quot;, &quot;OkHttp Headers.java&quot;) .addHeader(&quot;Accept&quot;, &quot;application/json; q=0.5&quot;) .addHeader(&quot;Accept&quot;, &quot;application/vnd.github.v3+json&quot;) .build(); try (Response response = client.newCall(request).execute()) &#123; if (!response.isSuccessful()) throw new IOException(&quot;Unexpected code &quot; + response); System.out.println(&quot;Server: &quot; + response.header(&quot;Server&quot;)); System.out.println(&quot;Date: &quot; + response.header(&quot;Date&quot;)); System.out.println(&quot;Vary: &quot; + response.headers(&quot;Vary&quot;)); &#125; &#125; Posting a String使用HTTP POST将请求正文发送到服务。此示例将markdown文档发布到将markdown呈现为HTML的Web服务。由于整个请求主体同时在内存中，因此请避免使用此API发布大型（大于1 MiB）文档。 1234567891011121314151617181920212223242526public static final MediaType MEDIA_TYPE_MARKDOWN = MediaType.parse(&quot;text/x-markdown; charset=utf-8&quot;); private final OkHttpClient client = new OkHttpClient(); public void run() throws Exception &#123; String postBody = &quot;&quot; + &quot;Releases\\n&quot; + &quot;--------\\n&quot; + &quot;\\n&quot; + &quot; * _1.0_ May 6, 2013\\n&quot; + &quot; * _1.1_ June 15, 2013\\n&quot; + &quot; * _1.2_ August 11, 2013\\n&quot;; Request request = new Request.Builder() .url(&quot;https://api.github.com/markdown/raw&quot;) .post(RequestBody.create(MEDIA_TYPE_MARKDOWN, postBody)) .build(); try (Response response = client.newCall(request).execute()) &#123; if (!response.isSuccessful()) throw new IOException(&quot;Unexpected code &quot; + response); System.out.println(response.body().string()); &#125; &#125; Post a file12345678910111213141516171819public static final MediaType MEDIA_TYPE_MARKDOWN = MediaType.parse(&quot;text/x-markdown; charset=utf-8&quot;); private final OkHttpClient client = new OkHttpClient(); public void run() throws Exception &#123; File file = new File(&quot;README.md&quot;); Request request = new Request.Builder() .url(&quot;https://api.github.com/markdown/raw&quot;) .post(RequestBody.create(MEDIA_TYPE_MARKDOWN, file)) .build(); try (Response response = client.newCall(request).execute()) &#123; if (!response.isSuccessful()) throw new IOException(&quot;Unexpected code &quot; + response); System.out.println(response.body().string()); &#125; &#125; Post Streaming在这里，我们将请求主体作为流发布。该请求正文的内容正在编写时生成。此示例直接流入Okio缓冲接收器。您的程序可能更喜欢OutputStream，您可以从BufferedSink.outputStream（）获取它。 1234567891011121314151617181920212223242526272829303132333435363738394041public static final MediaType MEDIA_TYPE_MARKDOWN = MediaType.parse(&quot;text/x-markdown; charset=utf-8&quot;); private final OkHttpClient client = new OkHttpClient(); public void run() throws Exception &#123; RequestBody requestBody = new RequestBody() &#123; @Override public MediaType contentType() &#123; return MEDIA_TYPE_MARKDOWN; &#125; @Override public void writeTo(BufferedSink sink) throws IOException &#123; sink.writeUtf8(&quot;Numbers\\n&quot;); sink.writeUtf8(&quot;-------\\n&quot;); for (int i = 2; i &lt;= 997; i++) &#123; sink.writeUtf8(String.format(&quot; * %s = %s\\n&quot;, i, factor(i))); &#125; &#125; private String factor(int n) &#123; for (int i = 2; i &lt; n; i++) &#123; int x = n / i; if (x * i == n) return factor(x) + &quot; × &quot; + i; &#125; return Integer.toString(n); &#125; &#125;; Request request = new Request.Builder() .url(&quot;https://api.github.com/markdown/raw&quot;) .post(requestBody) .build(); try (Response response = client.newCall(request).execute()) &#123; if (!response.isSuccessful()) throw new IOException(&quot;Unexpected code &quot; + response); System.out.println(response.body().string()); &#125; &#125; Posting form parameters使用FormBody.Builder构建一个像HTML 标记一样工作的请求体。名称和值将使用HTML兼容的表单URL编码进行编码。 1234567891011121314151617private final OkHttpClient client = new OkHttpClient(); public void run() throws Exception &#123; RequestBody formBody = new FormBody.Builder() .add(&quot;search&quot;, &quot;Jurassic Park&quot;) .build(); Request request = new Request.Builder() .url(&quot;https://en.wikipedia.org/w/index.php&quot;) .post(formBody) .build(); try (Response response = client.newCall(request).execute()) &#123; if (!response.isSuccessful()) throw new IOException(&quot;Unexpected code &quot; + response); System.out.println(response.body().string()); &#125; &#125; Posting a multipart requestMultipartBody.Builder可以构建与HTML文件上载表单兼容的复杂请求主体。多部分请求主体的每个部分本身都是一个请求主体，并且可以定义自己的头部。如果存在，这些标题应描述零件主体，例如其内容 - 处置。如果Content-Length和Content-Type标头可用，则会自动添加它们。 123456789101112131415161718192021222324252627282930/** * The imgur client ID for OkHttp recipes. If you&#x27;re using imgur for anything other than running * these examples, please request your own client ID! https://api.imgur.com/oauth2 */ private static final String IMGUR_CLIENT_ID = &quot;...&quot;; private static final MediaType MEDIA_TYPE_PNG = MediaType.parse(&quot;image/png&quot;); private final OkHttpClient client = new OkHttpClient(); public void run() throws Exception &#123; // Use the imgur image upload API as documented at https://api.imgur.com/endpoints/image RequestBody requestBody = new MultipartBody.Builder() .setType(MultipartBody.FORM) .addFormDataPart(&quot;title&quot;, &quot;Square Logo&quot;) .addFormDataPart(&quot;image&quot;, &quot;logo-square.png&quot;, RequestBody.create(MEDIA_TYPE_PNG, new File(&quot;website/static/logo-square.png&quot;))) .build(); Request request = new Request.Builder() .header(&quot;Authorization&quot;, &quot;Client-ID &quot; + IMGUR_CLIENT_ID) .url(&quot;https://api.imgur.com/3/image&quot;) .post(requestBody) .build(); try (Response response = client.newCall(request).execute()) &#123; if (!response.isSuccessful()) throw new IOException(&quot;Unexpected code &quot; + response); System.out.println(response.body().string()); &#125; &#125; Parse a JSON Response With Moshi(使用Moshi解析JSON响应)Moshi是一个方便的API，用于在JSON和Java对象之间进行转换。在这里，我们使用它来解码来自GitHub API的JSON响应。 请注意，ResponseBody.charStream（）使用Content-Type响应头来选择在解码响应主体时使用哪个charset。如果未指定charset，则默认为UTF-8。 123456789101112131415161718192021222324252627private final OkHttpClient client = new OkHttpClient(); private final Moshi moshi = new Moshi.Builder().build(); private final JsonAdapter&lt;Gist&gt; gistJsonAdapter = moshi.adapter(Gist.class); public void run() throws Exception &#123; Request request = new Request.Builder() .url(&quot;https://api.github.com/gists/c2a7c39532239ff261be&quot;) .build(); try (Response response = client.newCall(request).execute()) &#123; if (!response.isSuccessful()) throw new IOException(&quot;Unexpected code &quot; + response); Gist gist = gistJsonAdapter.fromJson(response.body().source()); for (Map.Entry&lt;String, GistFile&gt; entry : gist.files.entrySet()) &#123; System.out.println(entry.getKey()); System.out.println(entry.getValue().content); &#125; &#125; &#125; static class Gist &#123; Map&lt;String, GistFile&gt; files; &#125; static class GistFile &#123; String content; &#125; Response Caching要缓存响应，您需要一个可以读取和写入的缓存目录，以及缓存大小的限制。缓存目录应该是私有的，不受信任的应用程序不应该能够读取其内容。 让多个缓存同时访问同一缓存目录是错误的。大多数应用程序应该只调用一次新的OkHttpClient（），使用它们的缓存配置它，并在任何地方使用相同的实例。否则，两个缓存实例将相互踩踏，破坏响应缓存，并可能导致程序崩溃。 响应缓存使用HTTP标头进行所有配置。您可以添加请求标头，如Cache-Control：max-stale = 3600，OkHttp的缓存将遵循它们。您的Web服务器使用自己的响应标头配置缓存响应的时间，例如Cache-Control：max-age = 9600。有缓存标头可强制缓存响应，强制网络响应，或强制使用条件GET验证网络响应。 1234567891011121314151617181920212223242526272829303132333435363738private final OkHttpClient client;public CacheResponse(File cacheDirectory) throws Exception &#123; int cacheSize = 10 * 1024 * 1024; // 10 MiB Cache cache = new Cache(cacheDirectory, cacheSize); client = new OkHttpClient.Builder() .cache(cache) .build();&#125;public void run() throws Exception &#123; Request request = new Request.Builder() .url(&quot;http://publicobject.com/helloworld.txt&quot;) .build(); String response1Body; try (Response response1 = client.newCall(request).execute()) &#123; if (!response1.isSuccessful()) throw new IOException(&quot;Unexpected code &quot; + response1); response1Body = response1.body().string(); System.out.println(&quot;Response 1 response: &quot; + response1); System.out.println(&quot;Response 1 cache response: &quot; + response1.cacheResponse()); System.out.println(&quot;Response 1 network response: &quot; + response1.networkResponse()); &#125; String response2Body; try (Response response2 = client.newCall(request).execute()) &#123; if (!response2.isSuccessful()) throw new IOException(&quot;Unexpected code &quot; + response2); response2Body = response2.body().string(); System.out.println(&quot;Response 2 response: &quot; + response2); System.out.println(&quot;Response 2 cache response: &quot; + response2.cacheResponse()); System.out.println(&quot;Response 2 network response: &quot; + response2.networkResponse()); &#125; System.out.println(&quot;Response 2 equals Response 1? &quot; + response1Body.equals(response2Body));&#125; 要阻止响应使用缓存，请使用CacheControl.FORCE_NETWORK。要阻止它使用网络，请使用CacheControl.FORCE_CACHE。警告：如果你使用FORCE_CACHE并且响应需要网络，OkHttp将返回504不满意的请求响应。 Canceling a Call使用Call.cancel（）立即停止正在进行的呼叫。如果线程当前正在写入请求或读取响应，则它将收到IOException。当不再需要呼叫时，使用它来保护网络;例如，当您的用户导航离开应用程序时。同步和异步调用都可以取消。 123456789101112131415161718192021222324252627282930private final ScheduledExecutorService executor = Executors.newScheduledThreadPool(1); private final OkHttpClient client = new OkHttpClient(); public void run() throws Exception &#123; Request request = new Request.Builder() .url(&quot;http://httpbin.org/delay/2&quot;) // This URL is served with a 2 second delay. .build(); final long startNanos = System.nanoTime(); final Call call = client.newCall(request); // Schedule a job to cancel the call in 1 second. executor.schedule(new Runnable() &#123; @Override public void run() &#123; System.out.printf(&quot;%.2f Canceling call.%n&quot;, (System.nanoTime() - startNanos) / 1e9f); call.cancel(); System.out.printf(&quot;%.2f Canceled call.%n&quot;, (System.nanoTime() - startNanos) / 1e9f); &#125; &#125;, 1, TimeUnit.SECONDS); System.out.printf(&quot;%.2f Executing call.%n&quot;, (System.nanoTime() - startNanos) / 1e9f); try (Response response = call.execute()) &#123; System.out.printf(&quot;%.2f Call was expected to fail, but completed: %s%n&quot;, (System.nanoTime() - startNanos) / 1e9f, response); &#125; catch (IOException e) &#123; System.out.printf(&quot;%.2f Call failed as expected: %s%n&quot;, (System.nanoTime() - startNanos) / 1e9f, e); &#125; &#125; Timeouts当对等方无法访问时，使用超时来使呼叫失败。网络分区可能是由于客户端连接问题，服务器可用性问题或其他任何问题。OkHttp支持连接，读取和写入超时。 123456789101112131415161718private final OkHttpClient client; public ConfigureTimeouts() throws Exception &#123; client = new OkHttpClient.Builder() .connectTimeout(10, TimeUnit.SECONDS) .writeTimeout(10, TimeUnit.SECONDS) .readTimeout(30, TimeUnit.SECONDS) .build(); &#125; public void run() throws Exception &#123; Request request = new Request.Builder() .url(&quot;http://httpbin.org/delay/2&quot;) // This URL is served with a 2 second delay. .build(); try (Response response = client.newCall(request).execute()) &#123; System.out.println(&quot;Response completed: &quot; + response); &#125; Per-call Configuration所有HTTP客户端配置都存在于OkHttpClient中，包括代理设置，超时和缓存。当您需要更改单个调用的配置时，请调用OkHttpClient.newBuilder（）。这将返回与原始客户端共享相同连接池，调度程序和配置的构建器。在下面的示例中，我们发出一个请求，其中500毫秒超时，另一个请求超时3000毫秒。 123456789101112131415161718192021222324252627private final OkHttpClient client = new OkHttpClient(); public void run() throws Exception &#123; Request request = new Request.Builder() .url(&quot;http://httpbin.org/delay/1&quot;) // This URL is served with a 1 second delay. .build(); // Copy to customize OkHttp for this request. OkHttpClient client1 = client.newBuilder() .readTimeout(500, TimeUnit.MILLISECONDS) .build(); try (Response response = client1.newCall(request).execute()) &#123; System.out.println(&quot;Response 1 succeeded: &quot; + response); &#125; catch (IOException e) &#123; System.out.println(&quot;Response 1 failed: &quot; + e); &#125; // Copy to customize OkHttp for this request. OkHttpClient client2 = client.newBuilder() .readTimeout(3000, TimeUnit.MILLISECONDS) .build(); try (Response response = client2.newCall(request).execute()) &#123; System.out.println(&quot;Response 2 succeeded: &quot; + response); &#125; catch (IOException e) &#123; System.out.println(&quot;Response 2 failed: &quot; + e); &#125; &#125; Handling authentication(认证处理)OkHttp可以自动重试未经身份验证的请求。如果响应为401 Not Authorized，则要求Authenticator提供凭据。实现应该构建包含缺少凭据的新请求。如果没有可用的凭据，则返回null以跳过重试。 使用Response.challenges（）来获取任何身份验证挑战的方案和领域。在完成基本挑战时，使用Credentials.basic（用户名，密码）对请求标头进行编码。 123456789101112131415161718192021222324252627282930313233private final OkHttpClient client; public Authenticate() &#123; client = new OkHttpClient.Builder() .authenticator(new Authenticator() &#123; @Override public Request authenticate(Route route, Response response) throws IOException &#123; if (response.request().header(&quot;Authorization&quot;) != null) &#123; return null; // Give up, we&#x27;ve already attempted to authenticate. &#125; System.out.println(&quot;Authenticating for response: &quot; + response); System.out.println(&quot;Challenges: &quot; + response.challenges()); String credential = Credentials.basic(&quot;jesse&quot;, &quot;password1&quot;); return response.request().newBuilder() .header(&quot;Authorization&quot;, credential) .build(); &#125; &#125;) .build(); &#125; public void run() throws Exception &#123; Request request = new Request.Builder() .url(&quot;http://publicobject.com/secrets/hellosecret.txt&quot;) .build(); try (Response response = client.newCall(request).execute()) &#123; if (!response.isSuccessful()) throw new IOException(&quot;Unexpected code &quot; + response); System.out.println(response.body().string()); &#125; &#125; 为避免在身份验证不起作用时进行多次重试，您可以返回null以放弃。例如，您可能希望在尝试这些确切凭据时跳过重试： 123if (credential.equals(response.request().header(&quot;Authorization&quot;))) &#123; return null; // If we already failed with these credentials, don&#x27;t retry. &#125; 当您达到应用程序定义的尝试限制时，您也可以跳过重试： 123if (responseCount(response) &gt;= 3) &#123; return null; // If we&#x27;ve failed 3 times, give up. &#125; 上面的代码依赖于这个responseCount（）方法： 1234567private int responseCount(Response response) &#123; int result = 1; while ((response = response.priorResponse()) != null) &#123; result++; &#125; return result; &#125;","categories":[{"name":"网络","slug":"网络","permalink":"https://vincentxin-scott.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"OKHTTP","slug":"OKHTTP","permalink":"https://vincentxin-scott.github.io/tags/OKHTTP/"}]},{"title":"OKHTTP(三) Connections","slug":"HTTP/OKHttp(三) Connections","date":"2019-08-12T13:30:21.907Z","updated":"2019-12-11T06:56:58.038Z","comments":true,"path":"2019/08/12/HTTP/OKHttp(三) Connections/","link":"","permalink":"https://vincentxin-scott.github.io/2019/08/12/HTTP/OKHttp(%E4%B8%89)%20Connections/","excerpt":"","text":"Connections虽然您只提供URL，但OkHttp使用三种类型计划其与您的Web服务器的连接：URL，地址和路由。 URLsURL（如https://github.com/square/okhttp）是HTTP和Internet的基础。除了作为Web上所有内容的通用，分散的命名方案之外，它们还指定了如何访问Web资源。网址是抽象的： 它们指定呼叫可以是明文（http）或加密（https），但不能使用哪种加密算法。它们也没有指定如何验证对等方的证书（HostnameVerifier）或可以信任哪些证书（SSLSocketFactory）。 它们未指定是否应使用特定代理服务器或如何使用该代理服务器进行身份验证。 它们也具体：每个URL标识一个特定的路径（如/ square / okhttp）和查询（如？q = sharks＆lang = en）。每个Web服务器都托管许多URL。 Addresses地址指定Web服务器（如github.com）以及连接到该服务器所需的所有静态配置：端口号，HTTPS设置和首选网络协议（如HTTP / 2或SPDY）。共享相同地址的URL也可以共享相同的底层TCP套接字连接。共享连接具有显着的性能优势：更低的延迟，更高的吞吐量（由于TCP慢启动）和节省的电池。OkHttp使用ConnectionPool，它自动重用HTTP / 1.x连接并多路复用HTTP / 2和SPDY连接。 在OkHttp中，地址的某些字段来自URL（方案，主机名，端口），其余字段来自OkHttpClient。 Routes路由提供实际连接到Web服务器所需的动态信息。这是要尝试的特定IP地址（由DNS查询发现），要使用的确切代理服务器（如果正在使用ProxySelector），以及要协商的TLS版本（用于HTTPS连接）。单个地址可能有很多路由。例如，托管在多个数据中心中的Web服务器可能会在其DNS响应中生成多个IP地址。 Connections当您使用OkHttp请求URL时，它的作用如下： 它使用URL并配置OkHttpClient来创建地址。此地址指定我们将如何连接到Web服务器。 它尝试从连接池中检索具有该地址的连接。 如果它在池中找不到连接，则会选择要尝试的路由。这通常意味着发出DNS请求以获取服务器的IP地址。然后，如有必要，它会选择TLS版本和代理服务器。 如果它是新路由，则通过构建直接套接字连接，TLS隧道（通过HTTP代理的HTTPS）或直接TLS连接来连接。它根据需要进行TLS握手。 它发送HTTP请求并读取响应。 如果连接有问题，OkHttp将选择另一条路线并再试一次。这允许OkHttp在服务器地址的子集无法访问时进行恢复。当池化连接过时或者不支持尝试的TLS版本时，它也很有用。收到响应后，连接将返回到池中，以便可以将其重新用于将来的请求。经过一段时间的不活动后，连接将从池中逐出。","categories":[{"name":"网络","slug":"网络","permalink":"https://vincentxin-scott.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"OKHTTP","slug":"OKHTTP","permalink":"https://vincentxin-scott.github.io/tags/OKHTTP/"}]},{"title":"OKHTTP(二) Calls","slug":"HTTP/OKHttp(二) Calls","date":"2019-08-12T08:50:21.433Z","updated":"2019-12-11T06:56:54.202Z","comments":true,"path":"2019/08/12/HTTP/OKHttp(二) Calls/","link":"","permalink":"https://vincentxin-scott.github.io/2019/08/12/HTTP/OKHttp(%E4%BA%8C)%20Calls/","excerpt":"","text":"CallsHTTP客户端的工作是接受您的请求并生成其响应。这在理论上很简单，但在实践中却很棘手。 Requests每个HTTP请求都包含一个URL，一个方法（如GET或POST）和一个标题列表。请求还可以包含正文：特定内容类型的数据流。 Responses响应使用代码（例如200表示成功或404表示未找到），标题和自己的可选正文来回答请求。 Rewriting Requests当您向OkHttp提供HTTP请求时，您将在高级别描述请求：“使用这些标头获取此URL。”为了正确性和效率，OkHttp在传输之前重写您的请求。OkHttp可能会添加原始请求中不存在的标头，包括Content-Length，Transfer-Encoding，User-Agent，Host，Connection和Content-Type。它将为透明响应压缩添加Accept-Encoding标头，除非标头已存在。如果您有cookie，OkHttp将添加一个Cookie标头。某些请求将具有缓存响应。当这个缓存的响应不新鲜时，OkHttp可以执行条件GET来下载更新的响应，如果它比缓存的更新。这需要添加If-Modified-Since和If-None-Match等标题。 Rewriting Responses如果使用透明压缩，OkHttp将删除相应的响应头Content-Encoding和Content-Length，因为它们不适用于解压缩的响应主体。如果条件GET成功，则根据规范合并来自网络和缓存的响应。 Follow-up Requests（后续请求）当您请求的URL移动后，Web服务器将返回一个响应代码，如302，以指示文档的新URL。OkHttp将遵循重定向来检索最终响应。如果响应发出授权质询，OkHttp将要求Authenticator（如果配置了一个）来满足挑战。如果验证者提供凭证，则会使用包含的凭据重试该请求。 Retrying Requests有时连接失败：池连接失效并断开连接，或者无法访问Web服务器本身。如果有可用的话，OkHttp将使用不同的路由重试该请求。 Calls通过重写，重定向，后续跟踪和重试，您的简单请求可能会产生许多请求和响应。OkHttp使用Call来模拟满足您的请求的任务，但是需要许多中间请求和响应。通常这不是很多！但是，如果您的URL被重定向或者故障转移到备用IP地址，您的代码将继续有效，这一点令人欣慰。请求可以由着两种方式之一来执行： Synchronous(同步):你的线程阻塞，直到响应可读。 Asynchronous(异步):您将请求排入任何线程，并在响应可读时在另一个线程上回调。 可以从任何线程取消请求。如果尚未完成，这将无法通过！正在编写请求正文或读取响应正文的代码在其调用被取消时将遭受IOException。 Dispatch对于同步调用，您可以自带线程，并负责管理您同时发出的请求数。同时连接太多会浪费资源;太少会伤害延迟。对于异步调用，Dispatcher实现最大同时请求的策略。您可以设置每个网络服务器的最大值（默认值为5）和总体（默认值为64）。","categories":[{"name":"网络","slug":"网络","permalink":"https://vincentxin-scott.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"OKHTTP","slug":"OKHTTP","permalink":"https://vincentxin-scott.github.io/tags/OKHTTP/"}]},{"title":"OKHTTP(一)Overview","slug":"HTTP/OKHttp(一) Overview","date":"2019-08-12T07:01:16.963Z","updated":"2019-12-11T06:57:11.435Z","comments":true,"path":"2019/08/12/HTTP/OKHttp(一) Overview/","link":"","permalink":"https://vincentxin-scott.github.io/2019/08/12/HTTP/OKHttp(%E4%B8%80)%20Overview/","excerpt":"","text":"OkHttpHTTP是现代应用网络的方式。这就是我们交换数据和媒体的方式。有效地执行HTTP可以加快您的负载并节省带宽。OkHttp是一个默认有效的HTTP客户端： HTTP / 2支持允许对同一主机的所有请求共享套接字。 连接池减少了请求延迟（如果HTTP / 2不可用）。 透明GZIP缩小了下载大小。 响应缓存可以完全避免网络重复请求。 当网络很麻烦时，OkHttp坚持不懈：它将从常见的连接问题中无声地恢复。如果您的服务有多个IP地址，如果第一次连接失败，OkHttp将尝试备用地址。这对于IPv4 + IPv6和冗余数据中心中托管的服务是必需的。OkHttp支持现代TLS功能（TLS 1.3，ALPN，证书固定）。它可以配置为回退以实现广泛的连接。 使用OkHttp很容易。它的请求/响应API采用流畅的构建器和不变性设计。它支持同步阻塞调用和带回调的异步调用。 Get a URL1234567891011OkHttpClient client = new OkHttpClient();String run(String url) throws IOException &#123; Request request = new Request.Builder() .url(url) .build(); try (Response response = client.newCall(request).execute()) &#123; return response.body().string(); &#125;&#125; Post to a Server123456789101112131415public static final MediaType JSON = MediaType.get(&quot;application/json; charset=utf-8&quot;);OkHttpClient client = new OkHttpClient();String post(String url, String json) throws IOException &#123; RequestBody body = RequestBody.create(JSON, json); Request request = new Request.Builder() .url(url) .post(body) .build(); try (Response response = client.newCall(request).execute()) &#123; return response.body().string(); &#125;&#125; Requirements(要求)OkHttp适用于Android 5.0+（API级别21+）和Java 8+。OkHttp对Okio有一个库依赖，这是一个用于高性能I / O的小型库。我们强烈建议您保持OkHttp最新。与自动更新Web浏览器一样，与HTTPS客户端保持同步是防止潜在安全问题的重要防御。我们跟踪动态TLS生态系统并调整OkHttp以改善连接性和安全性。 OkHttp使用您平台的内置TLS实现。在Java平台上，OkHttp还支持Conscrypt，它将BoringSSL与Java集成在一起。如果它是第一个安全提供者，OkHttp将使用Conscrypt： 1Security.insertProviderAt(Conscrypt.newProvider(), 1);","categories":[{"name":"网络","slug":"网络","permalink":"https://vincentxin-scott.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"OKHTTP","slug":"OKHTTP","permalink":"https://vincentxin-scott.github.io/tags/OKHTTP/"}]},{"title":"HttpClient Apache(五)流畅的API","slug":"HTTP/HttpClient Apache(五) API","date":"2019-08-08T14:52:51.202Z","updated":"2019-12-11T06:56:42.825Z","comments":true,"path":"2019/08/08/HTTP/HttpClient Apache(五) API/","link":"","permalink":"https://vincentxin-scott.github.io/2019/08/08/HTTP/HttpClient%20Apache(%E4%BA%94)%20API/","excerpt":"","text":"Fluent APIEasy to use facade API（易于使用的外观API）从版本4.2开始，HttpClient提供了一个易于使用的Facade API，它基于流畅的界面概念。Fluent facade API仅公开HttpClient的最基本功能，适用于不需要HttpClient完全灵活性的简单用例。例如，流畅的外观API使用户不必处理连接管理和资源释放。 12345// Execute a GET with timeout settings and return response content as String.Request.Get(&quot;http://somehost/&quot;) .connectTimeout(1000) .socketTimeout(1000) .execute().returnContent().asString(); 1234567// Execute a POST with the &#x27;expect-continue&#x27; handshake, using HTTP/1.1,// containing a request body as String and return response content as byte array.Request.Post(&quot;http://somehost/do-stuff&quot;) .useExpectContinue() .version(HttpVersion.HTTP_1_1) .bodyString(&quot;Important stuff&quot;, ContentType.DEFAULT_TEXT) .execute().returnContent().asBytes(); 1234567// Execute a POST with a custom header through the proxy containing a request body// as an HTML form and save the result to the fileRequest.Post(&quot;http://somehost/some-form&quot;) .addHeader(&quot;X-Custom-header&quot;, &quot;stuff&quot;) .viaProxy(new HttpHost(&quot;myproxy&quot;, 8080)) .bodyForm(Form.form().add(&quot;username&quot;, &quot;vip&quot;).add(&quot;password&quot;, &quot;secret&quot;).build()) .execute().saveContent(new File(&quot;result.dump&quot;)); 也可以直接使用Executor，以便在特定的安全上下文中执行请求，从而对身份验证详细信息进行缓存并重新用于后续请求。 123456789101112Executor executor = Executor.newInstance() .auth(new HttpHost(&quot;somehost&quot;), &quot;username&quot;, &quot;password&quot;) .auth(new HttpHost(&quot;myproxy&quot;, 8080), &quot;username&quot;, &quot;password&quot;) .authPreemptive(new HttpHost(&quot;myproxy&quot;, 8080));executor.execute(Request.Get(&quot;http://somehost/&quot;)) .returnContent().asString();executor.execute(Request.Post(&quot;http://somehost/do-stuff&quot;) .useExpectContinue() .bodyString(&quot;Important stuff&quot;, ContentType.DEFAULT_TEXT)) .returnContent().asString(); Response handling(响应处理)流畅的外观API通常使用户不必处理连接管理和资源释放。但是，在大多数情况下，这需要在内存中缓冲响应消息的内容。强烈建议使用ResponseHandler进行HTTP响应处理，以避免在内存中缓冲内容。 1234567891011121314151617181920212223242526272829303132333435Document result = Request.Get(&quot;http://somehost/content&quot;) .execute().handleResponse(new ResponseHandler&lt;Document&gt;() &#123; public Document handleResponse(final HttpResponse response) throws IOException &#123; StatusLine statusLine = response.getStatusLine(); HttpEntity entity = response.getEntity(); if (statusLine.getStatusCode() &gt;= 300) &#123; throw new HttpResponseException( statusLine.getStatusCode(), statusLine.getReasonPhrase()); &#125; if (entity == null) &#123; throw new ClientProtocolException(&quot;Response contains no content&quot;); &#125; DocumentBuilderFactory dbfac = DocumentBuilderFactory.newInstance(); try &#123; DocumentBuilder docBuilder = dbfac.newDocumentBuilder(); ContentType contentType = ContentType.getOrDefault(entity); if (!contentType.equals(ContentType.APPLICATION_XML)) &#123; throw new ClientProtocolException(&quot;Unexpected content type:&quot; + contentType); &#125; String charset = contentType.getCharset(); if (charset == null) &#123; charset = HTTP.DEFAULT_CONTENT_CHARSET; &#125; return docBuilder.parse(entity.getContent(), charset); &#125; catch (ParserConfigurationException ex) &#123; throw new IllegalStateException(ex); &#125; catch (SAXException ex) &#123; throw new ClientProtocolException(&quot;Malformed XML document&quot;, ex); &#125; &#125; &#125;);","categories":[{"name":"网络","slug":"网络","permalink":"https://vincentxin-scott.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"HttpClient","slug":"HttpClient","permalink":"https://vincentxin-scott.github.io/tags/HttpClient/"}]},{"title":"HttpClient Apache(四)身份验证","slug":"HTTP/HttpClient Apache(四) 身份验证","date":"2019-08-08T14:32:46.800Z","updated":"2019-12-11T06:56:39.739Z","comments":true,"path":"2019/08/08/HTTP/HttpClient Apache(四) 身份验证/","link":"","permalink":"https://vincentxin-scott.github.io/2019/08/08/HTTP/HttpClient%20Apache(%E5%9B%9B)%20%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81/","excerpt":"","text":"HTTP authenticationHttpClient完全支持HTTP标准规范定义的身份验证方案以及许多广泛使用的非标准身份验证方案，如NTLM和SPNEGO。 User credentials(用户凭据)任何用户身份验证过程都需要一组可用于建立用户身份的凭据。在最简单的形式中，用户凭证可以只是用户名/密码对。UsernamePasswordCredentials表示由明文组成的安全主体和密码组成的一组凭据。此实现足以用于HTTP标准规范定义的标准身份验证方案。 123UsernamePasswordCredentials creds = new UsernamePasswordCredentials(&quot;user&quot;, &quot;pwd&quot;);System.out.println(creds.getUserPrincipal().getName());System.out.println(creds.getPassword()); NTCredentials是Microsoft Windows特定的实现，除了用户名/密码对之外还包括一组其他Windows特定属性，例如用户域的名称。在Microsoft Windows网络中，同一用户可以属于多个域，每个域具有不同的授权集。 123NTCredentials creds = new NTCredentials(&quot;user&quot;, &quot;pwd&quot;, &quot;workstation&quot;, &quot;domain&quot;);System.out.println(creds.getUserPrincipal().getName());System.out.println(creds.getPassword()); Authentication schemes(认证方案)AuthScheme接口代表 面向对象的抽象 质询-响应 认证方案。认证方案有望支持以下功能： 解析并处理目标服务器发送的质询，以响应对受保护资源的请求。 提供已处理质询的属性：身份验证方案类型及其参数，例如此身份验证方案适用的域（如果可用） 为给定的凭证集和HTTP请求生成授权字符串以响应实际的授权质询。 请注意，身份验证方案可能是有状态的，涉及一系列质询 - 响应交换。HttpClient附带了几个AuthScheme实现： Basic: RFC 2617中定义的基本身份验证方案。此身份验证方案不安全，因为凭据以明文形式传输。尽管不安全，但如果与TLS / SSL加密结合使用，基本身份验证方案就足够了。 Digest：RFC 2617中定义的摘要式身份验证方案。摘要式身份验证方案比Basic更安全，对于那些不希望通过TLS / SSL加密实现完全传输安全性开销的应用程序而言，它们是一个不错的选择。 NTLM：NTLM是Microsoft开发的专有身份验证方案，针对Windows平台进行了优化。NTLM被认为比Digest更安全。 SPNEGO（简单和受保护的GSSAPI协商机制）是GSSAPI“伪机制”，用于协商许多可能的实际机制之一。SPNEGO最明显的用途是在Microsoft的HTTP Negotiate身份验证扩展中。可协商的子机制包括Active Directory支持的NTLM和Kerberos。目前HttpClient仅支持Kerberos子机制。 Kerberos：Kerberos身份验证实现。 Credentials provider（凭证提供程序）凭据提供程序旨在维护一组用户凭据，并能够为特定的身份验证范围生成用户凭据。身份验证范围包括主机名，端口号，域名和身份验证方案名称。在凭证提供程序中注册凭据时，可以提供通配符（任何主机，任何端口，任何领域，任何方案）而不是具体的属性值。如果无法找到直接匹配，则凭证提供者可以找到特定范围的最接近匹配。HttpClient可以与实现CredentialsProvider接口的凭证提供程序的任何物理表示一起使用。名为BasicCredentialsProvider的默认CredentialsProvider实现是一个由java.util.HashMap支持的简单实现。 12345678910111213141516171819CredentialsProvider credsProvider = new BasicCredentialsProvider();credsProvider.setCredentials( new AuthScope(&quot;somehost&quot;, AuthScope.ANY_PORT), new UsernamePasswordCredentials(&quot;u1&quot;, &quot;p1&quot;));credsProvider.setCredentials( new AuthScope(&quot;somehost&quot;, 8080), new UsernamePasswordCredentials(&quot;u2&quot;, &quot;p2&quot;));credsProvider.setCredentials( new AuthScope(&quot;otherhost&quot;, 8080, AuthScope.ANY_REALM, &quot;ntlm&quot;), new UsernamePasswordCredentials(&quot;u3&quot;, &quot;p3&quot;));System.out.println(credsProvider.getCredentials( new AuthScope(&quot;somehost&quot;, 80, &quot;realm&quot;, &quot;basic&quot;)));System.out.println(credsProvider.getCredentials( new AuthScope(&quot;somehost&quot;, 8080, &quot;realm&quot;, &quot;basic&quot;)));System.out.println(credsProvider.getCredentials( new AuthScope(&quot;otherhost&quot;, 8080, &quot;realm&quot;, &quot;basic&quot;)));System.out.println(credsProvider.getCredentials( new AuthScope(&quot;otherhost&quot;, 8080, null, &quot;ntlm&quot;))); stdout &gt; [principal: u1][principal: u2]null[principal: u3] HTTP authentication and execution context(HTTP身份验证和执行上下文)HttpClient依赖于AuthState类来跟踪有关身份验证过程状态的详细信息。HttpClient在HTTP请求执行过程中创建两个AuthState实例：一个用于目标主机身份验证，另一个用于代理身份验证。如果目标服务器或代理需要用户身份验证，则相应的AuthScope实例将使用身份验证过程中使用的AuthScope，AuthScheme和Crednetials进行填充。可以检查AuthState以查明请求的身份验证类型，是否找到匹配的AuthScheme实现以及凭据提供程序是否设法查找给定身份验证范围的用户凭据。 在HTTP请求执行过程中，HttpClient将以下与身份验证相关的对象添加到执行上下文中： Lookup instance representing the actual authentication scheme registry. The value of this attribute set in the local context takes precedence over the default one. CredentialsProvider instance representing the actual credentials provider. The value of this attribute set in the local context takes precedence over the default one. AuthState instance representing the actual target authentication state. The value of this attribute set in the local context takes precedence over the default one. AuthState instance representing the actual proxy authentication state. The value of this attribute set in the local context takes precedence over the default one. AuthCache instance representing the actual authentication data cache. The value of this attribute set in the local context takes precedence over the default one. 本地HttpContext对象可用于在请求执行之前自定义HTTP身份验证上下文，或在请求执行后检查其状态： 12345678910111213141516171819202122CloseableHttpClient httpclient = &lt;...&gt;CredentialsProvider credsProvider = &lt;...&gt;Lookup&lt;AuthSchemeProvider&gt; authRegistry = &lt;...&gt;AuthCache authCache = &lt;...&gt;HttpClientContext context = HttpClientContext.create();context.setCredentialsProvider(credsProvider);context.setAuthSchemeRegistry(authRegistry);context.setAuthCache(authCache);HttpGet httpget = new HttpGet(&quot;http://somehost/&quot;);CloseableHttpResponse response1 = httpclient.execute(httpget, context);&lt;...&gt;AuthState proxyAuthState = context.getProxyAuthState();System.out.println(&quot;Proxy auth state: &quot; + proxyAuthState.getState());System.out.println(&quot;Proxy auth scheme: &quot; + proxyAuthState.getAuthScheme());System.out.println(&quot;Proxy auth credentials: &quot; + proxyAuthState.getCredentials());AuthState targetAuthState = context.getTargetAuthState();System.out.println(&quot;Target auth state: &quot; + targetAuthState.getState());System.out.println(&quot;Target auth scheme: &quot; + targetAuthState.getAuthScheme());System.out.println(&quot;Target auth credentials: &quot; + targetAuthState.getCredentials()); Caching of authentication data(缓存身份验证数据)从版本4.1开始，HttpClient会自动缓存有关已成功通过身份验证的主机的信息。请注意，必须使用相同的执行上下文来执行逻辑上相关的请求，以便缓存的身份验证数据从一个请求传播到另一个请求。一旦执行上下文超出范围，身份验证数据就会丢失。 Preemptive authentication(抢先认证)HttpClient不支持开箱即用的抢先身份验证，因为如果误用或使用不当，抢先身份验证可能会导致严重的安全问题，例如以明文形式向未经授权的第三方发送用户凭据。因此，期望用户在其特定应用环境的背景下评估抢先认证与安全风险的潜在好处。 1234567891011121314151617181920212223242526272829CloseableHttpClient httpclient = &lt;...&gt;HttpHost targetHost = new HttpHost(&quot;localhost&quot;, 80, &quot;http&quot;);CredentialsProvider credsProvider = new BasicCredentialsProvider();credsProvider.setCredentials( new AuthScope(targetHost.getHostName(), targetHost.getPort()), new UsernamePasswordCredentials(&quot;username&quot;, &quot;password&quot;));// Create AuthCache instanceAuthCache authCache = new BasicAuthCache();// Generate BASIC scheme object and add it to the local auth cacheBasicScheme basicAuth = new BasicScheme();authCache.put(targetHost, basicAuth);// Add AuthCache to the execution contextHttpClientContext context = HttpClientContext.create();context.setCredentialsProvider(credsProvider);context.setAuthCache(authCache);HttpGet httpget = new HttpGet(&quot;/&quot;);for (int i = 0; i &lt; 3; i++) &#123; CloseableHttpResponse response = httpclient.execute( targetHost, httpget, context); try &#123; HttpEntity entity = response.getEntity(); &#125; finally &#123; response.close(); &#125;","categories":[{"name":"网络","slug":"网络","permalink":"https://vincentxin-scott.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"HttpClient","slug":"HttpClient","permalink":"https://vincentxin-scott.github.io/tags/HttpClient/"}]},{"title":"Spring循环引用","slug":"SpringBoot/Spring循环引用","date":"2019-08-07T12:57:01.640Z","updated":"2020-07-03T10:41:34.511Z","comments":true,"path":"2019/08/07/SpringBoot/Spring循环引用/","link":"","permalink":"https://vincentxin-scott.github.io/2019/08/07/SpringBoot/Spring%E5%BE%AA%E7%8E%AF%E5%BC%95%E7%94%A8/","excerpt":"","text":"什么是循环依赖一个Bean A 依赖于 Bean B 同时 Bean B 依赖于Bean A；也有可能是更加复杂的循环依赖：Bean A → Bean B → Bean C → Bean D → Bean E → Bean A Spring中发生了什么当Spring上下文加载所有bean时，它会尝试按照它们完全工作所需的顺序创建bean。如果我们没有循环依赖：Bean A → Bean B → Bean CSpring将创建bean C，然后创建bean B（并将bean C 注入其中），然后创建bean A（并将bean B注入其中）。但是，当具有循环依赖时，Spring无法决定应该首先创建哪个bean，因为它们彼此依赖。在这些情况下，Spring将在加载上下文时引发BeanCurrentlyInCreationException。使用构造函数注入时，这种循环依赖的问题可能在Spring中发生;如果您使用其他类型的注入，则不应该发现此问题，因为依赖项将在需要时注入，而不是在上下文加载时注入。 解决方案重新设计如果您有循环依赖关系，则可能是您遇到了设计问题而且责任分离不清。您应该尝试正确地重新设计组件，以便它们的层次结构设计得很好，并且不需要循环依赖。如果您无法重新设计组件（可能有许多可能的原因：遗留代码，已经过测试且无法修改的代码，没有足够的时间或资源来完成重新设计……），有一些可行的解决方法。 使用@Lazy打破循环的一个简单方法是让Spring懒加载初始化其中一个bean。那就是：它不是完全初始化bean，而是创建一个代理将它注入另一个bean。注入的bean只有在第一次需要时才会完全创建。","categories":[{"name":"框架","slug":"框架","permalink":"https://vincentxin-scott.github.io/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://vincentxin-scott.github.io/tags/Spring/"}]},{"title":"shell构建项目打包脚本","slug":"Shell/项目自动化打包脚本","date":"2019-08-05T15:53:40.698Z","updated":"2020-10-13T09:51:45.929Z","comments":true,"path":"2019/08/05/Shell/项目自动化打包脚本/","link":"","permalink":"https://vincentxin-scott.github.io/2019/08/05/Shell/%E9%A1%B9%E7%9B%AE%E8%87%AA%E5%8A%A8%E5%8C%96%E6%89%93%E5%8C%85%E8%84%9A%E6%9C%AC/","excerpt":"","text":"打包构建Docker镜像并推送镜像12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#!/bin/sh# 当前文件夹REPOSITORY_NAME=&quot;./bus-order-consumer/external&quot;# git代码地址（配合ssh使用最佳）REPOSITORY_URL=&quot;git代码地址&quot;# 项目名称CONTAINER_NAME=&quot;gb-bus-order-consumer&quot;# 项目版本CODE_VERSION=&quot;0.0.1-SNAPSHOT&quot;# 环境前缀字符PROFILE_VERSION=&quot;external-pre&quot;# 分支或者环境GIT_VERSION=&quot;pre&quot;# 版本号versionid=&quot;0.0.1&quot;echo &quot;================清除仓库目录================&quot;# 清楚原有的文件夹rm -rf $&#123;REPOSITORY_NAME&#125;# 新建文件夹mkdir -p $&#123;REPOSITORY_NAME&#125;cd $&#123;REPOSITORY_NAME&#125;echo &quot;================克隆远程仓库================&quot;git clone -b $&#123;GIT_VERSION&#125; $&#123;REPOSITORY_URL&#125;# 进入需要编译的目录cd &quot;./java/gb-business/gb-bus-order/$&#123;CONTAINER_NAME&#125;&quot;echo &quot;================代码打包中================&quot;# 本地maven 构建项目/usr/local/maven/bin/mvn clean install -P $&#123;PROFILE_VERSION&#125;echo &quot;================移动jar包================&quot;# 将jar包 移动到docker file文件夹下。cd &quot;./target&quot;cp $&#123;CONTAINER_NAME&#125;-$&#123;CODE_VERSION&#125;.jar &quot;../docker/app.jar&quot;cd &quot;../docker&quot;echo &#x27;================开始推送镜像================&#x27;# 推送docker image到指定的镜像仓库docker login --username=************ --password=********** urldocker build --build-arg JAR_FILE=./app.jar -t 仓库地址/$&#123;CONTAINER_NAME&#125;:$&#123;PROFILE_VERSION&#125;-$&#123;CODE_VERSION&#125;-$&#123;versionid&#125; .docker push 仓库地址/$&#123;CONTAINER_NAME&#125;:$&#123;PROFILE_VERSION&#125;-$&#123;CODE_VERSION&#125;-$&#123;versionid&#125;echo &#x27;================结束推送镜像================&#x27;# 清除本地的docker imagedocker rmi $(docker images | grep &quot;$&#123;CONTAINER_NAME&#125;&quot; | awk &#x27;&#123;print $3&#125;&#x27;)echo &#x27;=================删除镜像=================&#x27;","categories":[{"name":"脚本语言","slug":"脚本语言","permalink":"https://vincentxin-scott.github.io/categories/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"shell","slug":"shell","permalink":"https://vincentxin-scott.github.io/tags/shell/"}]},{"title":"HttpClient Apache(三)状态管理","slug":"HTTP/HttpClient Apache(三)状态管理","date":"2019-08-05T15:35:14.468Z","updated":"2019-12-11T06:56:36.097Z","comments":true,"path":"2019/08/05/HTTP/HttpClient Apache(三)状态管理/","link":"","permalink":"https://vincentxin-scott.github.io/2019/08/05/HTTP/HttpClient%20Apache(%E4%B8%89)%E7%8A%B6%E6%80%81%E7%AE%A1%E7%90%86/","excerpt":"","text":"HTTP state management最初，HTTP被设计为一种无状态的，面向请求/响应的协议，它没有对跨越几个逻辑相关的请求/响应交换的有状态会话做出特殊规定。随着HTTP协议的普及和采用越来越多的系统开始将其用于应用程序，它从未打算用于例如电子商务应用程序的传输。因此，对状态管理的支持成为必要。Netscape Communications当时是Web客户端和服务器软件的领先开发商，它基于专有规范在其产品中实现了对HTTP状态管理的支持。后来，Netscape尝试通过发布规范草案来标准化该机制。这些努力促成了通过RFC标准轨道定义的正式规范。但是，大量应用程序中的状态管理仍然主要基于Netscape草案，并且与官方规范不兼容。Web浏览器的所有主要开发人员都不得不保持与这些应用程序的兼容性，这极大地促成了标准合规性的碎片化。 HTTP cookiesHTTP cookie是HTTP代理和目标服务器可以交换以维护会话的令牌或短状态信息包。Netscape的工程师曾经把它称为“神奇的饼干”并且名字命名。HttpClient使用Cookie接口表示抽象cookie令牌。在其最简单的形式中，HTTP cookie仅仅是名称/值对。通常，HTTP cookie还包含许多属性，例如有效的域，指定此cookie适用的源服务器上的URL子集的路径，以及cookie有效的最长时间。SetCookie接口表示由源服务器发送到HTTP代理的Set-Cookie响应头，以便维持会话状态。ClientCookie接口扩展了Cookie接口，具有其他特定于客户端的功能，例如能够完全检索原始服务器指定的原始cookie属性。这对于生成Cookie标头很重要，因为某些Cookie规范要求Cookie标头只有在Set-Cookie标头中指定时才应包含某些属性。 1234567BasicClientCookie cookie = new BasicClientCookie(&quot;name&quot;, &quot;value&quot;);// Set effective domain and path attributescookie.setDomain(&quot;.mycompany.com&quot;);cookie.setPath(&quot;/&quot;);// Set attributes exactly as sent by the servercookie.setAttribute(ClientCookie.PATH_ATTR, &quot;/&quot;);cookie.setAttribute(ClientCookie.DOMAIN_ATTR, &quot;.mycompany.com&quot;); Cookie specifications(规范)CookieSpec接口表示cookie管理规范。cookie管理规范有望强制执行： 解析Set-Cookie标头的规则。 解析cookie的验证规则。 Cookie 标题头格式化给定主机，端口和原始路径。 HttpClient附带了几个CookieSpec实现： 标准严格：状态管理策略符合RFC 6265第4节定义的行为良好的配置文件的语法和语义 规范：状态管理策略符合RFC 6265定义的更宽松的配置文件，第4节旨在与不符合良好行为的配置文件的现有服务器进行互操作。 默认：默认cookie策略是一种综合策略，它根据与HTTP响应一起发送的cookie的属性（例如版本属性，现在已过时）选择RFC 2965，RFC 2109或Netscape草案兼容实现。在HttpClient的下一个次要版本中，将弃用此策略以支持标准（符合RFC 6265）实现。 忽略cookie：所有cookie都被忽略。 强烈建议在新应用程序中使用标准或标准严格策略。应使用过时的规范与旧系统兼容。在HttpClient的下一个主要版本中将删除对过时规范的支持。 Choosing cookie policy(选择cookie策略)如果需要，可以在HTTP客户端设置Cookie策略，并在HTTP请求级别覆盖。 1234567891011RequestConfig globalConfig = RequestConfig.custom() .setCookieSpec(CookieSpecs.DEFAULT) .build();CloseableHttpClient httpclient = HttpClients.custom() .setDefaultRequestConfig(globalConfig) .build();RequestConfig localConfig = RequestConfig.copy(globalConfig) .setCookieSpec(CookieSpecs.STANDARD_STRICT) .build();HttpGet httpGet = new HttpGet(&quot;/&quot;);httpGet.setConfig(localConfig); Custom cookie policy(自定义cookie策略)为了实现自定义cookie策略，应该创建CookieSpec接口的自定义实现，创建CookieSpecProvider实现以创建和初始化自定义规范的实例，并使用HttpClient注册工厂。一旦注册了自定义规范，就可以像标准cookie规范一样激活它。 123456789101112131415161718PublicSuffixMatcher publicSuffixMatcher = PublicSuffixMatcherLoader.getDefault();Registry&lt;CookieSpecProvider&gt; r = RegistryBuilder.&lt;CookieSpecProvider&gt;create() .register(CookieSpecs.DEFAULT, new DefaultCookieSpecProvider(publicSuffixMatcher)) .register(CookieSpecs.STANDARD, new RFC6265CookieSpecProvider(publicSuffixMatcher)) .register(&quot;easy&quot;, new EasySpecProvider()) .build();RequestConfig requestConfig = RequestConfig.custom() .setCookieSpec(&quot;easy&quot;) .build();CloseableHttpClient httpclient = HttpClients.custom() .setDefaultCookieSpecRegistry(r) .setDefaultRequestConfig(requestConfig) .build(); Cookie persistence(Cookie持久性)HttpClient可以与实现CookieStore接口的持久性cookie存储的任何物理表示一起使用。名为BasicCookieStore的默认CookieStore实现是一个由java.util.ArrayList支持的简单实现。当容器对象被垃圾收集时，存储在BasicClientCookie对象中的Cookie将丢失。如有必要，用户可以提供更复杂的实现。 1234567891011// Create a local instance of cookie storeCookieStore cookieStore = new BasicCookieStore();// Populate cookies if neededBasicClientCookie cookie = new BasicClientCookie(&quot;name&quot;, &quot;value&quot;);cookie.setDomain(&quot;.mycompany.com&quot;);cookie.setPath(&quot;/&quot;);cookieStore.addCookie(cookie);// Set the storeCloseableHttpClient httpclient = HttpClients.custom() .setDefaultCookieStore(cookieStore) .build(); HTTP state management and execution context(HTTP状态管理和执行上下文)在HTTP请求执行过程中，HttpClient将以下与状态管理相关的对象添加到执行上下文中： Lookup:表示实际cookie规范注册表的实例。在本地上下文中设置的此属性的值优先于默认值。 CookieSpec:表示实际cookie规范的实例。 CookieOrigin:实例表示原始服务器的实际详细信息。 CookieStore:实例表示实际的cookie存储。在本地上下文中设置的此属性的值优先于默认值。 本地HttpContext对象可用于在请求执行之前自定义HTTP状态管理上下文，或在请求执行后检查其状态。还可以使用单独的执行上下文来实现每个用户（或每个线程）状态管理。在本地上下文中定义的cookie规范注册表和cookie存储将优先于在HTTP客户端级别设置的默认值 123456789101112131415CloseableHttpClient httpclient = &lt;...&gt;Lookup&lt;CookieSpecProvider&gt; cookieSpecReg = &lt;...&gt;CookieStore cookieStore = &lt;...&gt;HttpClientContext context = HttpClientContext.create();context.setCookieSpecRegistry(cookieSpecReg);context.setCookieStore(cookieStore);HttpGet httpget = new HttpGet(&quot;http://somehost/&quot;);CloseableHttpResponse response1 = httpclient.execute(httpget, context);&lt;...&gt;// Cookie origin detailsCookieOrigin cookieOrigin = context.getCookieOrigin();// Cookie spec usedCookieSpec cookieSpec = context.getCookieSpec();","categories":[{"name":"网络","slug":"网络","permalink":"https://vincentxin-scott.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"HttpClient","slug":"HttpClient","permalink":"https://vincentxin-scott.github.io/tags/HttpClient/"}]},{"title":"HttpClient Apache(二)连接管理","slug":"HTTP/HttpClient Apache(二)连接管理","date":"2019-07-26T01:54:45.236Z","updated":"2019-12-11T06:56:23.923Z","comments":true,"path":"2019/07/26/HTTP/HttpClient Apache(二)连接管理/","link":"","permalink":"https://vincentxin-scott.github.io/2019/07/26/HTTP/HttpClient%20Apache(%E4%BA%8C)%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86/","excerpt":"","text":"Connection managementConnection persistence(连接持久性)建立从一个主机到另一个主机的连接的过程非常复杂，并且涉及两个端点之间的多个分组交换，这可能非常耗时。连接握手的开销可能很大，尤其是对于小型HTTP消息。如果可以重新使用开放连接来执行多个请求，则可以实现更高的数据吞吐量。HTTP / 1.1声明HTTP连接可以在默认情况下重复用于多个请求。符合HTTP / 1.0标准的端点还可以使用一种机制来显式传达其首选项，以保持连接活动并将其用于多个请求。如果后续请求需要连接到同一目标主机，HTTP代理还可以使空闲连接保持一段时间。保持连接活动的能力通常被称为连接持久性。HttpClient完全支持连接持久性。 HTTP connection routing(Http连接路由)HttpClient能够直接或通过可能涉及多个中间连接的路由建立到目标主机的连接 - 也称为跳跃。HttpClient将路由的连接区分为普通，隧道和分层。使用多个中间代理来隧道连接到目标主机称为代理链。通过连接到目标或第一个也是唯一的代理来建立普通路由。隧道路由是通过连接到第一个隧道并通过代理链到目标的隧道来建立的，没有代理的路由无法进行隧道传输。通过在现有连接上分层协议来建立分层路由。协议只能通过隧道分层到目标，或通过没有代理的直接连接。 路由计算RouteInfo接口表示到目标主机有关的确定路由的信息，涉及一个或多个中间步骤或跃点。HttpRoute是RouteInfo不可改变的具体实现；HttpTracker是一个可变的RouteInfo实现，由HttpClient内部使用，用于跟踪剩余的跳转到最终路径目标。在成功执行到路线目标的下一跳之后，可以更新HttpTracker。HttpRouteDirector是一个帮助程序类，可用于计算路径中的下一步。该类由HttpClient内部使用。 HttpRoutePlanner是一个接口，表示根据执行上下文计算到给定目标的完整路由的策略。HttpClient附带两个默认的HttpRoutePlanner实现： SystemDefaultRoutePlanner基于java.net.ProxySelector。默认情况下，它将从系统属性或运行应用程序的浏览器中获取JVM的代理设置。 DefaultProxyRoutePlanner实现不使用任何Java系统属性，也不使用任何系统或浏览器代理设置。它始终通过相同的默认代理计算路由。Secure HTTP connections(安全的HTTP连接)如果未经授权的第三方无法读取或篡改两个连接端点之间传输的信息，则可以认为HTTP连接是安全的,SSL / TLS协议是确保HTTP传输安全性的最广泛使用的技术。但是，也可以采用其他加密技术。通常，HTTP传输通过SSL / TLS加密连接分层。HTTP connection managers(HTTP连接管理器)Managed connections and connection managers(托管连接和连接管理器)HTTP连接是复杂的，有状态的，线程不安全的对象，需要正确管理才能正常运行。HTTP连接一次只能由一个执行线程使用。HttpClient使用一个特殊实体来管理对HTTP连接的访问​​，称为HTTP连接管理器，并由HttpClientConnectionManager接口表示。HTTP连接管理器的目的是充当新HTTP连接的工厂，管理持久连接的生命周期以及同步对持久连接的访问​​，确保一次只有一个线程可以访问连接。内部HTTP连接管理器使用ManagedHttpClientConnection实例作为管理连接状态和控制I / O操作执行的实际连接的代理。如果托管连接被释放或由其使用者显式关闭，则底层连接将从其代理中分离并返回给管理器。即使服务使用者仍然拥有对代理实例的引用，它也不再能够有意或无意地执行任何I / O操作或更改真实连接的状态。12345678910111213141516171819HttpClientContext context = HttpClientContext.create();HttpClientConnectionManager connMrg = new BasicHttpClientConnectionManager();HttpRoute route = new HttpRoute(new HttpHost(&quot;localhost&quot;, 80));// Request new connection. This can be a long processConnectionRequest connRequest = connMrg.requestConnection(route, null);// Wait for connection up to 10 secHttpClientConnection conn = connRequest.get(10, TimeUnit.SECONDS);try &#123; // If not open if (!conn.isOpen()) &#123; // establish connection based on its route info connMrg.connect(conn, route, 1000, context); // and mark it as route complete connMrg.routeComplete(conn, route, context); &#125; // Do useful things with the connection.&#125; finally &#123; connMrg.releaseConnection(conn, null, 1, TimeUnit.MINUTES);&#125; 如果需要，可以通过调用ConnectionRequest＃cancelner（）来提前终止连接请求。这将取消阻止在ConnectionRequest＃get（）方法中阻塞的线程。 Simple connection manager(简单连接管理器)BasicHttpClientConnectionManager是一个简单的连接管理器，一次只能维护一个连接。即使这个类是线程安全的，它也应该只由一个执行线程使用。BasicHttpClientConnectionManager将努力为具有相同路由的后续请求重用连接。但是，如果持久连接的路由与连接请求的路由不匹配，它将关闭现有连接并为给定路由重新打开它。如果已经分配了连接，则抛出java.lang.IllegalStateException。应该在EJB容器中使用此连接管理器实现。 Pooling connection manager(连接池管理器)PoolingHttpClientConnectionManager是一个更复杂的实现，它管理客户端连接池，并且能够为来自多个执行线程的连接请求提供服务。 连接以每个路由为基础进行池化。管理员已经在池中提供持久连接的路由请求将通过从池租用连接而不是创建全新连接来提供服务。PoolingHttpClientConnectionManager维护每个路由和总计的最大连接数限制。默认情况下，此实现将为每个给定路由创建不超过2个并发连接，并且总共不再有20个连接。对于许多实际应用程序而言，这些限制可能过于严格，特别是如果它们使用HTTP作为其服务的传输协议。 123456789101112PoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager();// Increase max total connection to 200cm.setMaxTotal(200);// Increase default max connection per route to 20cm.setDefaultMaxPerRoute(20);// Increase max connections for localhost:80 to 50HttpHost localhost = new HttpHost(&quot;locahost&quot;, 80);cm.setMaxPerRoute(new HttpRoute(localhost), 50);CloseableHttpClient httpClient = HttpClients.custom() .setConnectionManager(cm) .build(); Connection manager shutdown(关闭连接管理)当配备池化连接管理器（如PoolingClientConnectionManager）时，HttpClient可用于使用多个执行线程同时执行多个请求。PoolingClientConnectionManager将根据其配置分配连接。如果已租用给定路由的所有连接，则会阻止连接请求，直到将连接释放回池中。通过将’http.conn-manager.timeout’设置为正值，可以确保连接管理器不会无限期地阻塞连接请求操作。如果在给定时间段内无法处理连接请求，则抛出ConnectionPoolTimeoutException。 1234567891011121314151617181920212223242526272829PoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager();CloseableHttpClient httpClient = HttpClients.custom() .setConnectionManager(cm) .build();// URIs to perform GETs onString[] urisToGet = &#123; &quot;http://www.domain1.com/&quot;, &quot;http://www.domain2.com/&quot;, &quot;http://www.domain3.com/&quot;, &quot;http://www.domain4.com/&quot;&#125;;// create a thread for each URIGetThread[] threads = new GetThread[urisToGet.length];for (int i = 0; i &lt; threads.length; i++) &#123; HttpGet httpget = new HttpGet(urisToGet[i]); threads[i] = new GetThread(httpClient, httpget);&#125;// start the threadsfor (int j = 0; j &lt; threads.length; j++) &#123; threads[j].start();&#125;// join the threadsfor (int j = 0; j &lt; threads.length; j++) &#123; threads[j].join();&#125; 虽然HttpClient实例是线程安全的，并且可以在多个执行线程之间共享，但强烈建议每个线程维护自己的HttpContext专用实例。 123456789101112131415161718192021222324252627282930static class GetThread extends Thread &#123; private final CloseableHttpClient httpClient; private final HttpContext context; private final HttpGet httpget; public GetThread(CloseableHttpClient httpClient, HttpGet httpget) &#123; this.httpClient = httpClient; this.context = HttpClientContext.create(); this.httpget = httpget; &#125; @Override public void run() &#123; try &#123; CloseableHttpResponse response = httpClient.execute( httpget, context); try &#123; HttpEntity entity = response.getEntity(); &#125; finally &#123; response.close(); &#125; &#125; catch (ClientProtocolException ex) &#123; // Handle protocol errors &#125; catch (IOException ex) &#123; // Handle I/O errors &#125; &#125;&#125; Connection eviction policy(连接拒绝策略)经典阻塞I / O模型的主要缺点之一是网络套接字只有在I / O操作中被阻塞时才能对I / O事件作出反应。当连接释放回管理器时，它可以保持活动状态，但它无法监视套接字的状态并对任何I / O事件做出反应。如果连接在服务器端关闭，则客户端连接无法检测连接状态的变化（并通过关闭其端部的套接字来做出适当的反应）。HttpClient尝试通过测试连接是否“陈旧”来缓解此问题，该连接在使用连接执行HTTP请求之前不再有效，因为它在服务器端关闭。陈旧的连接检查不是100％可靠。唯一可行的解​​决方案是，每个套接字模型不涉及空闲连接的一个线程是一个专用的监视器线程，用于驱逐由于长时间不活动而被视为过期的连接。监视器线程可以定期调用ClientConnectionManager＃closeExpiredConnections（）方法来关闭所有过期的连接并从池中驱逐关闭的连接。它还可以选择调用ClientConnectionManager＃closeIdleConnections（）方法来关闭在给定时间段内空闲的所有连接。 123456789101112131415161718192021222324252627282930313233343536public static class IdleConnectionMonitorThread extends Thread &#123; private final HttpClientConnectionManager connMgr; private volatile boolean shutdown; public IdleConnectionMonitorThread(HttpClientConnectionManager connMgr) &#123; super(); this.connMgr = connMgr; &#125; @Override public void run() &#123; try &#123; while (!shutdown) &#123; synchronized (this) &#123; wait(5000); // Close expired connections connMgr.closeExpiredConnections(); // Optionally, close connections // that have been idle longer than 30 sec connMgr.closeIdleConnections(30, TimeUnit.SECONDS); &#125; &#125; &#125; catch (InterruptedException ex) &#123; // terminate &#125; &#125; public void shutdown() &#123; shutdown = true; synchronized (this) &#123; notifyAll(); &#125; &#125; &#125; Connection keep alive strategy(长连接策略)HTTP规范没有规定持久连接可以保持多长时间并且应该保持活动状态。某些HTTP服务器使用非标准的Keep-Alive标头与客户端通信他们打算在服务器端保持连接活动的时间段（以秒为单位）。如果可用，HttpClient会使用此信息。如果响应中不存在Keep-Alive标头，HttpClient会假定连接可以无限期保持活动状态。但是，通常使用的许多HTTP服务器被配置为在一段不活动时间之后丢弃持久连接，以便节省系统资源，通常不通知客户端。如果默认策略过于乐观，可能需要提供自定义保持活动策略。 1234567891011121314151617181920212223242526272829303132ConnectionKeepAliveStrategy myStrategy = new ConnectionKeepAliveStrategy() &#123; public long getKeepAliveDuration(HttpResponse response, HttpContext context) &#123; // Honor &#x27;keep-alive&#x27; header HeaderElementIterator it = new BasicHeaderElementIterator( response.headerIterator(HTTP.CONN_KEEP_ALIVE)); while (it.hasNext()) &#123; HeaderElement he = it.nextElement(); String param = he.getName(); String value = he.getValue(); if (value != null &amp;&amp; param.equalsIgnoreCase(&quot;timeout&quot;)) &#123; try &#123; return Long.parseLong(value) * 1000; &#125; catch(NumberFormatException ignore) &#123; &#125; &#125; &#125; HttpHost target = (HttpHost) context.getAttribute( HttpClientContext.HTTP_TARGET_HOST); if (&quot;www.naughty-server.com&quot;.equalsIgnoreCase(target.getHostName())) &#123; // Keep alive for 5 seconds only return 5 * 1000; &#125; else &#123; // otherwise keep alive for 30 seconds return 30 * 1000; &#125; &#125;&#125;;CloseableHttpClient client = HttpClients.custom() .setKeepAliveStrategy(myStrategy) .build(); Connection socket factories(连接套接字工厂)HTTP连接在内部使用java.net.Socket对象来处理通过线路传输数据。但是，它们依赖于ConnectionSocketFactory接口来创建，初始化和连接套接字。这使HttpClient的用户能够在运行时提供特定于应用程序的套接字初始化代码。PlainConnectionSocketFactory是创建和初始化普通（未加密）套接字的默认工厂。创建套接字的过程以及将其连接到主机的过程是分离的，以便在连接操作中阻塞时可以关闭套接字。 12345678HttpClientContext clientContext = HttpClientContext.create();PlainConnectionSocketFactory sf = PlainConnectionSocketFactory.getSocketFactory();Socket socket = sf.createSocket(clientContext);int timeout = 1000; //msHttpHost target = new HttpHost(&quot;localhost&quot;);InetSocketAddress remoteAddress = new InetSocketAddress( InetAddress.getByAddress(new byte[] &#123;127,0,0,1&#125;), 80);sf.connectSocket(timeout, socket, target, remoteAddress, null, clientContext); Secure socket layering(安全套接字分层)LayeredConnectionSocketFactory是ConnectionSocketFactory接口的扩展。分层套接字工厂能够在现有的普通套接字上创建分层的套接字。套接字分层主要用于通过代理创建安全套接字。HttpClient附带SSLSocketFactory，可实现SSL / TLS分层。请注意，HttpClient不使用任何自定义加密功能。它完全依赖于标准Java加密（JCE）和安全套接字（JSEE）扩展。 Integration with connection manager(与连接管理器集成)自定义连接套接字工厂可以与特定协议方案关联，如HTTP或HTTPS，然后用于创建自定义连接管理器。 1234567891011ConnectionSocketFactory plainsf = &lt;...&gt;LayeredConnectionSocketFactory sslsf = &lt;...&gt;Registry&lt;ConnectionSocketFactory&gt; r = RegistryBuilder.&lt;ConnectionSocketFactory&gt;create() .register(&quot;http&quot;, plainsf) .register(&quot;https&quot;, sslsf) .build();HttpClientConnectionManager cm = new PoolingHttpClientConnectionManager(r);HttpClients.custom() .setConnectionManager(cm) .build(); SSL/TLS customization(SSL / TLS定制)HttpClient使用SSLConnectionSocketFactory来创建SSL连接。SSLConnectionSocketFactory允许高度自定义。它可以将javax.net.ssl.SSLContext的实例作为参数，并使用它来创建自定义配置的SSL连接。 12345KeyStore myTrustStore = &lt;...&gt;SSLContext sslContext = SSLContexts.custom() .loadTrustMaterial(myTrustStore) .build();SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory(sslContext); SSLConnectionSocketFactory的定制意味着对SSL / TLS协议的概念有一定程度的熟悉，其详细解释超出了本文档的范围。有关javax.net.ssl.SSLContext和相关工具的详细说明，请参阅Java™安全套接字扩展（JSSE）参考指南。 Hostname verification(主机名称验证)除了在SSL / TLS协议级别上执行的信任验证和客户端身份验证之外，一旦建立连接，HttpClient可以选择性地验证目标主机名是否与存储在服务器的X.509证书中的名称匹配。此验证可以提供服务器信任材料的真实性的额外保证。javax.net.ssl.HostnameVerifier接口表示主机名验证的策略。HttpClient附带了两个javax.net.ssl.HostnameVerifier实现。重要提示：不应将主机名验证与SSL信任验证混淆。 DefaultHostnameVerifier：HttpClient使用的默认实现应符合RFC 2818.主机名必须与证书指定的任何替代名称匹配，或者如果没有替代名称，则为证书主题的最具体CN。通配符可以出现在CN和任何主题中。 NoopH​​ostnameVerifier：此主机名验证程序实质上关闭了主机名验证。它接受任何SSL会话作为有效并匹配目标主机。 默认情况下，HttpClient使用DefaultHostnameVerifier实现。如果需要，可以指定不同的主机名验证器实现 1234SSLContext sslContext = SSLContexts.createSystemDefault();SSLConnectionSocketFactory sslsf = new SSLConnectionSocketFactory( sslContext, NoopHostnameVerifier.INSTANCE); 从版本4.4开始，HttpClient使用由Mozilla Foundation友好维护的公共后缀列表，以确保SSL证书中的通配符不会被滥用以应用于具有公共顶级域的多个域。HttpClient附带了在发布时检索的列表的副本。该列表的最新版本可在https://publicsuffix.org/list/找到。建议列表的本地副本并从原始位置每天下载列表不超过一次是非常明智的。 123PublicSuffixMatcher publicSuffixMatcher = PublicSuffixMatcherLoader.load( PublicSuffixMatcher.class.getResource(&quot;my-copy-effective_tld_names.dat&quot;));DefaultHostnameVerifier hostnameVerifier = new DefaultHostnameVerifier(publicSuffixMatcher); 可以使用null匹配器禁用对公共suffic列表的验证。 1DefaultHostnameVerifier hostnameVerifier = new DefaultHostnameVerifier(null); HttpClient proxy configuration(Http 代理设置)尽管HttpClient知道复杂的路由方案和代理链，但它只支持开箱即用的简单直接或一跳代理连接。告诉HttpClient通过代理连接到目标主机的 12345HttpHost proxy = new HttpHost(&quot;someproxy&quot;, 8080);DefaultProxyRoutePlanner routePlanner = new DefaultProxyRoutePlanner(proxy);CloseableHttpClient httpclient = HttpClients.custom() .setRoutePlanner(routePlanner) .build(); 还可以指示HttpClient使用标准JRE代理选择器来获取代理信息： 12345SystemDefaultRoutePlanner routePlanner = new SystemDefaultRoutePlanner( ProxySelector.getDefault());CloseableHttpClient httpclient = HttpClients.custom() .setRoutePlanner(routePlanner) .build(); 或者，可以提供自定义RoutePlanner实现，以便完全控制HTTP路由计算过程： 12345678910111213141516HttpRoutePlanner routePlanner = new HttpRoutePlanner() &#123; public HttpRoute determineRoute( HttpHost target, HttpRequest request, HttpContext context) throws HttpException &#123; return new HttpRoute(target, null, new HttpHost(&quot;someproxy&quot;, 8080), &quot;https&quot;.equalsIgnoreCase(target.getSchemeName())); &#125;&#125;;CloseableHttpClient httpclient = HttpClients.custom() .setRoutePlanner(routePlanner) .build(); &#125;&#125;","categories":[{"name":"网络","slug":"网络","permalink":"https://vincentxin-scott.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"HttpClient","slug":"HttpClient","permalink":"https://vincentxin-scott.github.io/tags/HttpClient/"}]},{"title":"HttpClient Apache(一)基本原理","slug":"HTTP/HttpClient Apache(一)基本原理","date":"2019-07-19T02:06:52.292Z","updated":"2019-12-11T06:56:48.812Z","comments":true,"path":"2019/07/19/HTTP/HttpClient Apache(一)基本原理/","link":"","permalink":"https://vincentxin-scott.github.io/2019/07/19/HTTP/HttpClient%20Apache(%E4%B8%80)%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/","excerpt":"","text":"Preface尽管java.net包提供了通过HTTP访问资源的基本功能，但它并未提供许多应用程序所需的灵活性或功能性。HttpClient旨在通过提供一个高效，最新且功能丰富的软件包来实现这一空白，该软件包实现了最新HTTP标准和建议的客户端。HttpClient专为扩展而设计，同时为基本HTTP协议提供强大支持。 HttpClient scope(HttpClient范围) 基于HttpCore的客户端HTTP传输库 基于经典的阻塞式IO 操作透明，使用用户无感What HttpClient is HttpClient不是一个浏览器，他是客户端的Http传输库。 HttpClient的目的是传输和接收Http信息。 HttpClient不会尝试处理内容、执行嵌入HTML中的js、在没有明确设置的情况下猜测内容类型、重新格式化请求、重写位置URI Fundamentals(基本原理)Request execution(请求执行)HttpClient最重要的功能是执行HTTP方法。执行HTTP方法涉及一个或多个HTTP请求/ HTTP响应交换，通常由HttpClient内部处理。期望用户提供要执行的请求对象，并且HttpClient期望将请求发送到目标服务器返回相应的响应对象，或者如果执行不成功则抛出异常。 12345678CloseableHttpClient httpclient = HttpClients.createDefault();HttpGet httpget = new HttpGet(&quot;http://localhost/&quot;);CloseableHttpResponse response = httpclient.execute(httpget);try &#123; &lt;...&gt;&#125; finally &#123; response.close();&#125; HTTP request(请求行)所有HTTP请求都有一个请求行，包括方法名称，请求URI和HTTP协议版本。 HttpClient支持开箱即用的HTTP / 1.1规范中定义的所有HTTP方法：GET，HEAD，POST，PUT，DELETE，TRACE和OPTIONS。每种方法类型都有一个特定的类：HttpGet，HttpHead，HttpPost，HttpPut，HttpDelete，HttpTrace和HttpOptions。Request-URI是统一资源标识符，用于标识应用请求的资源。HTTP请求URI由协议方案，主机名，可选端口，资源路径，可选查询和可选片段组成。 12HttpGet httpget = new HttpGet( &quot;http://www.google.com/search?hl=en&amp;q=httpclient&amp;btnG=Google+Search&amp;aq=f&amp;oq=&quot;); HttpClient提供了URIBuilder实体类，以简化请求URI的创建和修改。 1234567891011URI uri = new URIBuilder() .setScheme(&quot;http&quot;)//请求协议 .setHost(&quot;www.google.com&quot;)//主机 .setPath(&quot;/search&quot;)//路由 .setParameter(&quot;q&quot;, &quot;httpclient&quot;) .setParameter(&quot;btnG&quot;, &quot;Google Search&quot;) .setParameter(&quot;aq&quot;, &quot;f&quot;) .setParameter(&quot;oq&quot;, &quot;&quot;) .build();HttpGet httpget = new HttpGet(uri);System.out.println(httpget.getURI()); HTTP response(响应行)HTTP响应是服务器在接收并解释请求消息后发送回客户端的消息。该消息的第一行包括协议版本，后跟数字状态代码及其相关的文本短语。 12345678910111213HttpResponse response = new BasicHttpResponse(HttpVersion.HTTP_1_1, HttpStatus.SC_OK, &quot;OK&quot;);System.out.println(response.getProtocolVersion());System.out.println(response.getStatusLine().getStatusCode());System.out.println(response.getStatusLine().getReasonPhrase());System.out.println(response.getStatusLine().toString());soutHTTP/1.1200OKHTTP/1.1 200 OK Working with message headers(请求头)HTTP消息可以包含许多描述消息属性的标题，例如内容长度，内容类型等。HttpClient提供了检索，添加，删除和枚举标头的方法。 1234567891011121314151617HttpResponse response = new BasicHttpResponse(HttpVersion.HTTP_1_1, HttpStatus.SC_OK, &quot;OK&quot;);response.addHeader(&quot;Set-Cookie&quot;, &quot;c1=a; path=/; domain=localhost&quot;);response.addHeader(&quot;Set-Cookie&quot;, &quot;c2=b; path=\\&quot;/\\&quot;, c3=c; domain=\\&quot;localhost\\&quot;&quot;);Header h1 = response.getFirstHeader(&quot;Set-Cookie&quot;);System.out.println(h1);Header h2 = response.getLastHeader(&quot;Set-Cookie&quot;);System.out.println(h2);Header[] hs = response.getHeaders(&quot;Set-Cookie&quot;);System.out.println(hs.length);soutSet-Cookie: c1=a; path=/; domain=localhostSet-Cookie: c2=b; path=&quot;/&quot;, c3=c; domain=&quot;localhost&quot;2 获取给定类型的所有标头的最有效方法是使用HeaderIterator接口。 12345678910111213141516HttpResponse response = new BasicHttpResponse(HttpVersion.HTTP_1_1, HttpStatus.SC_OK, &quot;OK&quot;);response.addHeader(&quot;Set-Cookie&quot;, &quot;c1=a; path=/; domain=localhost&quot;);response.addHeader(&quot;Set-Cookie&quot;, &quot;c2=b; path=\\&quot;/\\&quot;, c3=c; domain=\\&quot;localhost\\&quot;&quot;);HeaderIterator it = response.headerIterator(&quot;Set-Cookie&quot;);while (it.hasNext()) &#123; System.out.println(it.next());&#125;soutSet-Cookie: c1=a; path=/; domain=localhostSet-Cookie: c2=b; path=&quot;/&quot;, c3=c; domain=&quot;localhost&quot; 它还提供了将HTTP消息解析为单个头元素的便捷方法。 123456789101112131415161718192021222324252627HttpResponse response = new BasicHttpResponse(HttpVersion.HTTP_1_1, HttpStatus.SC_OK, &quot;OK&quot;);response.addHeader(&quot;Set-Cookie&quot;, &quot;c1=a; path=/; domain=localhost&quot;);response.addHeader(&quot;Set-Cookie&quot;, &quot;c2=b; path=\\&quot;/\\&quot;, c3=c; domain=\\&quot;localhost\\&quot;&quot;);HeaderElementIterator it = new BasicHeaderElementIterator( response.headerIterator(&quot;Set-Cookie&quot;));while (it.hasNext()) &#123; HeaderElement elem = it.nextElement(); System.out.println(elem.getName() + &quot; = &quot; + elem.getValue()); NameValuePair[] params = elem.getParameters(); for (int i = 0; i &lt; params.length; i++) &#123; System.out.println(&quot; &quot; + params[i]); &#125;&#125;soutc1 = apath=/domain=localhostc2 = bpath=/c3 = cdomain=localhost HTTP entity(请求体)HTTP消息可以携带与请求或响应相关联的内容实体。实体可以在某些请求和某些响应中找到，对于某些方法实体是非必传的内容，使用实体的请求称为封闭请求的实体。HTTP规范定义了两个封闭请求方法的实体：POST和PUT，通常期望响应包含内容实体。此规则有例外，例如对HEAD方法的响应、204 No Content、304 Not Modified、205 Reset Content响应。HttpClient 根据内容的来源区分三种实体： streamed:内容从流中接收，或在运行中生成。特别是此类别包括从HTTP响应接收的实体。流实体通常不可重复。 self-contained:内容在内存中或通过独立于连接或其他实体的方式获得。自包含实体通常是可重复的。这种类型的实体主要用于封闭HTTP请求的实体。 wrapping:内容从另一个实体获得当从HTTP响应中流出内容时，这种区别对于连接管理很重要。对于由应用程序创建并仅使用HttpClient发送的请求实体，流式和自包含之间的差异并不重要。在这种情况下，建议将不可重复的实体视为流式传输，将那些可重复的实体视为自包含的。Repeatable entities(可重复实体)实体可以是可重复的，这意味着其内容可以被多次读取。这仅适用于自包含实体（如ByteArrayEntity或StringEntity）Using HTTP entities(使用HTTP实体)由于实体可以表示二进制和字符内容，因此它支持字符编码。在执行带有附加内容的请求时或者请求成功并且使用响应主体将结果发送回客户端时，将创建实体。要从实体读取内容，可以通过HttpEntity＃getContent（）方法检索输入流，该方法返回java.io.InputStream，或者可以向HttpEntity＃writeTo（OutputStream）方法提供输出流，一旦所有内容都写入给定流，它将返回。当接收到具有传入消息的实体时，方法HttpEntity＃getContentType（）和HttpEntity＃getContentLength（）方法可用于读取公共元数据，例如Content-Type和Content-Length头（如果它们可用）。由于Content-Type标头可以包含文本mime类型（如text / plain或text / html）的字符编码，因此HttpEntity＃getContentEncoding（）方法用于读取此信息。如果标头不可用，则返回长度-1，内容类型为NULL。如果Content-Type标头可用，则将返回Header对象。 1234567StringEntity myEntity = new StringEntity(&quot;important message&quot;, ContentType.create(&quot;text/plain&quot;, &quot;UTF-8&quot;));System.out.println(myEntity.getContentType());System.out.println(myEntity.getContentLength());System.out.println(EntityUtils.toString(myEntity));System.out.println(EntityUtils.toByteArray(myEntity).length); sout1234Content-Type: text/plain; charset=utf-817important message17 Ensuring release of low level resources(确保释法低级资源)为了确保正确释放系统资源，必须关闭与实体关联的内容流或响应本身12345678910111213141516CloseableHttpClient httpclient = HttpClients.createDefault();HttpGet httpget = new HttpGet(&quot;http://localhost/&quot;);CloseableHttpResponse response = httpclient.execute(httpget);try &#123; HttpEntity entity = response.getEntity(); if (entity != null) &#123; InputStream instream = entity.getContent(); try &#123; // do something useful &#125; finally &#123; instream.close(); &#125; &#125;&#125; finally &#123; response.close();&#125; 关闭内容流和关闭响应之间的区别在于前者将尝试通过使用实体内容来保持底层连接处于活动状态，而后者立即关闭并丢弃连接。请注意，一旦实体完全写出，还需要HttpEntity＃writeTo（OutputStream）方法来确保正确释放系统资源。如果此方法通过调用HttpEntity＃getContent（）获取java.io.InputStream的实例，则还应该在finally子句中关闭该流。使用流实体时，可以使用EntityUtils＃consume（HttpEntity）方法确保实体内容已完全消耗且基础流已关闭。然而，可能存在这样的情况：当只需要复用整个响应内容的一小部分并且消耗剩余内容并使连接可重用时的性能损失太高，在这种情况下，可以通过关闭响应来终止内容流。。1234567891011121314CloseableHttpClient httpclient = HttpClients.createDefault();HttpGet httpget = new HttpGet(&quot;http://localhost/&quot;);CloseableHttpResponse response = httpclient.execute(httpget);try &#123; HttpEntity entity = response.getEntity(); if (entity != null) &#123; InputStream instream = entity.getContent(); int byteOne = instream.read(); int byteTwo = instream.read(); // Do not need the rest &#125;&#125; finally &#123; response.close();&#125; 连接不会被重用，但它所拥有的所有级别资源都将被正确释放。 Consuming entity content(消费内容实体)消费实体内容的推荐方法是使用其HttpEntity＃getContent（）或HttpEntity＃writeTo（OutputStream）方法。HttpClient还附带了EntityUtils类，它公开了几种静态方法，以便更容易地从实体中读取内容或信息。可以使用此类中的方法检索字符串/字节数组中的整个内容主体，而不是直接读取java.io.InputStream。但是，强烈建议不要使用EntityUtils，除非响应实体来自可信HTTP服务器并且已知长度有限。12345678910111213141516CloseableHttpClient httpclient = HttpClients.createDefault();HttpGet httpget = new HttpGet(&quot;http://localhost/&quot;);CloseableHttpResponse response = httpclient.execute(httpget);try &#123; HttpEntity entity = response.getEntity(); if (entity != null) &#123; long len = entity.getContentLength(); if (len != -1 &amp;&amp; len &lt; 2048) &#123; System.out.println(EntityUtils.toString(entity)); &#125; else &#123; // Stream content out &#125; &#125;&#125; finally &#123; response.close();&#125; 在某些情况下，可能需要能够多次读取实体内容。在这种情况下，实体内容必须以某种方式缓冲，无论是在内存中还是在磁盘上。实现这一目标的最简单方法是使用BufferedHttpEntity类包装原始实体。这将导致原始实体的内容被读入内存缓冲区。在所有其他方式中，实体包装器将具有原始包装器。12345CloseableHttpResponse response = &lt;...&gt;HttpEntity entity = response.getEntity();if (entity != null) &#123; entity = new BufferedHttpEntity(entity);&#125; Producing entity content(生产内容实体)HttpClient提供了几个类，可用于通过HTTP连接有效地流出内容。这些类的实例可以与封闭请求（如POST和PUT）的实体相关联，以便将实体内容封装到传出的HTTP请求中。HttpClient为大多数常见数据容器提供了几个类，如字符串，字节数组，输入流和文件：StringEntity，ByteArrayEntity，InputStreamEntity和FileEntity。123456File file = new File(&quot;somefile.txt&quot;);FileEntity entity = new FileEntity(file, ContentType.create(&quot;text/plain&quot;, &quot;UTF-8&quot;)); HttpPost httppost = new HttpPost(&quot;http://localhost/action.do&quot;);httppost.setEntity(entity); 请注意，InputStreamEntity不可重复，因为它只能从基础数据流中读取一次。通常，建议实现自定义的HttpEntity类，而不是使用通用的InputStreamEntity。FileEntity可以是一个很好的起点。 HTML forms(表单)许多应用程序需要模拟提交HTML表单的过程，以便登录Web应用程序或提交输入数据。HttpClient提供实体类UrlEncodedFormEntity以方便该过程。123456List&lt;NameValuePair&gt; formparams = new ArrayList&lt;NameValuePair&gt;();formparams.add(new BasicNameValuePair(&quot;param1&quot;, &quot;value1&quot;));formparams.add(new BasicNameValuePair(&quot;param2&quot;, &quot;value2&quot;));UrlEncodedFormEntity entity = new UrlEncodedFormEntity(formparams, Consts.UTF_8);HttpPost httppost = new HttpPost(&quot;http://localhost/handler.do&quot;);httppost.setEntity(entity); UrlEncodedFormEntity实例将使用所谓的URL编码对参数进行编码并生成以下内容：1param1&#x3D;value1&amp;param2&#x3D;value2 Content chunking(内容分块)建议让HttpClient根据要传输的HTTP消息的属性选择最合适的传输编码。但是，通过将HttpEntity＃setChunked（）设置为true，可以通知HttpClient优先使用块编码。请注意，HttpClient将仅使用此标志作为提示。使用不支持块编码的HTTP协议版本（例如HTTP / 1.0）时，将忽略此值。 Response handlers(响应处理程序)处理响应的最简单和最方便的方法是使用ResponseHandler接口，该接口包含handleResponse（HttpResponse响应）方法。该方法完全使用户不必担心连接管理。使用ResponseHandler时，无论请求执行成功还是导致异常，HttpClient都会自动确保将连接释放回连接管理器。 1234567891011121314151617181920212223242526CloseableHttpClient httpclient = HttpClients.createDefault();HttpGet httpget = new HttpGet(&quot;http://localhost/json&quot;);ResponseHandler&lt;MyJsonObject&gt; rh = new ResponseHandler&lt;MyJsonObject&gt;() &#123; @Override public JsonObject handleResponse( final HttpResponse response) throws IOException &#123; StatusLine statusLine = response.getStatusLine(); HttpEntity entity = response.getEntity(); if (statusLine.getStatusCode() &gt;= 300) &#123; throw new HttpResponseException( statusLine.getStatusCode(), statusLine.getReasonPhrase()); &#125; if (entity == null) &#123; throw new ClientProtocolException(&quot;Response contains no content&quot;); &#125; Gson gson = new GsonBuilder().create(); ContentType contentType = ContentType.getOrDefault(entity); Charset charset = contentType.getCharset(); Reader reader = new InputStreamReader(entity.getContent(), charset); return gson.fromJson(reader, MyJsonObject.class); &#125;&#125;;MyJsonObject myjson = client.execute(httpget, rh); HttpClient interfaceHttpClient接口代表HTTP请求执行的最重要的契约。它对请求执行过程没有任何限制或特定细节，并且将连接管理，状态管理，身份验证和重定向处理的细节留给单个实现。这应该可以更容易地使用响应内容缓存等附加功能来修饰界面。通常，HttpClient实现充当许多专用处理程序或策略接口实现的外观，负责处理HTTP协议的特定方面，例如重定向或认证处理或决定连接持久性和保持活动持续时间。这使用户能够有选择地用自定义替换应用程序特定的这些方面的默认实现。 12345678910111213141516171819ConnectionKeepAliveStrategy keepAliveStrat = new DefaultConnectionKeepAliveStrategy() &#123; @Override public long getKeepAliveDuration( HttpResponse response, HttpContext context) &#123; long keepAlive = super.getKeepAliveDuration(response, context); if (keepAlive == -1) &#123; // Keep connections alive 5 seconds if a keep-alive value // has not be explicitly set by the server keepAlive = 5000; &#125; return keepAlive; &#125;&#125;;CloseableHttpClient httpclient = HttpClients.custom() .setKeepAliveStrategy(keepAliveStrat) .build(); HttpClient thread safety(HttpClient线程安全)HttpClient实现应该是线程安全的。建议将此类的同一实例重用于多个请求执行。 HttpClient resource deallocation(资源释放)当不再需要实例CloseableHttpClient并且即将超出范围时，必须通过调用CloseableHttpClient #close（）方法关闭与其关联的连接管理器。 123456CloseableHttpClient httpclient = HttpClients.createDefault();try &#123; &lt;...&gt;&#125; finally &#123; httpclient.close();&#125; HTTP execution context(HTTP执行上下文)最初，HTTP被设计为无状态，面向响应请求的协议。但是，真实世界的应用程序通常需要能够通过几个逻辑上相关的请求 - 响应交换来持久保存状态信息。为了使应用程序能够维持处理状态，HttpClient允许在特定的执行上下文中执行HTTP请求，称为HTTP上下文。如果在连续请求之间重用相同的上下文，则多个逻辑相关的请求可以参与逻辑会话。HTTP上下文函数与java.util.Map &lt;String，Object&gt;类似。它只是一组任意命名值。应用程序可以在请求执行之前填充上下文属性，也可以在执行完成后检查上下文。HttpContext可以包含任意对象，因此在多个线程之间共享可能不安全。建议每个执行线程都维护自己的上下文。在HTTP请求执行过程中，HttpClient将以下属性添加到执行上下文中： HttpConnection实例表示与目标服务器的实际连接。 HttpHost实例表示目标的连接 HttpRoute实例表示完整的连接路由 表示实际HTTP请求的HttpRequest实例。执行上下文中的最终HttpRequest对象始终表示消息的状态与发送到目标服务器的状态完全相同。默认HTTP / 1.0和HTTP / 1.1使用相对请求URI。但是，如果请求是通过代理以非隧道模式发送的，那么URI将是绝对的。 HttpResponse实例表示实际的HTTP响应。 java.lang.Boolean对象，表示指示实际请求是否已完全传输到连接目标的标志。 RequestConfig对象表示实际的请求配置。 java.util.List 对象，表示在请求执行过程中收到的所有重定向位置的集合。 可以使用HttpClientContext适配器类来简化与上下文状态的交互。 123456HttpContext context = &lt;...&gt;HttpClientContext clientContext = HttpClientContext.adapt(context);HttpHost target = clientContext.getTargetHost();HttpRequest request = clientContext.getRequest();HttpResponse response = clientContext.getResponse();RequestConfig config = clientContext.getRequestConfig(); 应使用相同的HttpContext实例执行表示逻辑相关会话的多个请求序列，以确保在请求之间自动传播会话上下文和状态信息。在以下示例中，初始请求设置的请求配置将保留在执行上下文中，并传播到共享相同上下文的连续请求。 123456789101112131415161718192021CloseableHttpClient httpclient = HttpClients.createDefault();RequestConfig requestConfig = RequestConfig.custom() .setSocketTimeout(1000) .setConnectTimeout(1000) .build();HttpGet httpget1 = new HttpGet(&quot;http://localhost/1&quot;);httpget1.setConfig(requestConfig);CloseableHttpResponse response1 = httpclient.execute(httpget1, context);try &#123; HttpEntity entity1 = response1.getEntity();&#125; finally &#123; response1.close();&#125;HttpGet httpget2 = new HttpGet(&quot;http://localhost/2&quot;);CloseableHttpResponse response2 = httpclient.execute(httpget2, context);try &#123; HttpEntity entity2 = response2.getEntity();&#125; finally &#123; response2.close();&#125; HTTP protocol interceptors(HTTP协议拦截器)HTTP协议拦截器是一个常规实现了Http协议的具体切面。通常，期望协议拦截器作用于传入传出消息的一个特定报头或一组相关报头。协议拦截器也可以操纵用消息附带的内容实体 - 透明内容压缩/解压缩就是一个很好的例子。通常这是通过使用’Decorator’模式来完成的，其中包装器实体类用于装饰原始实体。可以组合几个协议拦截器以形成一个逻辑单元。协议拦截器可以通过HTTP执行上下文共享信息（例如处理状态）来协作。协议拦截器可以使用HTTP上下文来存储一个请求或多个连续请求的处理状态。通常，执行拦截器的顺序无关紧要，只要它们不依赖于执行上下文的特定状态即可。如果协议拦截器具有相互依赖性，因此必须按特定顺序执行，则应按照与预期执行顺序相同的顺序将它们添加到协议处理器中。协议拦截器必须实现为线程安全的。与servlet类似，协议拦截器不应使用实例变量，除非同步访问这些变量。 这是一个如何使用本地上下文在连续请求之间保持处理状态的示例： 1234567891011121314151617181920212223242526CloseableHttpClient httpclient = HttpClients.custom() .addInterceptorLast(new HttpRequestInterceptor() &#123; public void process( final HttpRequest request, final HttpContext context) throws HttpException, IOException &#123; AtomicInteger count = (AtomicInteger) context.getAttribute(&quot;count&quot;); request.addHeader(&quot;Count&quot;, Integer.toString(count.getAndIncrement())); &#125; &#125;) .build();AtomicInteger count = new AtomicInteger(1);HttpClientContext localContext = HttpClientContext.create();localContext.setAttribute(&quot;count&quot;, count);HttpGet httpget = new HttpGet(&quot;http://localhost/&quot;);for (int i = 0; i &lt; 10; i++) &#123; CloseableHttpResponse response = httpclient.execute(httpget, localContext); try &#123; HttpEntity entity = response.getEntity(); &#125; finally &#123; response.close(); &#125;&#125; Exception handling(异常处理)HTTP协议处理器可以抛出两种类型的异常：在I / O故障（如套接字超时或套接字重置）和HttpException的情况下抛出java.io.IOException，表示HTTP故障（例如违反HTTP协议）。通常，I / O错误被认为是非致命和可恢复的，而HTTP协议错误被认为是致命的，无法自动恢复。请注意，HttpClient实现将HttpExceptions重新抛出为ClientProtocolException，它是java.io.IOException的子类。这使HttpClient的用户能够从单个catch子句处理I / O错误和协议违规 HTTP transport safety(Http传输安全)重要的是要理解HTTP协议并不是适合所有类型的应用程序。HTTP是一种简单的面向请求/响应的协议，最初设计用于支持静态或动态生成的内容检索。它从未打算支持事务操作。例如，如果HTTP服务器成功接收并处理请求，生成响应并将状态代码发送回客户端，则HTTP服务器将考虑这是合约履行的一部分。如果客户端由于读取超时，请求取消或系统崩溃而未能完全接收响应，则服务器将不会尝试回滚事务。如果客户端决定重试相同的请求，则服务器将不可避免地多次执行同一事务。在某些情况下，这可能会导致应用程序数据损坏或应用程序状态不一致。尽管HTTP从未被设计为支持事务处理，但只要满足某些条件，它仍可用作关键任务应用程序的传输协议。为确保HTTP传输层安全，系统必须确保应用层上HTTP方法的幂等性。 Idempotent methods(幂等方法)HTTP / 1.1规范将幂等方法定义为[方法也可以具有“幂等”的属性（除了错误或过期问题）N&gt; 0个相同请求的副作用与单个请求相同]换句话说，应用程序应该确保它准备好处理同一方法的多次执行的情况。例如，这可以通过提供唯一的事务id和通过避免执行相同逻辑操作的其他手段来实现。请注意，此问题并非特定于HttpClient。基于浏览器的应用程序与HTTP方法非幂等性相关的问题完全相同。默认情况下，HttpClient假定只有非实体封闭方法（如GET和HEAD）是幂等的，而实体封闭方法（如POST和PUT）因为兼容性原因问题所以不是幂等性。 Automatic exception recovery(自动异常恢复)默认情况下，HttpClient会尝试从I / O异常中自动恢复。默认的自动恢复机制仅限于一些已知安全的例外情况 HttpClient不会尝试从任何逻辑或HTTP协议错误（从HttpException类派生的错误）中恢复。 HttpClient将自动重试那些被认为是幂等的方法。 当HTTP请求仍在传输到目标服务器时（即请求尚未完全传输到服务器），HttpClient将自动重试那些因传输异常而失败的方法。 Request retry handler(请求重试处理程序)为了启用自定义异常恢复机制，应该提供HttpRequestRetryHandler接口的实现。 12345678910111213141516171819202122232425262728293031323334353637383940HttpRequestRetryHandler myRetryHandler = new HttpRequestRetryHandler() &#123; public boolean retryRequest( IOException exception, int executionCount, HttpContext context) &#123; if (executionCount &gt;= 5) &#123; // Do not retry if over max retry count return false; &#125; if (exception instanceof InterruptedIOException) &#123; // Timeout return false; &#125; if (exception instanceof UnknownHostException) &#123; // Unknown host return false; &#125; if (exception instanceof ConnectTimeoutException) &#123; // Connection refused return false; &#125; if (exception instanceof SSLException) &#123; // SSL handshake exception return false; &#125; HttpClientContext clientContext = HttpClientContext.adapt(context); HttpRequest request = clientContext.getRequest(); boolean idempotent = !(request instanceof HttpEntityEnclosingRequest); if (idempotent) &#123; // Retry if the request is considered idempotent return true; &#125; return false; &#125;&#125;;CloseableHttpClient httpclient = HttpClients.custom() .setRetryHandler(myRetryHandler) .build(); 请注意，可以使用StandardHttpRequestRetryHandler而不是默认使用的那个，以便将RFC-2616定义为幂等的请求方法视为安全自动重试：GET，HEAD，PUT，DELETE，OPTIONS和TRACE。 Aborting requests(关于请求)在某些情况下，由于目标服务器上的高负载或客户端发出的并发请求太多，HTTP请求执行无法在预期的时间范围内完成。在这种情况下，可能需要提前终止请求并解除阻塞I / O操作中阻止的执行线程。通过调用HttpUriRequest＃abort（）方法，可以在执行的任何阶段中止由HttpClient执行的HTTP请求。此方法是线程安全的，可以从任何线程调用。当HTTP请求被中止时，它的执行线程 - 即使当前在I / O操作中被阻塞 - 也可以通过抛出InterruptedIOException来解除阻塞 Redirect handling(重定向处理)HttpClient自动处理所有类型的重定向，除了HTTP规范明确禁止的需要用户干预的重定向。请参阅其他（状态代码303）重定向POST，并将PUT请求转换为HTTP规范要求的GET请求。可以使用自定义重定向策略来放宽对HTTP规范强加的POST方法的自动重定向的限制。 1234LaxRedirectStrategy redirectStrategy = new LaxRedirectStrategy();CloseableHttpClient httpclient = HttpClients.custom() .setRedirectStrategy(redirectStrategy) .build(); HttpClient通常必须在执行过程中重写请求消息。默认情况下，HTTP / 1.0和HTTP / 1.1通常使用相对请求URI。同样，原始请求可能会多次从一个位置重定向到另一个位置。可以使用原始请求和上下文构建最终解释的绝对HTTP位置。实用程序URIUtils #resolution可用于构建用于生成最终请求的已解释绝对URI。此方法包括重定向请求或原始请求中的最后一个片段标识符。 12345678910111213CloseableHttpClient httpclient = HttpClients.createDefault();HttpClientContext context = HttpClientContext.create();HttpGet httpget = new HttpGet(&quot;http://localhost:8080/&quot;);CloseableHttpResponse response = httpclient.execute(httpget, context);try &#123; HttpHost target = context.getTargetHost(); List&lt;URI&gt; redirectLocations = context.getRedirectLocations(); URI location = URIUtils.resolve(httpget.getURI(), target, redirectLocations); System.out.println(&quot;Final HTTP location: &quot; + location.toASCIIString()); // Expected to be an absolute URI&#125; finally &#123; response.close();&#125;","categories":[{"name":"网络","slug":"网络","permalink":"https://vincentxin-scott.github.io/categories/%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"HttpClient","slug":"HttpClient","permalink":"https://vincentxin-scott.github.io/tags/HttpClient/"}]},{"title":"支付宝支付","slug":"第三方支付/支付宝支付","date":"2019-07-08T03:13:26.143Z","updated":"2019-12-11T06:43:08.882Z","comments":true,"path":"2019/07/08/第三方支付/支付宝支付/","link":"","permalink":"https://vincentxin-scott.github.io/2019/07/08/%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98/%E6%94%AF%E4%BB%98%E5%AE%9D%E6%94%AF%E4%BB%98/","excerpt":"","text":"支付类型当面付 条码支付 扫码支付APP 支付适用于商家在 App 应用中集成支付宝支付功能。商家APP调用支付宝提供的 SDK，SDK 再调用支付宝APP内的支付模块。如果用户已安装支付宝 APP，商家 APP 会跳转到支付宝中完成支付，支付完后跳回到商家APP内，最后展示支付结果。如果用户没有安装支付宝 APP，商家 APP 内会调起支付宝网页支付收银台，用户登录支付宝账户，支付完后展示支付结果。目前支持手机系统有：iOS（苹果）、Android（安卓）。手机网站支付适用于商家在移动端网页应用中集成支付宝支付功能。商家在网页中调用支付宝提供的网页支付接口调起支付宝客户端内的支付模块，商家网页会跳转到支付宝中完成支付，支付完后跳回到商家网页内，最后展示支付结果。若无法唤起支付宝客户端，则在一定的时间后会自动进入网页支付流程。电脑网站支付通过电脑网站支付功能，用户在商家 PC 网站消费后界面会自动跳转到支付宝 PC 网站收银台完成付款。 交易资金直接打入商家支付宝账户，实时到账。用户交易款项即时到账，交易订单三个月内可退款，提供退款、清结算、对账等配套服务。","categories":[{"name":"第三方支付","slug":"第三方支付","permalink":"https://vincentxin-scott.github.io/categories/%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98/"}],"tags":[{"name":"支付宝支付","slug":"支付宝支付","permalink":"https://vincentxin-scott.github.io/tags/%E6%94%AF%E4%BB%98%E5%AE%9D%E6%94%AF%E4%BB%98/"}]},{"title":"Docker(四)多容器运行应用","slug":"Docker/docker | 04入门多容器运行应用","date":"2019-07-04T08:51:40.937Z","updated":"2020-03-06T02:57:23.158Z","comments":true,"path":"2019/07/04/Docker/docker | 04入门多容器运行应用/","link":"","permalink":"https://vincentxin-scott.github.io/2019/07/04/Docker/docker%20|%2004%E5%85%A5%E9%97%A8%E5%A4%9A%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E5%BA%94%E7%94%A8/","excerpt":"","text":"","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://vincentxin-scott.github.io/categories/DevOps/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://vincentxin-scott.github.io/tags/Docker/"}]},{"title":"Docker(三)构建镜像以及在单一容器运行","slug":"Docker/docker | 03入门构建镜像以及在单一容器运行","date":"2019-07-04T07:00:35.680Z","updated":"2020-03-06T02:57:04.120Z","comments":true,"path":"2019/07/04/Docker/docker | 03入门构建镜像以及在单一容器运行/","link":"","permalink":"https://vincentxin-scott.github.io/2019/07/04/Docker/docker%20|%2003%E5%85%A5%E9%97%A8%E6%9E%84%E5%BB%BA%E9%95%9C%E5%83%8F%E4%BB%A5%E5%8F%8A%E5%9C%A8%E5%8D%95%E4%B8%80%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C/","excerpt":"","text":"容器基本操作启动容器：1docker run IMAGE [COMMAND] [ARGS...] run 命令解释： 1.命令会检测当前要运行的镜像在本地存不存在,若不存在他会自动 pull 下来再运行 2.运行后会启动一个容器, 并且开启一个文件系统, 你可以直接在容器内创建文件夹. 运行一个指定的程序, 当程序退出后, 容器也就退出了 3.运行时的容器无法删除, 只能停止后删除, 或者加上 -f 参数强制删除 示例: docker run centos echo ‘hello docker’ 启动守护式容器:1docker run -i -t IMAGE /bin/bash -i --interactive=true|false 默认是false:允许你对容器内的标准输入 (STDIN) 进行交互 -t --tty=true|false 默认是false:在新容器内指定一个伪终端或终端 示例: docker run -i -t centos /bin/bash 使用exit退出守护式容器. 查看容器:docker ps [-a] [-l] -a:表示列举所有的容器 -l :表示列举最近创建的容器. 默认情况容器在运行之后就停止了,ps只是显示正在运行的容器. 查看容器详细信息:docker inspect [容器名字|容器唯一标识] 要查看容器详细信息,需要输入很长串的字母. docker允许用户自定义容器的名字: docker run --name=自定义名 -i -t IMAGE /bin/bash 重新启动停止的容器:docker start [-i] 容器名 删除停止的容器:docker rm 容器名 只能删除停止的容器,但是不能删除正在运行中的容器. 守护式容器以守护形式运行容器:启动容器:docker run -i -t IMAGE /bin/bash 退出但不关闭容器:Ctrl+P Ctrl+Q 附加到运行中的容器:docker attach 容器名 启动守护式容器:docker run -d 镜像名 [COMMAND] [ARG...] 示例:docker run --name dc1 -d centos /bin/sh -c &quot;while true; do echo helloworld;sleep 1;done&quot; 查看容器日志:docker logs [-f] [-t] [--tail] 容器名 -f --follow=true|false 默认为false 一致跟踪日志的变化,并返回结果 -t --timestamps=true|false 默认为false 在返回的结果上加上时间戳 --tail = “all” 返回后几行的日志数据. 查看容器内进程:docker top 容器名 在运行中的容器内启动新进程:docker exec [-d] [-i] [-t] 容器名 [COMMAND] [ARG...] 示例:docker exec -i -t dc1 /bin/bash 停止守护式容器:docker stop 容器名 :发送一个信号给容器,等待容器的关闭. docker kill 容器名 :直接停止容器. 设置容器的端口映射run [-P] [-p] -P , --publish-all=true|false 默认为false :将为容器所有暴露的端口进行映射. 示例:docker run -P -i -t centos /bin/bash -p, --publish=[] :给指定的端口进行映射. 方式一:containerPort 示例:docker run -p 80 -i -t centos /bin/bash 方式二:hostPort:containerPort 示例:docker run -p 8080:80 -i -t centos /bin/bash 方式三:ip::containerPort 示例:docker run -p 0.0.0.0:80 -i -t centos /bin/bash 方式四:ip:hostPort:containerPort 示例:docker run -p 0.0.0.0:8080:80 -i -t centos /bin/bash Docker镜像和仓库列出镜像docker images [OPTIONS] [REPOSITORY] -a, --all=false :表示列举出所有的镜像.默认并不显示中间层的镜像. -f, --filter=[] :表示添加过滤条件. --no-trunc=false:表示对信息进行截断.默认情况是会截断镜像的唯一id的. -q, --quiet=false:表示值显示镜像的唯一id REPOSITORY 仓库: 是一切镜像的集合. REGISTRY 注册仓库:包含REPOSITORY 的仓库. TAG 标签:我们之前运行的centos默认使用的是lastest的标签.仓库名+镜像名就能唯一确定一个镜像. 如果使用docker images -a 看到没有仓库名和标签名的其实是中间层镜像. 删除镜像docker rmi [OPTIONS] IMAGE [IMAGE...] -f, --force=false :表示强制删除镜像. --no-proune=false :会保留未被打标签的父镜像. 删除对应仓库所有的镜像:docker rmi $(docker images -q centos) 获取和推送镜像Docker中REGISTER仓库有些类似Maven的中央仓库.我们通过类似Git中的pull和push命令从REGISTER仓库中拉取镜像和推送镜像. 查找镜像:方式一: Docker Hub https://hub.docker.com/ 方式二: docker search [OPTIONS] TERM --no-trunc=false : 截断操作 -s,--starts=0 : 每个镜像都会有star,我们可以通过-s操作来限定star数. 一次最多返回25条记录. 拉取镜像:docker pull [OPTIONS] NAME [:TAG] -a, --all-tags=false :会把所有仓库中标记的镜像下载到本地中 示例:docker pull ubuntu:14.04 我们会发现我们拉取镜像的速度非常慢.我们可以修改REGISTER仓库的地址来加快下载的速度. https://www.daocloud.io/mirror#accelerator-doc curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://a7775d97.m.daocloud.io sudo systemctl restart docker docker pull ubuntu:12.10 我们会发现明显速度已经提升很多了. 推送镜像:docker push 镜像名. 步骤: 1.注册hub的账号. 2.登陆hub的账号.docker login 3.使用push命令推送到hub中 docker push username/repo name/tag 构建镜像构建镜像可以让我们保存对容器的修改,并再次使用.提供了自定义镜像的能力,以软件的形式打包并方法服务及其运行环境.docker里面提供了两种方式来构建镜像: 方式一:docker commit 通过容器构建 方式二:docker build 通过Dockerfile文件构建. 使用commit构建镜像:docker commit [OPTIONS] CONTAINER(容器名称) [REPOSITORY[:TAG]] -a, --author=”” 指定镜像的作者. -m, --message=”” 提交信息,构建信息 -p, --pause=true 默认情况在commit的时候会暂停容器,使用这个参数可以在构建的时候不暂停容器. 步骤: 1.创建一个容器并安装nginx服务 docker run -it --name commit_test -p 80 centos /bin/bash 2.在容器内部安装nginx,和之前步骤一样 3.提交镜像. docker commit -a &#39;作者信息&#39; -m &#39;备注&#39; commit_test（容器名称） username/repo:tag 4.通过docker images命令可以看到我们刚构建的镜像. 5.推送到远程仓库 docker push username/repo:tag 使用Dockerfile定义容器:Dockerfile定义容器内环境中发生的事情。对网络接口和磁盘驱动器等资源的访问在此环境中进行虚拟化，该环境与系统的其他部分隔离，因此您需要将端口映射到外部世界，并具体说明要“复制”到哪些文件。您可以预期在此Dockerfile中定义的应用程序的构建在其运行的任何位置都表现完全相同。 什么是Dockerfile文件呢?其实就是包含了一些执行命令的文本文件.docker build [OPTIONS] PATH|URL|- --force-rm=false --no-cache=false --pull=false -q, --quiet=false -rm=true -t, --tag=”” 步骤: 1.在宿主机中,我们创建存放Dockerfile文件的目录和Dockerfile文件. mkdir -p dockerfile/df_test1 cd dockerfile/df_test1/ vi Dockerfile 2.编写Dockfile文件 # First docker file for test FROM centos MAINTAINER lanxw0720 &quot;lanxiongwei@wolfcode.cn&quot; RUN yum install -y wget RUN wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo RUN yum install -y epel-release RUN yum install -y nginx EXPOSE 80 3.使用build命令构建镜像. docker build -t=&#39;lanxw0720/df_test1&#39; . 4.通过我们构建好的镜像来创建容器. docker run -d --name nginx_web3 -p 80 lanxw0720/df_test1 /usr/sbin/nginx -g &quot;daemon off;&quot; Dockerfile的指令格式指令主要分为两种: 注释 : # Comment 指令 : INSTRUCTION argument FROM: 包含两种格式: 1. FROM &lt;image&gt; 2. FROM &lt;image&gt;:&lt;tag&gt; image要求是已经存在的镜像,我们也称为基础镜像.必须是第一条非注释指令 MAINTAINER: 指定镜像的作者信息,包含镜像的所有者和联系信息. RUN: 指定当前镜像中运行的命令 RUN &lt;command&gt; (shell模式) /bin/sh -c command RUN echo hello RUN [“executable”,”param1”,”param2”] (exec模式) RUN [“/bin/bash”,”-c”,”echo hello”] 每个RUN命令都会在当前镜像的上层创建一个新的镜像来运行指令. EXPOSE: 指定运行该镜像的容器使用的端口. 虽然我们在构建镜像的时候暴露了端口号,但是我们在运行容器的时候依然需要指定端口的映射. 我们使用EXPOSE只是告诉Docker运行该镜像的容器会使用80端口,出于安全的考虑,docker并不会打开该端口. 而是需要我们在使用该镜像运行容器的时候指定端口的映射. CMD: CMD指令提供容器默认运行的命令,和之前讲的RUN指令类似.都是执行一个命令,但是RUN命令指定的命令是在镜像构建的过程运行的. CMD的命令是在容器运行的时候运行的.如果我们在docker run命令中指定运行的命令的时候,CMD的指令会被覆盖,默认命令就不会执行. CMD命令是指定容器启动的时候默认命令. 两种模式. CMD [“executable”,”param1”,”param2”] (exec模式) CMD command param1 param2 (shell 模式) CMD [”param1”,”param2”] (作为ENTRYPOINT指令的默认参数.) 通过构建的镜像来创建容器 docker run -p 80 --name cmd_test1 -itd lanxw0720/df_test3 docker top cmd_test1 发现已经启动nginx了. 如果我们在启动的时候指定了参数,默认的CMD命令就会被覆盖了. ENTRYPOINT: 这个和我们刚刚讲的CMD指令非常相似,唯一的区别:不会给docker run的启动命令给覆盖. 如果需要覆盖ENTRYPOINT的指令,需要在docker run使用docker run --entrypoint覆盖. ENTRYPOINT [“executable”,”param1”,”param2”] (exec模式) ENTRYPOINT command param1 param2 (shell 模式) 示例: docker build -t=&quot;lanxw0720/df_test4&quot; . docker run -p 80 --name ep_test1 -d lanxw0720/df_test4 docker ps -l 可以发现,启动的容器依然使用的ENTRYPOINT指定的命令执行. ADD: 将文件和目录复制到使用dockerfile构建的镜像中. 目标的来源可以本地的地址也可以是远程地址. 如果是本地地址,本地地址必须是构建目录中的相对地址 对于远程URL,docker并不推荐使用,更建议使用的是curl或者wget的命令来获取 目标路径需要指定镜像中的绝对路径 ADD &lt;src&gt;...&lt;dest&gt; ADD [“&lt;src&gt;”...”&lt;dest&gt;”](适用于文件路径有空格的情况) COPY: 同上. COPY&lt;src&gt;...&lt;dest&gt; COPY[“&lt;src&gt;”...”&lt;dest&gt;”](适用于文件路径有空格的情况) 示例: 在Dockerfile所在目录添加index.html文件 docker build -t=&quot;lanxw0720/df_test6&quot; . docker run -p 80 --name add_test1 -d lanxw0720/df_test6 curl http://127.0.0.1:32775 VOLUME: 用于基于镜像创建的容器添加卷,一个卷可以存在一个或者多个容器的特定目录.这个目录可以绕过联合文件系统.提供共享数据和持久化数据的功能.(后面单独讲) WORKDIR: WORKDIR /path/to/workdir 这个指令从指令创建一个容器是,在容器内部设置工作目录.ENTRYPOINT和CMD的命令都会在这个目录下执行. 我们也可以使用这个命令给后续的构建中指定工作目录. 通常会使用绝对路径,如果使用了相对路径,那这个路径会一致传递下去.如下所示: WORKDIR /a WORKDIR b WORKDIR c RUN pwd 结果====&gt;/a/b/c ENV: ENV &lt;key&gt;&lt;value&gt; ENV &lt;key&gt;&lt;value&gt;... 这个指令主要是来设置环境变量,这个环境变量在构建过程中和运行过程中都有效. USER: USER daemon 指定镜像会以什么样的用户去运行. 比如:USER nginx 基于该镜像启动的容器就会以nginx的用户来运行. 如果没有指定USER,容器会使用root用户来运行. ONBUILD: ONBUILD [INSTRUCTION] 镜像触发器. 当一个镜像被其他镜像作为基础镜像时执行 会在构建过程中插入指令 示例: docker run -p 80 --name onbuild_test1 -d lanxw0720/df_test7 curl http://127.0.0.1:32776 发现在构建这个镜像的时候并没有执行COPY命令. 接下来我们基于这个镜像来构建新的镜像. docker build -t=&quot;lanxw0720/df_test8&quot; . docker run -p 80 --name onbuild_test2 -d lanxw0720/df_test8 curl http://127.0.0.1:32777 此时发现已经执行COPY命令了.","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://vincentxin-scott.github.io/categories/DevOps/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://vincentxin-scott.github.io/tags/Docker/"}]},{"title":"Markdown代码高亮支持语言","slug":"杂记随笔/Markdown代码高亮支持语言","date":"2019-07-02T15:07:01.164Z","updated":"2019-12-11T06:43:01.446Z","comments":true,"path":"2019/07/02/杂记随笔/Markdown代码高亮支持语言/","link":"","permalink":"https://vincentxin-scott.github.io/2019/07/02/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/Markdown%E4%BB%A3%E7%A0%81%E9%AB%98%E4%BA%AE%E6%94%AF%E6%8C%81%E8%AF%AD%E8%A8%80/","excerpt":"","text":"使用方式```（语言关键字）|语言|关键字||—|—|AppleScript|applescriptActionScript 3.0|actionscript3, as3Shell|bash, shellColdFusion|coldfusion, cfC|cpp, cC#|c-sharp, csharpCSS|cssDelphi|delphi, pascal, pasdiff&amp;patch|diff patchErlang|erl, erlangGroovy|groovyJava|javaJavaFX|jfx, javafxJavaScript|js, jscript, javascriptPerl|perl, pl, PerlPHP|phptext|text, plainPython|py, pythonRuby|ruby, rails, ror, rbSASS&amp;SCSS|sass, scssScala|scalaSQL|sqlVisual Basic|vb, vbnetXML|xml, xhtml, xslt, htmlObjective C|objc, obj-cF#|f#, f-sharp, fsharpR|r, s, splusmatlab|matlabswift|swift 作者：码农吉小星链接：https://www.jianshu.com/p/f02d5a3736ba来源：简书简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。","categories":[{"name":"杂记随笔","slug":"杂记随笔","permalink":"https://vincentxin-scott.github.io/categories/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://vincentxin-scott.github.io/tags/Markdown/"}]},{"title":"lftp应用","slug":"杂记随笔/lftp的使用","date":"2019-07-02T14:59:37.100Z","updated":"2019-12-11T06:43:03.113Z","comments":true,"path":"2019/07/02/杂记随笔/lftp的使用/","link":"","permalink":"https://vincentxin-scott.github.io/2019/07/02/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/lftp%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"lftp简介lftp 是一个功能强大的下载工具，它支持访问文件的协议: ftp, ftps, http, https, hftp,fish.(其中ftps和https需要在编译的时候包含openssl库)。llftp的界面非常想一个shell:有命令补全，历史记录，允许多个后台任务执行等功能，使用起来非常方便。它还有书签、排队、镜像、断点续传、多进程下载等功能。 1.常见登录到对方服务器方法12345678#登录到ftp--法1lftp (ftp:&#x2F;&#x2F;)user:password@site:21 #ftp:&#x2F;&#x2F;可以省略，默认21端口可以省略#登录到ftp--法2lftp (ftp:&#x2F;&#x2F;)user@site:port #这种方式回车后，系统提示输入密码#登录到sftp---法1lftp sftp:&#x2F;&#x2F;user:password@site:22 #如果是默认端口22，可以省略，如果不是就必须填写端口号#登录到sftp---法2lftp sftp:&#x2F;&#x2F;user@password:port 当然lftp的登录方式还有很多种记录常用的即可 2.lftp常用option，lftp [OPTS]12345678-f #执行文件中的命令后退出-c #执行命令后退出--help #显示帮助信息后退出--version #显示 lftp 版本后退出#其他的选项同 &#39;open&#39; 命令-e #在选择后执行命令-u [,] #使用指定的用户名&#x2F;口令进行验证-p #连接指定的端口 3.登录后常用命令1234567891011121314cd #切换远端目录， lcd 切换本地目录ls #显示远端文件列表 !ls 显示本地文件列表get #下载远端文件 mget 下载远端文件可以用通配符也就是 *，pget 使用多个线程来下载远端文件, 预设为五个。mirror #下载&#x2F;上传(mirror -R)&#x2F;同步 整个目录。put #上传文件 ，mput 上传多个文件(支持通配符)mv #移动远端文件(远端文件改名)rm #删除远端文件， mrm 删除多个远端文件(支持通配符)mkdir #建立远端目录 ，rmdir删除远端目录pwd #显示目前远端所在目录，lpwd 显示本地目录du #计算远端目录的大小! #执行本地 shell的命令，如!datealias #定义别名bookmark #设定书签exit #退出ftp 注：ftp中的bookmark命令，是将配置写到~/.lftp/bookmarks文件中；我们可以直接修改此文件，快速登陆ftp服务器。 4.小技巧lftp中文乱码问题 1set ftp:charset gbk #(或者 gb2312 或 utf-8) 设置ftp端的编码格式 set -a 查看所有可以设置的命令 设置被动/非被动模式 12set ftp:passive-mode 1 ## 1 被动 0主动 查找ftp端文件 1234ls *.txt ##查找当前目录下的所有txt文件ls .&#x2F;123&#x2F; ##列出123目录下所有文件find . -name &quot;*.txt&quot; ##递归查找站点上所有的txt文件find .&#x2F;xx -name &quot;*.txt&quot; ##查找xx目录下所有的txt文件 ls第二次读取的是本地缓存,可以用 rels 代替 ls 或者catch off / catch on 来开关catch,catch flush清空本地catch 多任务处理 123456789101112ctrl+z ##将当前进行的任务移交后台处理，也可以在命令行末尾加&amp;符号使任务在后台执行wait ##将后台处理任务调至前台查看jobs ##查看后台进行的任务列表kill all 或者 job_no ##删除所有任务 或 指定的任务queue start ##开始任务列表queue stop ##停止任务列表##将任务加入任务列表queue get 123.txtqueue put 234.txtqueue mirror aaa&#x2F; 定义别名 123alias #查看所有定义的别名alias less more #定义别名 将less定义为more的功能alias less #后面直接跟别名，取消别名 bookmark 书签 12345bookmark add [name] #增加名称为 name 的书签bookmark del [name] #删除名称为 name 的书签bookmark list #显示目前有设定那些书签（或直接输入bookmark）bookmark edit #编辑器修改书签 (~&#x2F;.lftp&#x2F;bookmarks)open [name] #链接书签 常用实例 123456get -c a.zip # -c 断点续传mget *.txt #下载所有远程当前目录的txt文档mirror --parallel&#x3D;3 incoming #--parallel 多线程， 下载整个incoming目录mirror -R local_name #上传本地local_name目录pget -n 6 a.zip #多线程，默认5线程lftp -c &quot;pget -n 10 http:&#x2F;&#x2F;www.baidu.com&#x2F;img&#x2F;baidu_jgylogo3.gif&quot; #多线程 断点续传 http资源 增量备份 以前的博文中就讲到过的，在拿出来 123456lftp -u [username],[password] -e &quot;mirror -R --delete --only-newer --verbose 本地目录 远程目录&quot; [ftpsite]# -e 告诉lftp执行连接服务器后接着运行指定命令# mirror -R 上传目录# --delete：删除远程备份服务器中存在的文件而本地服务器不存在的文件#--only-newer ：lftp只上传新的文件#--verbose：监视同步的进程 当如如果要恢复的话 1lftp -u username,password -e &quot;mirror --delete --only-newer --verbose 远程目录 本地目录&quot; ftpsite","categories":[{"name":"杂记随笔","slug":"杂记随笔","permalink":"https://vincentxin-scott.github.io/categories/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"lftp","slug":"lftp","permalink":"https://vincentxin-scott.github.io/tags/lftp/"}]},{"title":"Homebrew安装","slug":"Mac/Homebrew安装","date":"2019-06-23T16:02:31.203Z","updated":"2019-12-11T06:47:50.701Z","comments":true,"path":"2019/06/24/Mac/Homebrew安装/","link":"","permalink":"https://vincentxin-scott.github.io/2019/06/24/Mac/Homebrew%E5%AE%89%E8%A3%85/","excerpt":"","text":"首先确认 xcode 已经安装App Store 中安装。或者 1xcode-select --install 打开 Homebrew 官网https://brew.sh/index_zh-cn 按照官网提示或者直接复制下面内容进行安装。 1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install) 错误情况一：1234error: RPC failed; curl 18 transfer closed with outstanding read data remainingfatal: The remote end hung up unexpectedlyfatal: early EOFfatal: index-pack failed 解决方案：设置请求的数据缓存大小，防止请求回执的数据庞大报错。 12git config --global http.postBuffer 524288000 错误情况二：1fatal:unable to access &#x27;http://github.com/Homebrew/brew/&#x27;:Could not resolve host:github.com 删除 rm -f /usr/local/Homebrew 之后重试。重新执行安装","categories":[{"name":"Mac","slug":"Mac","permalink":"https://vincentxin-scott.github.io/categories/Mac/"}],"tags":[{"name":"Homebrew","slug":"Homebrew","permalink":"https://vincentxin-scott.github.io/tags/Homebrew/"}]},{"title":"Homebrew换源","slug":"Mac/Homebrew更换中科大源","date":"2019-06-23T15:32:55.845Z","updated":"2019-12-11T06:47:24.971Z","comments":true,"path":"2019/06/23/Mac/Homebrew更换中科大源/","link":"","permalink":"https://vincentxin-scott.github.io/2019/06/23/Mac/Homebrew%E6%9B%B4%E6%8D%A2%E4%B8%AD%E7%A7%91%E5%A4%A7%E6%BA%90/","excerpt":"","text":"更换中科大的源地址更换Homebrew源文件仓库地址12cd &quot;$(brew --repo)&quot;git remote set-url origin https://mirrors.ustc.edu.cn/brew.git 更换Homebrew 核心软件仓库123cd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot;git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git 更换Homebrew 预编译二进制软件包对于 bash 用户： 12echo &#x27;export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles&#x27; &gt;&gt; ~/.bash_profilesource ~/.bash_profile 对于 zsh 用户： 12echo &#x27;export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles&#x27; &gt;&gt; ~/.zshrcsource ~/.zshrc Homebrew cask 软件仓库，提供 macOS 应用和大型二进制文件123cd &quot;$(brew --repo)&quot;/Library/Taps/homebrew/homebrew-caskgit remote set-url origin https://mirrors.ustc.edu.cn/homebrew-cask.git 还原官方源地址还原Homebrew源文件仓库地址123cd &quot;$(brew --repo)&quot;git remote set-url origin https://github.com/Homebrew/brew.git 还原Homebrew 核心软件仓库123cd &quot;$(brew --repo)/Library/Taps/homebrew/homebrew-core&quot;git remote set-url origin https://github.com/Homebrew/homebrew-core 还原Homebrew 预编译二进制软件包对于 bash 用户： 1234vim ~/.bash_profile找到 “export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles&#x27;”代码行注释掉。 source ~/.bash_profile 对于 zsh 用户： 123vim ~/.zshrc找到 “export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles&#x27;”代码行注释掉。source ~/.zshrc 还原Homebrew cask 软件仓库，提供 macOS 应用和大型二进制文件123cd &quot;$(brew --repo)&quot;/Library/Taps/homebrew/homebrew-caskgit remote set-url origin https://github.com/Homebrew/homebrew-cask","categories":[{"name":"Mac","slug":"Mac","permalink":"https://vincentxin-scott.github.io/categories/Mac/"}],"tags":[{"name":"Homebrew","slug":"Homebrew","permalink":"https://vincentxin-scott.github.io/tags/Homebrew/"}]},{"title":"Docker删除缓存的images","slug":"Docker/docker删除缓存的images","date":"2019-06-20T17:05:15.703Z","updated":"2019-12-11T07:04:35.280Z","comments":true,"path":"2019/06/21/Docker/docker删除缓存的images/","link":"","permalink":"https://vincentxin-scott.github.io/2019/06/21/Docker/docker%E5%88%A0%E9%99%A4%E7%BC%93%E5%AD%98%E7%9A%84images/","excerpt":"","text":"删除缓存的images在系统文件：/var/lib/docker/image/overlay2/imagedb/content/sha256使用 ls与docker images 命令对比删除 rm 前缀*","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://vincentxin-scott.github.io/categories/DevOps/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://vincentxin-scott.github.io/tags/Docker/"}]},{"title":"Docker(二)安装","slug":"Docker/docker | 02入门安装","date":"2019-06-20T00:44:49.599Z","updated":"2020-03-06T02:56:48.847Z","comments":true,"path":"2019/06/20/Docker/docker | 02入门安装/","link":"","permalink":"https://vincentxin-scott.github.io/2019/06/20/Docker/docker%20|%2002%E5%85%A5%E9%97%A8%E5%AE%89%E8%A3%85/","excerpt":"","text":"Centos7 安装Docker CEDocker系统有两个程序：docker服务端和docker客户端。其中docker服务端是一个服务进程，管理着所有的容器。docker客户端则扮演着docker服务端的远程控制器，可以用来控制docker的服务端进程。大部分情况下，docker服务端和客户端运行在一台机器上。 1234567891011121314151617181920212223242526272829303132333435363738394041424344Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 2Server Version: 18.09.6Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: bb71b10fd8f58240ca47fbb579b9d1028eea7c84runc version: 2b18fe1d885ee5083ef9f0838fee39b62d653e30init version: fec3683Security Options: seccomp Profile: defaultKernel Version: 3.10.0-957.5.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.7GiBName: vincent-osID: FPSG:FBC3:LLNU:6TCG:HATE:NZ6J:Z36F:C6PY:KSYW:RGFE:AER6:IFDMDocker Root Dir: &#x2F;var&#x2F;lib&#x2F;dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https:&#x2F;&#x2F;index.docker.io&#x2F;v1&#x2F;Labels:Experimental: falseInsecure Registries: 127.0.0.0&#x2F;8Live Restore Enabled: falseProduct License: Community Engine 安装步骤卸载旧版本（未安装跳过此步骤）12345678910yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 安装yum插件1.安装所需的软件包 yum-utils提供了yum-config-manager 效用 1yum install -y yum-utils tools for manipulating repositories and extended package management(用于操作存储库和扩展包管理的工具) 2.并需要安装device-mapper-persistent-data和lvm2支持devicemapper存储驱动程序。 1yum install -y device-mapper-persistent-data \\lvm23.设置使用国内镜像源 123yum-config-manager \\ --add-repo \\ https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo 4.更新更新 yum 软件源缓存 1yum makecache fast 安装Docker-CE1yum install docker-ce 1.设置开机启动并启动Docker 12systemctl enable dockersystemctl start docker 2.更新Docker与安装相似，只需要将install替换为upgrade 1yum -y upgrade docker-ce 3.镜像加速找到文件/etc/docker/daemon.json修改参数 1234567&#123; &quot;registry-mirrors&quot;: [ &quot;https://dockerhub.azk8s.cn&quot;, &quot;https://reg-mirror.qiniu.com&quot;, &quot;http://hub-mirror.c.163.com&quot; ]&#125; 4.修改之后重新加载并重启docker 12systemctl daemon-reloadsystemctl restart docker 重启之后docker info 中的镜像源信息 MacOS 安装Docker1brew install docker 其实最好的是直接安装docker Desktop Docker 基础命令12345678910111213141516171819## List Docker CLI commands（列出Docker的命令行指令）dockerdocker container --help## Display Docker version and info（显示Docker的版本和详细信息）docker --versiondocker versiondocker info## Execute Docker image （Docker启动镜像或者说是创建镜像实例启动容器）docker run hello-world## List Docker images （列出docker所有镜像）docker image ls## List Docker containers (列出所有Docker的所有容器）docker container ls ## 列出所有运行的容器docker container ls --all ## 列出所有的容器docker container ls -aq ## 只列出了容器ID","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://vincentxin-scott.github.io/categories/DevOps/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://vincentxin-scott.github.io/tags/Docker/"}]},{"title":"01｜Jenkins安装配置","slug":"Jenkins/01｜Jenkins安装配置","date":"2019-06-19T15:20:08.756Z","updated":"2020-04-27T02:38:16.282Z","comments":true,"path":"2019/06/19/Jenkins/01｜Jenkins安装配置/","link":"","permalink":"https://vincentxin-scott.github.io/2019/06/19/Jenkins/01%EF%BD%9CJenkins%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","excerpt":"","text":"准备工作 centos 环境 docker 安装 docker-compose(选择性安装) 安装JDK 安装maven 如果是git管理的项目装gitCentos 7 Docker 安装Jenkins 镜像","categories":[{"name":"DevOps","slug":"DevOps","permalink":"https://vincentxin-scott.github.io/categories/DevOps/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://vincentxin-scott.github.io/tags/Jenkins/"}]},{"title":"SpringCloud_Zuul","slug":"SpringCloud/02｜Zuul","date":"2019-06-13T15:30:52.323Z","updated":"2020-04-17T07:20:51.741Z","comments":true,"path":"2019/06/13/SpringCloud/02｜Zuul/","link":"","permalink":"https://vincentxin-scott.github.io/2019/06/13/SpringCloud/02%EF%BD%9CZuul/","excerpt":"","text":"定义：Zuul是Netflix的基于JVM的路由器和服务器端负载均衡器。 Zuul属性12345&#x2F;&#x2F;默认&#x2F;&#x2F;最大连接数zuul.host.maxTotalConnections &#x3D; 200 &#x2F;&#x2F;预制连接zuul.host.maxPerRouteConnections &#x3D; 20 所有路由的默认Hystrix隔离模式（ExecutionIsolationStrategy）都是 SEMAPHORE。可以将zuul.ribbonIsolationStrategy更改为THREAD，这是官方推荐的选择（使用熔断的线程池来达到线程级别隔离） Zuul routers 配置模式服务ID模式 要跳过自动添加的服务，请将zuul.ignored-services设置为服务ID模式列表。如果服务与忽略包含则按照显式配置的路由映射模式匹配 1234567application.yml:zuul: ignoredServices: &#39;*&#39; routes: users: &#x2F;myusers&#x2F;** 只开放users服务，请求路径就是/myusers/**，所有前缀是/myusers的HTTP请求都指向users服务。 要对路由进行更细粒度的控制，可以单独指定路径和serviceId 123456application.yml:routes: users: path: &#x2F;myusers&#x2F;** serviceId: users_service 所有前缀为/myusers的HTTP请求都指向users_service服务。 物理地址模式 制定地址url 123456application.yml:routes: users: path: &#x2F;myusers&#x2F;** url: https:&#x2F;&#x2F;example.com&#x2F;users_service 这些简单的url-routes不会作为HystrixCommand执行，也不会使用Ribbon对多个URL进行负载均衡。 Zuul 请求Zuul使用的默认HTTP客户端现在由Apache HTTP Client支持，而不是不推荐使用的Ribbon RestClient。要使用RestClient或okhttp3.OkHttpClient，请分别设置ribbon.restclient.enabled = true或ribbon.okhttp.enabled = true。 通过 Zuul实现文件上传如果您使用@EnableZuulProxy，您可以使用代理路径上传文件，只要文件很小，它就可以工作。对于大型文件，有一个替代路径绕过 zuul 中的Spring DispatcherServlet（以避免多部分处理）。换句话说，如果你有zuul.routes.customers = /customers / *，那么你可以将大文件POST到/zuul / customers / *。servlet路径通过zuul.servletPath外部化。*如果代理路由引导您完成功能区负载平衡器，则极大文件也需要提升超时设置** 123456application.yml. hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 60000ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 Zuul Timeout如果您想为通过Zuul代理的请求配置套接字超时和读取超时，您有两种选择，具体取决于您的配置：如果Zuul使用服务发现，则需要使用功能区属性配置这些超时。 ribbon.ReadTimeout ribbon.SocketTimeout 如果通过指定URL配置了Zuul路由，则需要使用 zuul.host.connect-timeout-millis zuul.host.socket-timeout-millis。 Zuul内部使用Ribbon来调用远程URL，并且在第一次调用时，Spring Cloud会默认懒加载Ribbon客户端。可以使用以下配置更改Zuul的此行为，并将导致在应用程序启动时急切地加载子功能区相关的应用程序上下文。 application.yaml1234zuul: ribbon: eager-load: enabled: true application.properties1zuul.ribbon.eager-load.enabled= true 服务发现配置—如果Zuul正在使用服务发现，则需要关注两个超时，Hystrix超时（因为默认情况下所有路由都包含在Hystrix命令中）和功能区超时。Hystrix超时需要考虑功能区读取和连接超时PLUS将为该服务发生的重试总次数。默认情况下，Spring Cloud Zuul会尽力为您计算Hystrix超时，除非您明确指定Hystrix超时。 Hystrix的熔断超时计算方式 12(ribbon.ConnectTimeout + ribbon.ReadTimeout) * (ribbon.MaxAutoRetries + 1) * (ribbon.MaxAutoRetriesNextServer + 1) application.yaml 12345ribbon: ReadTimeout:100 &#x2F;&#x2F;读取等待时间 ConnectTimeout:500 &#x2F;&#x2F;连接建立时间 MaxAutoRetries:1 &#x2F;&#x2F;最大重试次数 MaxAutoRetriesNextServer:1 &#x2F;&#x2F; 重试服务器个数 如上配置，Hystrix的熔断超时时间为2400ms 禁用Hystrix的熔断超时功能 1hystrix.command.default.execution.timeout.enabled = false @EnableZuulProxy Filters创建DiscoveryClientRouteLocator，用于从DiscoveryClient（例如Eureka）以及属性加载路径定义。为DiscoveryClient中的每个serviceId创建一个路由。添加新服务后，将刷新路由。除了前面描述的过滤器之外，还安装了以下过滤器（与普通的Spring Bean一样）： Pre filters: PreDecorationFilter：根据提供的RouteLocator确定路由的位置和方式。它还为下游请求设置各种与代理相关的标头。 Route filters: RibbonRoutingFilter：使用Ribbon，Hystrix和可插入HTTP客户端发送请求。服务ID位于RequestContext属性FilterConstants.SERVICE_ID_KEY中。此过滤器可以使用不同的HTTP客户端： 1.Apache HttpClient：默认客户端。 2.Squareup OkHttpClient v3：通过在类路径上设置com.squareup.okhttp3：okhttp库并设置ribbon.okhttp.enabled = true来启用。 3.Netflix Ribbon HTTP客户端：通过设置ribbon.restclient.enabled = true启用。 此客户端具有限制，包括它不支持PATCH方法，但它也具有内置重试。 SimpleHostRoutingFilter：通过Apache HttpClient向预定URL发送请求。URL位于RequestContext.getRouteHost（）中。","categories":[{"name":"框架","slug":"框架","permalink":"https://vincentxin-scott.github.io/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://vincentxin-scott.github.io/tags/SpringCloud/"}]},{"title":"SpringCloud_Ribbon","slug":"SpringCloud/03｜Ribbon","date":"2019-06-13T15:17:37.996Z","updated":"2020-04-17T07:21:00.408Z","comments":true,"path":"2019/06/13/SpringCloud/03｜Ribbon/","link":"","permalink":"https://vincentxin-scott.github.io/2019/06/13/SpringCloud/03%EF%BD%9CRibbon/","excerpt":"","text":"定义：Ribbon是一个客户端负载均衡器，可以让您对HTTP和TCP客户端的行为进行大量控制。Feign已经使用了Ribbon，因此，如果您使用@FeignClient，此部分也适用。Ribbon中的一个核心概念是指定客户端的概念。每个负载均衡器都是一组组件的一部分，这些组件一起工作以按需联系远程服务器，并且该集合具有您作为应用程序开发人员提供的名称（例如，通过使用@FeignClient批注）。根据需要，Spring Cloud通过使用RibbonClientConfiguration为每个命名客户端创建一个新的集合作为ApplicationContext。这包含（除其他外）ILoadBalancer，RestClient和ServerListFilter。 Ribbon与Spring Retry一起使用将Ribbon与Spring Retry一起使用时，可以通过配置某些功能区属性来控制重试功能。 client.ribbon.MaxAutoRetries 最大重试次数 client.ribbon.MaxAutoRetriesNextServer 下一个服务器重试次数 client.ribbon.OkToRetryOnAllOperations 重试所有操作包括post会缓存很多信息此外，您可能希望在响应中返回某些状态代码时重试请求。您可以通过设置clientName.ribbon.retryableStatusCodes属性列出您希望Ribbon客户端重试的响应代码123clientName: ribbon: retryableStatusCodes: 404,502 you can also create a bean of type LoadBalancedRetryPolicy and implement the retryableStatusCode method to retry a request given the status code.","categories":[{"name":"框架","slug":"框架","permalink":"https://vincentxin-scott.github.io/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://vincentxin-scott.github.io/tags/SpringCloud/"}]},{"title":"SpringCloud_Hystrix","slug":"SpringCloud/04｜Hystrix","date":"2019-06-13T15:00:56.700Z","updated":"2020-04-17T07:21:11.567Z","comments":true,"path":"2019/06/13/SpringCloud/04｜Hystrix/","link":"","permalink":"https://vincentxin-scott.github.io/2019/06/13/SpringCloud/04%EF%BD%9CHystrix/","excerpt":"","text":"定义：Circuit Breaker—Hystrix首先他实现的是断路器模式；较低级别的服务中的服务故障可能导致级联故障一直到用户。当对特定服务的调用超过circuitBreaker.requestVolumeThreshold（默认值：20个请求）且失败百分比大于circuitBreaker.errorThresholdPercentage（默认值：&gt; 50％）时circuit.rolllingStats.timeInMilliseconds定义的滚动窗口中的（默认值：10秒），通路断开，不再请求。在出现错误和开路的情况下，开发人员可以提供回退callback。","categories":[{"name":"框架","slug":"框架","permalink":"https://vincentxin-scott.github.io/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://vincentxin-scott.github.io/tags/SpringCloud/"}]},{"title":"SpringCloud_Eureka","slug":"SpringCloud/01｜Eureka","date":"2019-06-13T14:36:01.977Z","updated":"2020-04-17T07:20:38.386Z","comments":true,"path":"2019/06/13/SpringCloud/01｜Eureka/","link":"","permalink":"https://vincentxin-scott.github.io/2019/06/13/SpringCloud/01%EF%BD%9CEureka/","excerpt":"","text":"Why Is It so Slow to Register a Service?官方文档说明：实例注册到注册服务中心的时间很慢是因为，默认是持续30秒，在实例、服务端、客户端各自缓存相同的数据之前，客户端无法发现服务 （至少需要三次心跳才能达到要求） 12可以通过设置： eureka.instance.leaseRenewalIntervalInSeconds &#x3D; 10 设置它的时间小于30秒即可，但是在实际生产环境中，最好不要使用。因为eureka服务端会根据这个注册的时间来估算租约期限。 When to Prefer IP Address官方文档说明：在线上的时候最好使用IP代替主机名称注册，如果Java无法确定主机名称，将IP地址发给Eureka。 1eureka.instance.preferIpAddress &#x3D; true Securing The Eureka Server当我们在开发中使用spring-boot-starter-security的时候，它将要求在应用程序中的每个请求中发送有效的令牌，Eureka客户端通常不会拥有跨站点的伪造令牌，所以需要我们为/eureka/**端点禁用此要求。 123456789@EnableWebSecurityclass WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http.csrf().ignoringAntMatchers(&quot;&#x2F;eureka&#x2F;**&quot;); super.configure(http); &#125;&#125;","categories":[{"name":"框架","slug":"框架","permalink":"https://vincentxin-scott.github.io/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://vincentxin-scott.github.io/tags/SpringCloud/"}]},{"title":"SpringBoot多环境配置","slug":"SpringBoot/SpringBoot多环境配置","date":"2019-06-11T14:27:22.979Z","updated":"2019-12-11T06:53:10.085Z","comments":true,"path":"2019/06/11/SpringBoot/SpringBoot多环境配置/","link":"","permalink":"https://vincentxin-scott.github.io/2019/06/11/SpringBoot/SpringBoot%E5%A4%9A%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"","text":"profiles部分参考自：蚩尤后裔 profiles配置多环境需求分析：Profile 是 Spring 对不同环境提供不同配置功能的支持，可以通过激活、指定参数等方式快速切换环境；项目开发时有开发环境、测试环境、部署环境等，可以通过 profile 配置切换 多profile文件形式格式：application-{profile}.yml Spring Boot 默认都是从全局配置文件 application.properties 和 application.yml 进入开始读取 可以使用约定格式“application-{profile}.properties/yml”写任意多的配置文件 然后在全局配置文件 application.properties 和 application.yml 激活它们即可，使用“spring.profiles.active=xxx”123使用命令启动的话: java -jar eureka-study-1.0-SNAPSHOT.jar --spring.profiles.active&#x3D;eureka3 yml文档块形式 yml 文件支持多文档块方式，同一个yml文件中，可以使用”—“来区分不同的文档，相当于不同的配置文件 这也是Spring Boot官方推荐的方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263spring: profiles: active: eureka1---spring: application: name: spring-cloud-eureka profiles: eureka1server: port: 8000eureka: instance: hostname: eureka1 client: serviceUrl: defaultZone: http:&#x2F;&#x2F;eureka2:8001&#x2F;eureka&#x2F;,http:&#x2F;&#x2F;eureka3:8002&#x2F;eureka&#x2F;---spring: application: name: spring-cloud-eureka profiles: eureka2server: port: 8001eureka: instance: hostname: eureka2 client: serviceUrl: defaultZone: http:&#x2F;&#x2F;eureka1:8000&#x2F;eureka&#x2F;,http:&#x2F;&#x2F;eureka3:8002&#x2F;eureka&#x2F;---spring: application: name: spring-cloud-eureka profiles: eureka3server: port: 8002eureka: instance: hostname: eureka3 client: serviceUrl: defaultZone: http:&#x2F;&#x2F;eureka1:8000&#x2F;eureka&#x2F;,http:&#x2F;&#x2F;eureka2:8001&#x2F;eureka&#x2F;---spring: application: name: sinle-eureka cloud: config: enabled: false profiles: singleserver: port: 8761eureka: instance: hostname: localhost server: enable-self-preservation: false eviction-interval-timer-in-ms: 5000 # 设置注册表的清理间隔（默认是60 * 1000 毫秒）。单位：毫秒 client: fetch-registry: false register-with-eureka: false service-url: defalutZone: http:&#x2F;&#x2F;$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;&#x2F;eureka&#x2F; Maven配置多环境文件目录：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120&lt;!--定义不同环境--&gt; &lt;profiles&gt; &lt;!-- 对外服务层 --&gt; &lt;profile&gt; &lt;!-- 本地开发环境 --&gt; &lt;id&gt;external-dev&lt;&#x2F;id&gt; &lt;properties&gt; &lt;!-- 配置文件的路径 --&gt; &lt;profiles.active&gt;&#x2F;yml&#x2F;external&#x2F;dev&lt;&#x2F;profiles.active&gt; &lt;&#x2F;properties&gt; &lt;activation&gt; &lt;!--默认是本地开发环境 --&gt; &lt;activeByDefault&gt;true&lt;&#x2F;activeByDefault&gt; &lt;&#x2F;activation&gt; &lt;&#x2F;profile&gt; &lt;profile&gt; &lt;!-- 测试环境 --&gt; &lt;id&gt;external-test&lt;&#x2F;id&gt; &lt;properties&gt; &lt;profiles.active&gt;&#x2F;yml&#x2F;external&#x2F;test&lt;&#x2F;profiles.active&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;profile&gt; &lt;!-- 预发布 --&gt; &lt;id&gt;external-pre&lt;&#x2F;id&gt; &lt;properties&gt; &lt;profiles.active&gt;&#x2F;yml&#x2F;external&#x2F;pre&lt;&#x2F;profiles.active&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;profile&gt; &lt;!-- 生产环境 --&gt; &lt;id&gt;external-www&lt;&#x2F;id&gt; &lt;properties&gt; &lt;profiles.active&gt;&#x2F;yml&#x2F;external&#x2F;www&lt;&#x2F;profiles.active&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;!-- 对内服务层 --&gt; &lt;profile&gt; &lt;!-- 本地开发环境 --&gt; &lt;id&gt;internal-dev&lt;&#x2F;id&gt; &lt;properties&gt; &lt;profiles.active&gt;&#x2F;yml&#x2F;internal&#x2F;dev&lt;&#x2F;profiles.active&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;profile&gt; &lt;!-- 测试环境 --&gt; &lt;id&gt;internal-test&lt;&#x2F;id&gt; &lt;properties&gt; &lt;profiles.active&gt;&#x2F;yml&#x2F;internal&#x2F;test&lt;&#x2F;profiles.active&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;profile&gt; &lt;!-- 预发布 --&gt; &lt;id&gt;internal-pre&lt;&#x2F;id&gt; &lt;properties&gt; &lt;profiles.active&gt;&#x2F;yml&#x2F;internal&#x2F;pre&lt;&#x2F;profiles.active&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;profile&gt; &lt;!-- 生产环境 --&gt; &lt;id&gt;internal-www&lt;&#x2F;id&gt; &lt;properties&gt; &lt;profiles.active&gt;&#x2F;yml&#x2F;internal&#x2F;www&lt;&#x2F;profiles.active&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;!-- 管理员层 --&gt; &lt;profile&gt; &lt;!-- 本地开发环境 --&gt; &lt;id&gt;manage-dev&lt;&#x2F;id&gt; &lt;properties&gt; &lt;profiles.active&gt;&#x2F;yml&#x2F;manage&#x2F;dev&lt;&#x2F;profiles.active&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;profile&gt; &lt;!-- 测试环境 --&gt; &lt;id&gt;manage-test&lt;&#x2F;id&gt; &lt;properties&gt; &lt;profiles.active&gt;&#x2F;yml&#x2F;manage&#x2F;test&lt;&#x2F;profiles.active&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;profile&gt; &lt;!-- 预发布 --&gt; &lt;id&gt;manage-pre&lt;&#x2F;id&gt; &lt;properties&gt; &lt;profiles.active&gt;&#x2F;yml&#x2F;manage&#x2F;pre&lt;&#x2F;profiles.active&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;profile&gt; &lt;!-- 生产环境 --&gt; &lt;id&gt;manage-www&lt;&#x2F;id&gt; &lt;properties&gt; &lt;profiles.active&gt;&#x2F;yml&#x2F;manage&#x2F;www&lt;&#x2F;profiles.active&gt; &lt;&#x2F;properties&gt; &lt;&#x2F;profile&gt; &lt;&#x2F;profiles&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;!-- 该目录下与通配符匹配的文件将不会生成到classes目录下 --&gt; &lt;directory&gt;$&#123;basedir&#125;&#x2F;src&#x2F;main&#x2F;resources&lt;&#x2F;directory&gt; &lt;!-- 排除标签 --&gt; &lt;excludes&gt; &lt;!-- yml目录下的文件将不会生成到classes目录下，除非由filtering过滤动态添加的 --&gt; &lt;exclude&gt;yml&#x2F;**&lt;&#x2F;exclude&gt; &lt;&#x2F;excludes&gt; &lt;filtering&gt;true&lt;&#x2F;filtering&gt; &lt;&#x2F;resource&gt; &lt;resource&gt; &lt;!-- 资源文件位置src&#x2F;main&#x2F;resources&#x2F;,这下面的资源文件的$&#123;&#125;会全部被替换成filter中的标签内容。 directory指定的value会作为classes的资源根目录， --&gt; &lt;directory&gt;$&#123;basedir&#125;&#x2F;src&#x2F;main&#x2F;resources&#x2F;$&#123;profiles.active&#125;&lt;&#x2F;directory&gt; &lt;filtering&gt;true&lt;&#x2F;filtering&gt; &lt;&#x2F;resource&gt; &lt;&#x2F;resources&gt; &lt;&#x2F;build&gt; 在项目打包过程过程中直接使用命令或者直接在maven中打包即可。","categories":[{"name":"框架","slug":"框架","permalink":"https://vincentxin-scott.github.io/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://vincentxin-scott.github.io/tags/SpringBoot/"}]},{"title":"SpringCloud_Feign超时报错的处理","slug":"SpringCloud/05｜Feign超时报错的处理","date":"2019-06-11T07:43:15.442Z","updated":"2020-04-17T07:21:19.833Z","comments":true,"path":"2019/06/11/SpringCloud/05｜Feign超时报错的处理/","link":"","permalink":"https://vincentxin-scott.github.io/2019/06/11/SpringCloud/05%EF%BD%9CFeign%E8%B6%85%E6%97%B6%E6%8A%A5%E9%94%99%E7%9A%84%E5%A4%84%E7%90%86/","excerpt":"","text":"","categories":[{"name":"框架","slug":"框架","permalink":"https://vincentxin-scott.github.io/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://vincentxin-scott.github.io/tags/SpringCloud/"}]},{"title":"SpringBoot中加载加密证书报错处理","slug":"杂记随笔/SpringBoot中加载加密证书报错处理","date":"2019-06-04T15:42:28.809Z","updated":"2019-12-11T06:43:00.461Z","comments":true,"path":"2019/06/04/杂记随笔/SpringBoot中加载加密证书报错处理/","link":"","permalink":"https://vincentxin-scott.github.io/2019/06/04/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/SpringBoot%E4%B8%AD%E5%8A%A0%E8%BD%BD%E5%8A%A0%E5%AF%86%E8%AF%81%E4%B9%A6%E6%8A%A5%E9%94%99%E5%A4%84%E7%90%86/","excerpt":"","text":"发生背景开发深证银盛支付接口，需要用到公钥和私钥，密钥文件统一放在src/main/resources/key的某个目录下。在本地测试过程中出现： 12报错：DerInputStream.getLength(): lengthTag&#x3D;111, too big. 错误定位通过本地debug发现，在证书加载过程中出现这个问题，但是路径以及密钥都没有问题，于是在网上寻找解决方案，得出的为问题原因可能有两种。 原因1: 由于路径过长导致文件加载错误。（显然不是这个原因） 原因2: 由于maven在编译过程中修改了文件，导致文件失效，故而出现加载错误。 为了证实这种情况，我把maven打好的war中的证书文件替换掉，果然是这个原因。那证书为什么会被修改呢，原来就是maven-resources-plugin作怪。 解决方案123456789101112&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;!-- 过滤后缀为cer、pfx的证书文件 --&gt; &lt;nonFilteredFileExtensions&gt; &lt;nonFilteredFileExtension&gt;cer&lt;/nonFilteredFileExtension&gt; &lt;nonFilteredFileExtension&gt;pfx&lt;/nonFilteredFileExtension&gt; &lt;/nonFilteredFileExtensions&gt; &lt;/configuration&gt; &lt;/plugin&gt;","categories":[{"name":"杂记随笔","slug":"杂记随笔","permalink":"https://vincentxin-scott.github.io/categories/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"解决问题","slug":"解决问题","permalink":"https://vincentxin-scott.github.io/tags/%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/"}]},{"title":"微信支付","slug":"第三方支付/微信支付","date":"2019-05-29T00:28:33.239Z","updated":"2019-12-11T06:43:09.796Z","comments":true,"path":"2019/05/29/第三方支付/微信支付/","link":"","permalink":"https://vincentxin-scott.github.io/2019/05/29/%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98/","excerpt":"","text":"支付模式 1、付款码支付付款码支付是用户展示微信钱包内的“刷卡条码/二维码”给商户系统扫描后直接完成支付的模式。主要应用线下面对面收银的场景。 2、Native支付Native支付是商户系统按微信支付协议生成支付二维码，用户再用微信“扫一扫”完成支付的模式。该模式适用于PC网站支付、实体店单品或订单支付、媒体广告支付等场景。 3、JSAPI支付JSAPI支付是用户在微信中打开商户的H5页面，商户在H5页面通过调用微信支付提供的JSAPI接口调起微信支付模块完成支付。应用场景有： 用户在微信公众账号内进入商家公众号，打开某个主页面，完成支付 用户的好友在朋友圈、聊天窗口等分享商家页面连接，用户点击链接打开商家页面，完成支付 将商户页面转换成二维码，用户扫描二维码后在微信浏览器中打开页面后完成支付 4、APP支付APP支付又称移动端支付，是商户通过在移动端应用APP中集成开放SDK调起微信支付模块完成支付的模式。 5、H5支付H5支付主要是在手机、ipad等移动设备中通过浏览器来唤起微信支付的支付产品。 6、小程序支付小程序支付是专门被定义使用在小程序中的支付产品。目前在小程序中能且只能使用小程序支付的方式来唤起微信支付。","categories":[{"name":"第三方支付","slug":"第三方支付","permalink":"https://vincentxin-scott.github.io/categories/%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98/"}],"tags":[{"name":"微信支付","slug":"微信支付","permalink":"https://vincentxin-scott.github.io/tags/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98/"}]},{"title":"Transactional事务失效自检流程","slug":"Java/@Transactional事务失效自检流程","date":"2019-05-14T08:54:17.720Z","updated":"2020-06-03T02:02:08.840Z","comments":true,"path":"2019/05/14/Java/@Transactional事务失效自检流程/","link":"","permalink":"https://vincentxin-scott.github.io/2019/05/14/Java/@Transactional%E4%BA%8B%E5%8A%A1%E5%A4%B1%E6%95%88%E8%87%AA%E6%A3%80%E6%B5%81%E7%A8%8B/","excerpt":"","text":"Mysql数据库引擎需为InnnoDB，MyIsam不支持事务 @Transactional所注解的方法是否为public @Transactional所注解方法所在的类，需被Spring容器所管理，换句话说所注解方法所在的类需要被@Service、@Component所注解 需要调用该方法，且需要支持事务特性的调用方是在在 @Transactional所在的类的外面。注意：类内部的其他方法调用这个注解了@Transactional的方法，事务是不会起作用的。 注解为事务范围的方法中，事务的回滚仅仅对于unchecked的异常有效。对于checked异常无效。也就是说事务回滚仅仅发生在出现RuntimeException或Error的时候。如果希望一般的异常也能触发事务回滚，需要在注解了@Transactional的方法上，将@Transactional回滚参数设为：@Transactional(rollbackFor=Exception.class) try catch 相关语句可能会在事务之前捕捉异常，需要： 12345678910@Transactional(rollbackFor = Exception.class)public Integer compute(ProductInfo p)&#123; try&#123;...&#125;catch(Exception e)&#123;e.printStackTrace();TransactionAspectSupport.currentTransactionStatus().setRollbackOnly();return 0;&#125;&#125; Spring 的传播行为123456789 public enum Propagation &#123; REQUIRED(0), SUPPORTS(1), MANDATORY(2), REQUIRES_NEW(3), NOT_SUPPORTED(4), NEVER(5), NESTED(6); &#125;","categories":[{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"事务","slug":"事务","permalink":"https://vincentxin-scott.github.io/tags/%E4%BA%8B%E5%8A%A1/"}]},{"title":"Spring官方文档阅读(一)--Spring框架概述(Spring Framework Overview)","slug":"Spring官方文档/Spring框架概述","date":"2019-04-17T06:43:13.359Z","updated":"2019-06-13T14:56:43.426Z","comments":true,"path":"2019/04/17/Spring官方文档/Spring框架概述/","link":"","permalink":"https://vincentxin-scott.github.io/2019/04/17/Spring%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/Spring%E6%A1%86%E6%9E%B6%E6%A6%82%E8%BF%B0/","excerpt":"","text":"–官方文档地址Overview 在知乎上看到很多看Spring源码方法的帖子，最后看到一个醍醐灌顶的帖子怎么阅读Spring源码？。原文有这样一句问题 我想先问一下题主和有些答主，spring.io上的文档你们都读了几遍了？所有项目的文档读不过来没事，Spring Framework这个项目的reference有完整从头到尾读一遍吗？然后再来问怎么阅读Spring源代码，或者回答人家如何阅读Spring源码。 1：先看官方文档。好的技术和框架，官方文档一定全面丰富详实，JHipster就是这样，Spring.io更是好文档的典范。所以先把官方文档过一遍，理解的就理解，不理解的要记住在文档的哪一节。 2：开始实践！有些知识只有实践的过程中才能理解，并且加深认识。遇到问题，知道这个问题对应文档的哪一部分，然后去查文档。 3：做完一两个实际项目之后，返回去再读一遍文档，这时你会发现自己站在一个新高度上。 4：1/2/3部分循环。每一次循环，你都站在一个新的高度。 Spring makes it easy to create Java enterprise applications. It provides everything you need to embrace the Java language in an enterprise environment, with support for Groovy and Kotlin as alternative languages on the JVM, and with the flexibility to create many kinds of architectures depending on an application’s needs. As of Spring Framework 5.1, Spring requires JDK 8+ (Java SE 8+) and provides out-of-the-box support for JDK 11 LTS. Spring 可以轻松创建Java企业应用程序。Spring提供了在企业环境中使用Java语言所需要的一切，支持Groovy和Kotlin作为JVM的替代语言，并且可以根据用于程序的需要灵活的创建多种体系结构。","categories":[{"name":"Spring官方文档","slug":"Spring官方文档","permalink":"https://vincentxin-scott.github.io/categories/Spring%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/"}],"tags":[{"name":"Spring文档","slug":"Spring文档","permalink":"https://vincentxin-scott.github.io/tags/Spring%E6%96%87%E6%A1%A3/"}]},{"title":"设计模式(二)---面向对象设计原则","slug":"设计模式/03｜面向对象设计原则","date":"2019-04-16T15:47:16.363Z","updated":"2020-01-30T15:26:23.824Z","comments":true,"path":"2019/04/16/设计模式/03｜面向对象设计原则/","link":"","permalink":"https://vincentxin-scott.github.io/2019/04/16/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/03%EF%BD%9C%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/","excerpt":"","text":"","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://vincentxin-scott.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://vincentxin-scott.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"PlantUML学习","slug":"设计模式/02｜PlantUML学习","date":"2019-04-13T11:49:30.456Z","updated":"2020-01-30T15:26:17.706Z","comments":true,"path":"2019/04/13/设计模式/02｜PlantUML学习/","link":"","permalink":"https://vincentxin-scott.github.io/2019/04/13/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/02%EF%BD%9CPlantUML%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"PlantUML 语法及使用教学详情参考官网详细教学PlantUML","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://vincentxin-scott.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://vincentxin-scott.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"mac启动SpringBoot项目的等待时间长问题解决","slug":"Mac/mac启动SpringBoot项目等待时间长","date":"2019-04-09T03:02:00.109Z","updated":"2019-12-11T06:42:37.347Z","comments":true,"path":"2019/04/09/Mac/mac启动SpringBoot项目等待时间长/","link":"","permalink":"https://vincentxin-scott.github.io/2019/04/09/Mac/mac%E5%90%AF%E5%8A%A8SpringBoot%E9%A1%B9%E7%9B%AE%E7%AD%89%E5%BE%85%E6%97%B6%E9%97%B4%E9%95%BF/","excerpt":"","text":"mac启动SpringBoot项目的等待时间长问题解决发生背景JDK: 123java version &quot;1.8.0_181&quot;Java(TM) SE Runtime Environment (build 1.8.0_181-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode) Mac: 项目启动时会等待将近一分钟才会出现日志信息，需要等待很久。 解决方法is_Min参考学习。 需要修改hosts修改，把localhost的解析继续添加mac本地的名称.local mac本地名称获取 打开偏好设置 找到共享图标点击进入 复制内容到hosts hosts 修改推荐使用SwitchHosts，好用的的飞起。到此，再次启动项目简直快的飞起。","categories":[{"name":"Mac","slug":"Mac","permalink":"https://vincentxin-scott.github.io/categories/Mac/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://vincentxin-scott.github.io/tags/mac/"}]},{"title":"设计模式(一)---统一建模语言基础","slug":"设计模式/01｜统一建模语言基础","date":"2019-04-08T13:37:33.930Z","updated":"2020-01-30T15:25:44.655Z","comments":true,"path":"2019/04/08/设计模式/01｜统一建模语言基础/","link":"","permalink":"https://vincentxin-scott.github.io/2019/04/08/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/01%EF%BD%9C%E7%BB%9F%E4%B8%80%E5%BB%BA%E6%A8%A1%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/","excerpt":"","text":"统一建模语言基础知识统一建模语言（Unified Modeling Language，UML）是一种可视化的标准建模语言，他是一种分析和设计语言，通过UML可以构造软件系统的蓝图。 在设计模式中，需要使用UML来分析和设计每一个模式的结构，描述每一个模式实例，并对部分模式进行深入的解析。因此，在学习设计模式之前，需要先学习一些基本的UML知识。 UML介绍UML已经成为面向对象软件分析与设计建模的标准，其应用越来越广泛，在学习设计模式之前需要掌握一些基本的UML知识，以便于理解每个模式和模式实例的结构，并通过一些UML图形来加深对设计模式的理解。 UML结构UML是由图形符号表达的建模语言。其结构见下图 UML特点 工程化 规范化 可视化 系统化 文档化 智能化 类图类图是使用频率最高的UML图之一。 类与类图 类是一组具有相同属性、表现相同行为的对象的抽象 类图用来描述不同类以及它们之间的关系类之间的关系 关联关系(Association) 是类与类之间最常见的一种关系，它是一种结构化关系，用于表示一类对象与另一类对象之间的联系。在UML类图中，用实线连接有关联的对象对应的类 (1)双向关联 (2)单向关联 (3)自关联 (4)多重性关联 (5)聚合关系 (6)组合关系 依赖关系(Dependency) 是一种使用关系，特定事物的改变有可能会影响到使用该事物的其他事物，在需要表示一个事物使用另外一个事物时使用依赖关系。 大多数情况下，依赖关系体现在某一类的方法使用另一个类的对象作为参数。==在UML类图中，依赖关系用带箭头的虚线表示，由依赖一方指向被依赖一方。== 泛化关系(Generalization) 也就是继承关系，泛化关系用于描述父类与子类之间的关系，父类又称作基类或超类，子类被称作派生类。 ==在UML类图中，泛化关系用带空心三角形的直线来表示。指向父类== 接口与实现关系 ==在UML类图中，类与接口之间的实现关系用带空心三角形的虚线来表示。指向接口== 类图实例 附加plantUML代码 12345678910111213141516171819202122232425262728@startumlClass RegisterForm&#123; - user:UserDTO - userDao:IUserDAO&#125;interface IUserDAO&#123; + addUser(UserDTO usder):boolean&#125;Class OracleUserDAO&#123; + addUser(UserDTO usder):boolean&#125;Class UserDTO&#123; - userAccount:String - userPassword:String + getUserAccount():String + setUserAccount():void + getUserPassword():String + setUserPassword():void&#125;RegisterForm *--&gt; UserDTO :组合关系RegisterForm o..&gt; IUserDAO :聚合关系IUserDAO ..&gt; UserDTO : 依赖关系IUserDAO &lt;|.. OracleUserDAO : 实现关系@enduml 在RegisterForm中可以直接实例话UserDTO，因此他们之间可以使用组合关联 在RegisterForm中不能直接实例话IUserDAO的子类，可以针对接口编程，在通过注入的方式传入一个IUserDao接口的子类对象，因此RegisterForm和IUserDAO之间有聚合关系 顺序图顺序图是最常用的系统动态建模工具之一，也是使用频率最高的交互图，他用于表示对象之间的动态交互，而且以图形化的方式描述了对象间消息传递的时间顺序。在设计模式中，我们将使用顺序图来描述某些模式中对象之间的交互关系 顺序图定义顺序图(Sequence Diagram)是一种强调对象消息传递次序的交互图，又称为时序图或序列图 顺序图组成元素与绘画在UML中，顺序图将交互关系表示为一个二维图，纵向是时间轴，时间沿竖线向下延伸；横向轴表示了在交互过程中的独立对象，对象的活动用生命线表示。顺序图由执行者(Actor)、生命线(Lifeline)、对象(Object)、激活框(Activation)和消息(Message)等元素组成。 顺序图实例TODO 状态图对于系统中哪些有多种状态的对象，状态图是一种常用的建模手段。状态图用于描述对象的各种状态以及状态之间的转换。在设计模式中，将使用状态图来描述某些模式中对象的状态及状态间和转换。 状态图定义状态图(Statechart Diagram)用来描述一个特定对象的所有可能状态及其引起状态转移的事件。只有那些有重要交互行为的类，我们才会使用状态图来描述，一个状态图包括一系列的状态及状态之间的转移。 状态图组成元素与绘制在UML中，包含如下组成元素： 状态(State):又称中间状态，用圆角矩形框表示，在一个状态图中可有多个状态。 初始状态(Initial State):由称为初态，用一个黑色的实心圆圈表示，在一个状态图中只能有一个 结束状态(Final State):又称为终止状态或终态，用一个实心圆外加圆圈表示。 转移(Transition):用从一个状态到另一个状态之间的连线和箭头说明状态的转移情况。状态图实例 TODO","categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://vincentxin-scott.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://vincentxin-scott.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"多线程学习（三）线程池","slug":"Java/Java多线程学习（三）线程池","date":"2019-03-17T14:37:56.414Z","updated":"2019-12-11T06:44:20.085Z","comments":true,"path":"2019/03/17/Java/Java多线程学习（三）线程池/","link":"","permalink":"https://vincentxin-scott.github.io/2019/03/17/Java/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%89%EF%BC%89%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"","text":"参考学习于作者：Matrix海子 Java中的ThreadPoolExecutor类深入剖析线程池实现原理使用示例如何合理配置线程池的大小","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://vincentxin-scott.github.io/categories/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://vincentxin-scott.github.io/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"多线程学习（二）线程同步","slug":"Java/Java多线程学习（二）线程的同步","date":"2019-03-17T13:42:40.082Z","updated":"2019-12-11T06:44:04.610Z","comments":true,"path":"2019/03/17/Java/Java多线程学习（二）线程的同步/","link":"","permalink":"https://vincentxin-scott.github.io/2019/03/17/Java/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%BA%8C%EF%BC%89%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%90%8C%E6%AD%A5/","excerpt":"","text":"线程同步的方法 究竟什么是线程同步？ 所谓同步，就是在发生一个方法的调用时，在没有结果之前，这个调用就不返回，同时其他线程也不能调用这个方法。线程同步不是说让一个线程执行完了再执行其他线程，一般是指让线程中某一些操作进行同步就可以了。 同步方法同步代码块使用重入锁实现线程同步volatile 关键字使用局部变量实现线程同步","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://vincentxin-scott.github.io/categories/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://vincentxin-scott.github.io/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"多线程学习（一）基础线程入门","slug":"Java/Java多线程学习（一）基础线程了解","date":"2019-03-15T12:44:27.497Z","updated":"2020-06-03T02:02:10.859Z","comments":true,"path":"2019/03/15/Java/Java多线程学习（一）基础线程了解/","link":"","permalink":"https://vincentxin-scott.github.io/2019/03/15/Java/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%E5%9F%BA%E7%A1%80%E7%BA%BF%E7%A8%8B%E4%BA%86%E8%A7%A3/","excerpt":"","text":"基础概念什么是进程？一个进程对应一个应用程序。例如：在 windows 操作系统启动 Word 就表示启动了一个进程。在java的开发环境下启动JVM，就表示启动了一个进程。现代的计算机都是支持多进程的，在同一个操作系统中，可以同时启动多个进程。对于操作系统来说，一个任务就是一个进程（Process），比如打开一个浏览器就是启动一个浏览器进程，打开一个记事本就启动了一个记事本进程，打开两个记事本就启动了两个记事本进程，打开一个Word就启动了一个Word进程。有些进程还不止同时干一件事，比如Word，它可以同时进行打字、拼写检查、打印等事情。在一个进程内部，要同时干多件事，就需要同时运行多个“子任务”，我们把进程内的这些“子任务”称为线程（Thread）。 进程是操作系统进行资源分配的单位,进程是计算机系统分配资源的最小单位。每个进程都有自己的一部分独立的系统资源，彼此是隔离的。进程(英语：Process)是计算机中已运行程序的实体。进程本身不会运行，是线程的容器。程序本身只是指令的集合，进程才是程序(那些指令)的真正运行。若干进程有可能与同一个程序相关系，且每个进程皆可以同步(循序)或不同步(平行)的方式独立运行。进程为现今分时系统的基本运作单位。 什么是线程？线程指进程中的一个执行场景，也就是执行流程。同一个进程中的线程共享其进程中的内存和资源（共享的内存是堆内存和方法区内存，栈内存不共享，每个线程有自己的。） 线程(英语：thread)，操作系统技术中的术语，是操作系统能够进行运算调度的最小单位。它被包涵在进程之中，一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。在Unix System V及SunOS中也被称为轻量进程(lightweight processes)，但轻量进程更多指内核线程(kernel thread)，而把用户线程(user thread)称为线程。 多线程的作用多线程是为了同步完成多项任务，不是为了提高运行效率，而是为了提高资源使用效率来提高系统的效率。线程是在同一时间需要完成多项任务的时候实现的。 反应“多角色”的程序代码，最起码每个角色要给他一个线程吧，否则连实际场景都无法模拟，当然也没法说能用单线程来实现：比如最常见的“生产者，消费者模型”。 并行与并发 并行：多个cpu实例或者多台机器同时执行一段处理逻辑，是真正的同时。 并发：通过cpu调度算法，让用户看上去同时执行，实际上从cpu操作层面不是真正的同时。并发往往在场景中有公用的资源，那么针对这个公用的资源往往产生瓶颈，我们会用TPS(Transactions Per Second（每秒传输的事物处理个数))或者QPS(每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准)来反应这个系统的处理能力。 总线程数&lt;= CPU数量：并行运行总线程数&gt; CPU数量：并发运行 什么是线程安全？指在并发的情况之下，该代码经过多线程使用，线程的调度顺序不影响任何结果。 线程不安全的原因：多个线程访问了相同的资源，同一内存区（变量，数组，或对象）、系统（数据库，web services等）或文件，并发生写操作。竞态条件 &amp; 临界区当两个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在竞态条件。导致竞态条件发生的代码区称作临界区。共享资源允许被多个线程同时执行的代码称作线程安全的代码。线程安全的代码不包含竞态条件。当多个线程同时更新共享资源时会引发竞态条件。因此，了解Java线程执行时共享了什么资源很重要。什么是线程同步？保证多线程共享资源但是对资源的操作先后执行。线程的创建 此部分内容参考至sunddenly 通过继承Thread类来创建并启动多线程的方式 通过实现Runable接口来创建并启动多线程的方式 通过实现Callable接口来创建并启动线程的方式继承Thread类来创建线程类Java使用Thread类代表线程，所有的线程对象都必须是Thread类或其子类的实例。每个线程的作用是完成一定的任务，实际上就是执行一段程序流即一段顺序执行的代码。Java使用线程执行体来代表这段程序流。Java中通过继承Thread类来创建并启动多线程的步骤如下： 定义Thread类的子类，并重写该类的run()方法，该run()方法的方法体就代表了线程需要完成的任务因此把run()方法称为线程执行体； 创建Thread子类的实例，即创建了线程对象； 调用线程对象的start()方法来启动该线程12345678910111213141516171819 public class ExtendsThreadDemo &#123; public static void main(String[] args) &#123; for (int i&#x3D;0;i&lt;300;i++)&#123; System.out.println(&quot;打游戏&quot;+i); if(i&#x3D;&#x3D;10)&#123; MusicThread t &#x3D;new MusicThread(); t.start(); &#125; &#125; &#125;&#125;class MusicThread extends java.lang.Thread&#123; @Override public void run()&#123; for(int i&#x3D;0;i&lt;300;i++)&#123; System.out.println(&quot;播放音乐&quot;+i); &#125; &#125;&#125; 实现Runnable接口创建线程类实现Runnable接口来创建并启动多线程的步骤如下： 定义Runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体 创建Runnable实现类的实例，并以此实例作为Thread的target来创建Thread对象，该Thread对象才是真正的线程对象 调用线程对象的start()方法来启动线程1234567891011121314151617181920212223public class ImplementRunnableDemo &#123; public static void main(String[] args) &#123; for (int i &#x3D; 0; i &lt; 100; i++) &#123; System.out.println(Thread.currentThread().getName()+&quot;--打游戏&quot; + i); if (i &#x3D;&#x3D; 1) &#123; Runnable target &#x3D; new MusicRunnableImpl(); Thread t &#x3D; new Thread(target,&quot;线程1&quot;); t.start(); Thread t1 &#x3D; new Thread(target,&quot;线程2&quot;); t1.start(); &#125; &#125; &#125;&#125;class MusicRunnableImpl implements java.lang.Runnable&#123; @Override public void run() &#123; for(int i&#x3D;0;i&lt;100;i++)&#123; System.out.println(Thread.currentThread().getName()+&quot;--播放音乐&quot;+i); &#125; &#125;&#125; 在这种方式下，程序所创建的Runnable对象只是线程的target，而多个线程可以共享同一个target。2. 所以多个线程可以共享同一个线程类即线程的target类的实例属性. 这个时候target的全局变量会受到线程资源抢夺的问题。 123456789101112131415161718192021222324252627282930public class ImplementRunnableDemo &#123; public static void main(String[] args) &#123; for (int i &#x3D; 0; i &lt; 100; i++) &#123; System.out.println(Thread.currentThread().getName()+&quot;--打游戏&quot; + i); if (i &#x3D;&#x3D; 1) &#123; Runnable target &#x3D; new MusicRunnableImpl(); Thread t &#x3D; new Thread(target,&quot;线程1&quot;); t.start(); Thread t1 &#x3D; new Thread(target,&quot;线程2&quot;); t1.start(); &#125; &#125; System.out.println(&quot;主线程结束&quot;); &#125;&#125;class MusicRunnableImpl implements java.lang.Runnable&#123; private int i&#x3D;0; void print()&#123; System.out.println(Thread.currentThread().getName()+&quot;--i--&quot;+(i)); &#125; @Override public void run() &#123; for(;i&lt;500;i++)&#123; System.out.println(Thread.currentThread().getName()+&quot;--播放音乐&quot;+i); print(); &#125; &#125;&#125; 使用Callable和Future创建线程Callable和Future接口概述从Java 5开始，Java提供了Callable接口，该接口怎么看都像是Runnable接口的增强版，Callable接口提供了一个call()方法可以作为线程执行体，但call()方法比run()方法功能更强大。 call()方法可以有返回值； call()方法可以声明抛出异常； 因此我们完全可以提供一个Callable对象作为Thread的target，而该线程的线程执行体就是该Callable对象的call()方法。问题是：Callable接口是Java 5新增的接口，而且它不是Runnable接口的子接口，所以Callable对象不能直接作为Thread的target。而且call()方法还有一 个返回值—–call()方法并不是直接调用，它是作为线程执行体被调用的。那么如何获取call()方法的返回值呢？ Java 5提供了Future接口来代表Callable接口里call()方法的返回值，并为Future接口提供了一个FutureTask实现类，该实现类实现了Future接口和Runnable接口可以作为Thread类的target。在Future接口里定义了如下几个公共方法来控制它关联的Callable任务： boolcan cancel(boolean maylnterruptltRunning)：试图取消该Future里关联的Callable任务 V get()：返回Callable任务里call()方法的返回值。调用该方法将导致程序阻塞，必须等到子线程结束后才会得到返回值 V get(long timeout，TimeUnit unit)：返回Callable任务里call()方法的返回值。该方法让程序最多阻塞timeout和unit指定的时间，如果经过指定时间后Callable任务依然没有返回值，将会抛出TimeoutExccption异常 boolean isCancelled()：如果在Callable任务正常完成前被取消，则返回true boolean isDone()：妇果Callable任务已完成，则返回true 注意：Callable接口有泛型限制，Callable接口里的泛型形参类型与call()方法返回值类型相同。 创建并启动有返回值的线程的步骤： 创建Callable接口的实现类，并实现call()方法，该call()方法将作为线程执行体，且该call()方法有返回值 创建Callable实现类的实例，使用FutureTask类来包装Callable对象该FutureTask对象封装了该Callable对象的call()方法的返回值 使用FutureTask对象作为Thread对象的target创建并启动新线程 调用FutureTask对象的get()方法来获得子线程执行结束后的返回值 123456789101112131415161718192021222324252627282930313233public class ImplementCallableDemo implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; int i &#x3D; 0; for ( ; i &lt; 100 ; i++ )&#123; System.out.println(Thread.currentThread().getName()+ &quot;--i--&quot; + i); &#125; &#x2F;&#x2F; call()方法可以有返回值 return i; &#125; public static void main(String[] args) &#123; &#x2F;&#x2F;创建callable对象 ImplementCallableDemo callableDemo&#x3D;new ImplementCallableDemo(); &#x2F;&#x2F;使用FutureTask来包装Callable对象 FutureTask&lt;Integer&gt; task &#x3D; new FutureTask&lt;Integer&gt;(callableDemo); for (int i&#x3D;0;i&lt;100;i++)&#123; System.out.println(Thread.currentThread().getName()+&quot;\\t&quot;+i); if (i&#x3D;&#x3D;1)&#123; new Thread(task,&quot;callable&quot;).start(); &#125; &#125; try&#123; &#x2F;&#x2F; 获取线程返回值 System.out.println(&quot;callable返回值：&quot; + task.get()); &#125; catch (Exception ex)&#123; ex.printStackTrace(); &#125; &#125;&#125; (1) 采用实现Runnable、Callable接口的方式创建多线程线程类只是实现了Runnable接口或Callable接口，还可以继承其他类。在这种方式下，多个线程可以共享同一个target对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将CPU、代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。劣势：编程稍稍复杂，如果需要访问当前线程，则必须使用Thread.currentThread()方法。(2) 采用继承Thread类的方式创建多线程劣势：因为线程类已经继承了Thread类，所以不能再继承其他父类 线程的生命周期 新建状态：采用new语句创建完成 就绪状态：执行start之后，进入就绪状态（就是有权去获取CPU的运行时间，可以被JVM调度） 运行状态：在被JVM调度，获取CPU运行时间，执行run方法。此时是运行状态 阻塞状态：执行了wait语句、执行了sleep语句和等待某个对象锁，等待输入的场合。 消亡状态：run 方法执行完。 （来源于知乎作者：泥瓦匠） 123456789101112131415161718192021222324252627282930public enum State &#123; &#x2F;** * 创建了线程，但是还没有启动 *&#x2F; NEW, &#x2F;** * 这个状态包含了线程在JVM中执行或则在等待争抢执行的权利 *&#x2F; RUNNABLE, &#x2F;** * 线程的这个状态表示阻塞状态，等待获取一个监视器锁进入到同步方法或同步代码块，或者等待方法返回后重新获取。 *&#x2F; BLOCKED, &#x2F;** *表示线程处于无限制等待状态，等待一个特殊的事件来重新唤醒， *如通过wait()方法进行等待的线程等待一个notify()或者notifyAll()方法， *通过join()方法进行等待的线程等待目标线程运行结束而唤 *&#x2F; WAITING, &#x2F;** *表示线程进入了一个有时限的等待，如sleep(3000)，等待3秒后线程重新进行RUNNABLE状态继续运行。或者join(3000),等待线程的加入，等待一定时间。 *&#x2F; TIMED_WAITING, &#x2F;** * 表示线程执行完毕后，进行终止状态。 *需要注意的是，一旦线程通过start方法启动后就再也不能回到初始NEW状态，线程终止后也不能再回到RUNNABLE状态。 *&#x2F; TERMINATED;&#125; 线程阻塞： 线程调用sleep()方法主动放弃所占用的处理器资源 线程调用了一个阻塞式IO方法，在该方法返回之前，该线程被阻塞 线程试图获得一个同步监视器，但该同步监视器正被其他线程所持有。 线程在等待某个通知（notify） 当前正在执行的线程被阻塞之后，其他线程就可以获得执行的机会。被阻塞的线程会在合适的时候重新进入就绪状态，注意是就绪状态而不是运行状态。也就是说，被阻塞线程的阻塞解除后，必须重新等待线程调度器再次调度它。解除阻塞： 用sleep()方法的线程经过了指定时间。 线程调用的阻塞式IO方法已经返回。 线程成功地获得了试图取得的同步监视器。 线程正在等待某个通知时，其他线程发出了个通知。 线程调度与控制线程的调度模型分为: 分时调度模型和抢占式调度模型,Java使用抢占式调度模型 分时调度模型：所有线程轮流使用 CPU 的使用权，平均分配每个线程占用 CPU 的时间片 抢占式调度模型：优先让优先级高的线程使用 CPU，如果线程的优先级相同，那么会随机选择一个，优先级高的线程获取的 CPU 时间片相对多一些。 线程的joinThread提供了让一个线程等待另一个线程完成的方法join()方法。当在某个程序执行流中调用其他线程的join()方法时，调用线程将被阻塞，直到被join()方法加入的join线程执行完为止。join()方法通常由使用线程的程序调用，以将大问题划分成许多小问题，每个小问题分配一个线程。当所有的小问题都得到处理后，再调用主线程来进一步操作。 后台线程有一种线程，它是在后台运行的，它的任务是为其他的线程提供服务，这种线程被称为后台线程（Daemon Thread），又称为守护线程或精灵线程。JVM的垃圾回收线程就是典型的后台线程。后台线程有个特征：如果所有的前台线程都死亡，后台线程会自动死亡。 调用Thread对象的setDaemon(true)方法可将指定线程设置成后台线程。下面程序将执行线程设置成后台线程，可以看到当所有的前台线程死亡时，后台线程随之死亡。当整个虚拟机中只剩下后台线程时，程序就没有继续运行的必要了，所以虚拟机也就退出了。 线程睡眠 sleep如果需要让当前正在执行的线程暂停一段时，并进入阻塞状态，则可以通过调用Thread类的静态sleep()方法来实现。当当前线程调用sleep()方法进入阻塞状态后，在其睡眠时间段内，该线程不会获得执行的机会，即使系统中没有其他可执行的线程，处于sleep()中的线程也不会执行，因此sleep()方法常用来暂停程序的执行。 线程让步 yieldyield()方法是一个和sleep()方法有点相似的方法，它也是Threard类提供的一个静态方法，它也可以让当前正在执行的线程暂停，但它不会阻塞该线程，它只是将该线程转入就绪状态。yield()只是让当前线程暂停一下，让系统的线程调度器重新调度一次，完全可能的情况是：当某个线程调用了yield()方法暂停之后，线程调度器又将其调度出来重新执行。 关于sleep()方法和yield()方法的区别如下： sleep()方法暂停当前线程后，会给其他线程执行机会，不会理会其他线程的优先级；但yield()方法只会给优先级相同，或优先级更高的线程执行机会 sleep()方法会将线程转入阻塞状态，直到经过阻塞时间才会转入就绪状态：而yield()不会将线程转入阻塞状态，它只是强制当前线程进入就绪状态。因此完全有可能某个线程调用yield()方法暂停之后，立即再次获得处理器资源被执行 sleep()方法声明抛出了InterruptcdException异常，所以调用sleep()方法时要么捕捉该异常，要么显式声明抛出该异常；而yield()方法则没有声明抛出任何异常 sleep()方法比yield()方法有更好的可移植性，通常不建议使用yield()方法来控制并发线程的执行 线程的优先级线 程 优 先 级 主 要 分 三 种 ： MAX_PRIORITY( 最 高 级 ); MIN_PRIORITY （ 最 低 级 ） NORM_PRIORITY(标准)默认","categories":[{"name":"Java基础","slug":"Java基础","permalink":"https://vincentxin-scott.github.io/categories/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"线程","slug":"线程","permalink":"https://vincentxin-scott.github.io/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"我的Hexo博客搭建","slug":"杂记随笔/我的Hexo博客搭建","date":"2019-03-15T10:28:25.245Z","updated":"2019-12-11T06:43:04.874Z","comments":true,"path":"2019/03/15/杂记随笔/我的Hexo博客搭建/","link":"","permalink":"https://vincentxin-scott.github.io/2019/03/15/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/%E6%88%91%E7%9A%84Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","excerpt":"","text":"下载初始化Hexo博客框架第一步，万事开头看官网 Hexo!什么也不说就是直接整。直接执行首页的代码(默认大家git和Node.js已经安装哈，有问题看文档)。 12345npm install hexo-cli -ghexo init blogcd blognpm installhexo server 这个时候你已经可以看到你的博客页面了，通过文档的阅读修改 _config.yml来配置自己的博客名称，绝对地址等等。但是你以为这样就结束了吗。这个时候我们需要骚起来，这样千篇一律的样式怎么能满足我呢。于是开始找各式各样的主题（github可找到很多直接搜索 hexo theme 全站搜索）。 选择优秀的主题（打造自己的博客） 这里首先感谢cofess贡献的美腻主题。 安装主题 首先进入到你安装的Hexo文件的themes文件目录之下。 直接在当前页面下执行一下代码1git clone https:&#x2F;&#x2F;github.com&#x2F;cofess&#x2F;hexo-theme-pure.git themes&#x2F;pure 执行完之后可以看到一个名字为 pure的文件夹。 修改Hexo博客框架中的主要配置文件启用主题（config.yml） 在左图中的文件中找到右图的内容，并修改对应字段信息为主题名称（就是你下载主题之后的文件夹名称） 安装插件 hexo-wordocunt：字数统计的插件可以看到你文章的字数统计1npm install hexo-wordcount --save hexo-generator-json-content:搜索插件1npm install hexo-generator-json-content --save hexo-generator-feed：SSR订阅1npm install hexo-generator-feed --save hexo-generator-sitemap1npm install hexo-generator-sitemap --save hexo-generator-baidu-sitemap1npm install hexo-generator-baidu-sitemap --save 这个时候就需要配合主题文档来修改详细的信息。以github.io建站首先建立一个github仓库命名为“github名称+github.io”;在Hexo框架的主配置文件中修改对应发布位置使用命令进行发布12hexo ghexo d 就会将已经生成的文件发布到github仓库。使用github仓库名称作为域名访问。 重新配置Gitment评论功能由于主题本身的应用可能过时，会报object ProgressEvent问题。于是在网络上搜索修改方式，@wardseptember。提出的修改方案完美解决问题，在此感谢。 关于gitment的配置问题首先找到主题的配置文件找到标记位置githubID：对应你的github名称repo：对应是你的评论归属的仓库名称ClientID：注册OAuth Application获得 ，用于之后的用户登录ClientSecret:注册OAuth Application获得 ，用于之后的用户登录点击这里注册OAuth Application并参考Sogrey的注册步骤及详细进行注册。 完成以上的gitment注册之后，针对当前主题的配置修改。 首先找到下图位置的gitment.ejs 之后修改文件中标记的位置（此配置亲测可用） 继续找到另外的一个配置文件位置 继续修改标记位置的内容 这个时候基本的的配置已经完成，可以愉快总结自己的内容并发布了。加油","categories":[{"name":"杂记随笔","slug":"杂记随笔","permalink":"https://vincentxin-scott.github.io/categories/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://vincentxin-scott.github.io/tags/Hexo/"}]}],"categories":[{"name":"杂记随笔","slug":"杂记随笔","permalink":"https://vincentxin-scott.github.io/categories/%E6%9D%82%E8%AE%B0%E9%9A%8F%E7%AC%94/"},{"name":"数据库","slug":"数据库","permalink":"https://vincentxin-scott.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"脚本语言","slug":"脚本语言","permalink":"https://vincentxin-scott.github.io/categories/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/"},{"name":"小程序","slug":"小程序","permalink":"https://vincentxin-scott.github.io/categories/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"DevOps","slug":"DevOps","permalink":"https://vincentxin-scott.github.io/categories/DevOps/"},{"name":"工作流","slug":"工作流","permalink":"https://vincentxin-scott.github.io/categories/%E5%B7%A5%E4%BD%9C%E6%B5%81/"},{"name":"Spring","slug":"Spring","permalink":"https://vincentxin-scott.github.io/categories/Spring/"},{"name":"Linux","slug":"Linux","permalink":"https://vincentxin-scott.github.io/categories/Linux/"},{"name":"Mac","slug":"Mac","permalink":"https://vincentxin-scott.github.io/categories/Mac/"},{"name":"网络","slug":"网络","permalink":"https://vincentxin-scott.github.io/categories/%E7%BD%91%E7%BB%9C/"},{"name":"框架","slug":"框架","permalink":"https://vincentxin-scott.github.io/categories/%E6%A1%86%E6%9E%B6/"},{"name":"第三方支付","slug":"第三方支付","permalink":"https://vincentxin-scott.github.io/categories/%E7%AC%AC%E4%B8%89%E6%96%B9%E6%94%AF%E4%BB%98/"},{"name":"Spring官方文档","slug":"Spring官方文档","permalink":"https://vincentxin-scott.github.io/categories/Spring%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3/"},{"name":"设计模式","slug":"设计模式","permalink":"https://vincentxin-scott.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Java基础","slug":"Java基础","permalink":"https://vincentxin-scott.github.io/categories/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"certbot","slug":"certbot","permalink":"https://vincentxin-scott.github.io/tags/certbot/"},{"name":"分布式数据库","slug":"分布式数据库","permalink":"https://vincentxin-scott.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"MySQL","slug":"MySQL","permalink":"https://vincentxin-scott.github.io/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"https://vincentxin-scott.github.io/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"shell","slug":"shell","permalink":"https://vincentxin-scott.github.io/tags/shell/"},{"name":"微信公众号，微信小程序","slug":"微信公众号，微信小程序","permalink":"https://vincentxin-scott.github.io/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%EF%BC%8C%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"Docker","slug":"Docker","permalink":"https://vincentxin-scott.github.io/tags/Docker/"},{"name":"ORACLE","slug":"ORACLE","permalink":"https://vincentxin-scott.github.io/tags/ORACLE/"},{"name":"Activiti","slug":"Activiti","permalink":"https://vincentxin-scott.github.io/tags/Activiti/"},{"name":"SpringSecurity","slug":"SpringSecurity","permalink":"https://vincentxin-scott.github.io/tags/SpringSecurity/"},{"name":"Linux","slug":"Linux","permalink":"https://vincentxin-scott.github.io/tags/Linux/"},{"name":"解决问题","slug":"解决问题","permalink":"https://vincentxin-scott.github.io/tags/%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/"},{"name":"MySQL(MariaDB)报错处理","slug":"MySQL-MariaDB-报错处理","permalink":"https://vincentxin-scott.github.io/tags/MySQL-MariaDB-%E6%8A%A5%E9%94%99%E5%A4%84%E7%90%86/"},{"name":"npm","slug":"npm","permalink":"https://vincentxin-scott.github.io/tags/npm/"},{"name":"nvm","slug":"nvm","permalink":"https://vincentxin-scott.github.io/tags/nvm/"},{"name":"Oh-my-zsh","slug":"Oh-my-zsh","permalink":"https://vincentxin-scott.github.io/tags/Oh-my-zsh/"},{"name":"JDK","slug":"JDK","permalink":"https://vincentxin-scott.github.io/tags/JDK/"},{"name":"Lua","slug":"Lua","permalink":"https://vincentxin-scott.github.io/tags/Lua/"},{"name":"Redis","slug":"Redis","permalink":"https://vincentxin-scott.github.io/tags/Redis/"},{"name":"Idea","slug":"Idea","permalink":"https://vincentxin-scott.github.io/tags/Idea/"},{"name":"OKHTTP","slug":"OKHTTP","permalink":"https://vincentxin-scott.github.io/tags/OKHTTP/"},{"name":"HttpClient","slug":"HttpClient","permalink":"https://vincentxin-scott.github.io/tags/HttpClient/"},{"name":"Spring","slug":"Spring","permalink":"https://vincentxin-scott.github.io/tags/Spring/"},{"name":"支付宝支付","slug":"支付宝支付","permalink":"https://vincentxin-scott.github.io/tags/%E6%94%AF%E4%BB%98%E5%AE%9D%E6%94%AF%E4%BB%98/"},{"name":"Markdown","slug":"Markdown","permalink":"https://vincentxin-scott.github.io/tags/Markdown/"},{"name":"lftp","slug":"lftp","permalink":"https://vincentxin-scott.github.io/tags/lftp/"},{"name":"Homebrew","slug":"Homebrew","permalink":"https://vincentxin-scott.github.io/tags/Homebrew/"},{"name":"Jenkins","slug":"Jenkins","permalink":"https://vincentxin-scott.github.io/tags/Jenkins/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://vincentxin-scott.github.io/tags/SpringCloud/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://vincentxin-scott.github.io/tags/SpringBoot/"},{"name":"微信支付","slug":"微信支付","permalink":"https://vincentxin-scott.github.io/tags/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98/"},{"name":"Spring文档","slug":"Spring文档","permalink":"https://vincentxin-scott.github.io/tags/Spring%E6%96%87%E6%A1%A3/"},{"name":"设计模式","slug":"设计模式","permalink":"https://vincentxin-scott.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"mac","slug":"mac","permalink":"https://vincentxin-scott.github.io/tags/mac/"},{"name":"线程","slug":"线程","permalink":"https://vincentxin-scott.github.io/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"Hexo","slug":"Hexo","permalink":"https://vincentxin-scott.github.io/tags/Hexo/"}]}